{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13598939763a4922b8b6045ebfde5189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa7fd44b28a4f148677dc823a137bfb",
              "IPY_MODEL_c4930eef52744441aad91fe5ccd1a201",
              "IPY_MODEL_41fe98cf21d0407d821781e5e8f403ff"
            ],
            "layout": "IPY_MODEL_ccaf3f8698e34196845868d147c8c803"
          }
        },
        "eaa7fd44b28a4f148677dc823a137bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ec0aad06c64c50b1ca752ebc44ef51",
            "placeholder": "​",
            "style": "IPY_MODEL_d86c9f7ca18e421cbf62254f72408d41",
            "value": "100%"
          }
        },
        "c4930eef52744441aad91fe5ccd1a201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56748c21059a42399226daf5132f166f",
            "max": 214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6e7d8c8cced44bba271f400e4df3227",
            "value": 214
          }
        },
        "41fe98cf21d0407d821781e5e8f403ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d52afbd9c594948863c76f5a771bd00",
            "placeholder": "​",
            "style": "IPY_MODEL_82bbf72cbf2346a39fa4f4c4de5c6af0",
            "value": " 214/214 [27:43&lt;00:00,  7.19s/it]"
          }
        },
        "ccaf3f8698e34196845868d147c8c803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ec0aad06c64c50b1ca752ebc44ef51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86c9f7ca18e421cbf62254f72408d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56748c21059a42399226daf5132f166f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e7d8c8cced44bba271f400e4df3227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d52afbd9c594948863c76f5a771bd00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82bbf72cbf2346a39fa4f4c4de5c6af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc8ebc1358d4dce9fd88536e8364254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b292d93826024b0d97186737e14a6383",
              "IPY_MODEL_8869b283a7f44d62893726b9cfa47382",
              "IPY_MODEL_7fd3c1d95ee645d7ab16e2c8bce41365"
            ],
            "layout": "IPY_MODEL_46ed0c3bcc4a436091010a1ce53615d6"
          }
        },
        "b292d93826024b0d97186737e14a6383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee93dfa82e840079c0d69cd920f995a",
            "placeholder": "​",
            "style": "IPY_MODEL_9083d3fd505b4393aaaa97c4fc239283",
            "value": "100%"
          }
        },
        "8869b283a7f44d62893726b9cfa47382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06881a7d05742ce852ce71159cf2e39",
            "max": 130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ee36588a2146079ba573d3dbc5e0b6",
            "value": 130
          }
        },
        "7fd3c1d95ee645d7ab16e2c8bce41365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f0b1dc1ec440ec852509518c5f1083",
            "placeholder": "​",
            "style": "IPY_MODEL_c94085ea360c4948a452ee16a5d25066",
            "value": " 130/130 [23:29&lt;00:00, 10.52s/it]"
          }
        },
        "46ed0c3bcc4a436091010a1ce53615d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee93dfa82e840079c0d69cd920f995a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9083d3fd505b4393aaaa97c4fc239283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06881a7d05742ce852ce71159cf2e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ee36588a2146079ba573d3dbc5e0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f0b1dc1ec440ec852509518c5f1083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94085ea360c4948a452ee16a5d25066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2461b42b8de64e1492db4f6f57cbb8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a295fdbf0325482daef804c3fa1480ab",
              "IPY_MODEL_3612d5b126904022852780de0265025a",
              "IPY_MODEL_7f054857dd9a46b4a6944d88f46af0f6"
            ],
            "layout": "IPY_MODEL_373ac36437da42fc802e2f1f5f62c953"
          }
        },
        "a295fdbf0325482daef804c3fa1480ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79bc6d756bb046fd8aeb3a790bc6baef",
            "placeholder": "​",
            "style": "IPY_MODEL_7cda80b9b5bb42beb0becc9f82ae133e",
            "value": "modules.json: 100%"
          }
        },
        "3612d5b126904022852780de0265025a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1c885221054f60b7af0877e8febd9e",
            "max": 341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a00d5eaf54f48ad8c2ced776306f75a",
            "value": 341
          }
        },
        "7f054857dd9a46b4a6944d88f46af0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1b6a068b7e4fda911f47e5026c15a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a0bde5521dd240dca08a1f153ec88a6c",
            "value": " 341/341 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "373ac36437da42fc802e2f1f5f62c953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79bc6d756bb046fd8aeb3a790bc6baef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cda80b9b5bb42beb0becc9f82ae133e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d1c885221054f60b7af0877e8febd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a00d5eaf54f48ad8c2ced776306f75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee1b6a068b7e4fda911f47e5026c15a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bde5521dd240dca08a1f153ec88a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bee8532a7044a9882b412cf89df5a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9794dfc40f847c98840fd954c71f440",
              "IPY_MODEL_b9dc78c4370b4c5c9cde53263dfc1496",
              "IPY_MODEL_5316016b5b7445d880f2ecbc5dbf4188"
            ],
            "layout": "IPY_MODEL_615736c378014b489930f448a88a9e0c"
          }
        },
        "d9794dfc40f847c98840fd954c71f440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3e9b44b01045bbab4c9e0a21b1ef58",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f116b9c958419f964131d9d46a1077",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "b9dc78c4370b4c5c9cde53263dfc1496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c33bff8ac027458d975f8d5bbe0364c9",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62347c51e84d4705845745fde2a8c60b",
            "value": 122
          }
        },
        "5316016b5b7445d880f2ecbc5dbf4188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390c5f4514c34690ab011ffe89eb25e6",
            "placeholder": "​",
            "style": "IPY_MODEL_33ee3db3f96f4d0c8d5418945b423853",
            "value": " 122/122 [00:00&lt;00:00, 9.36kB/s]"
          }
        },
        "615736c378014b489930f448a88a9e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3e9b44b01045bbab4c9e0a21b1ef58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f116b9c958419f964131d9d46a1077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33bff8ac027458d975f8d5bbe0364c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62347c51e84d4705845745fde2a8c60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "390c5f4514c34690ab011ffe89eb25e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ee3db3f96f4d0c8d5418945b423853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11053d7e5a0427bb56324cbfb9c391f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b37a719f27be47d6875989b694d198a2",
              "IPY_MODEL_a0e47ea3e06846b38fd6722732a4aaf0",
              "IPY_MODEL_069e544b7e254657b1affe0e7ca4ec53"
            ],
            "layout": "IPY_MODEL_6468b1e0254545b891af4aee16b8d800"
          }
        },
        "b37a719f27be47d6875989b694d198a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b177f0bb5fe4a348ff399f962f16bab",
            "placeholder": "​",
            "style": "IPY_MODEL_b46e952178334d01b2bad5e9011779f6",
            "value": "README.md: 100%"
          }
        },
        "a0e47ea3e06846b38fd6722732a4aaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e74837cd564438aa9718b5d867d40dd",
            "max": 2466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19cb02dda8f6433b9f95b29b980821c5",
            "value": 2466
          }
        },
        "069e544b7e254657b1affe0e7ca4ec53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec4c72c548244eaa26d9efcfcae79a0",
            "placeholder": "​",
            "style": "IPY_MODEL_43b3fd370fca4d5d801617f360189f2a",
            "value": " 2.47k/2.47k [00:00&lt;00:00, 173kB/s]"
          }
        },
        "6468b1e0254545b891af4aee16b8d800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b177f0bb5fe4a348ff399f962f16bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b46e952178334d01b2bad5e9011779f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e74837cd564438aa9718b5d867d40dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cb02dda8f6433b9f95b29b980821c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cec4c72c548244eaa26d9efcfcae79a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b3fd370fca4d5d801617f360189f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36512fbe1e814138a81c07be8e383dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aba894f6c5748b28d4ebe67105eba9c",
              "IPY_MODEL_8ef90cac3f1c42eca461ab173369c604",
              "IPY_MODEL_2f7b26a23dfd42788b5f807929ade5e3"
            ],
            "layout": "IPY_MODEL_76d0f2db357f40d38970476f09de126b"
          }
        },
        "1aba894f6c5748b28d4ebe67105eba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61c4706c88d41a997f3e9a84da1875b",
            "placeholder": "​",
            "style": "IPY_MODEL_41959f668eaa4de6b0804c5bedf286bf",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8ef90cac3f1c42eca461ab173369c604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc20f876ec746d6b0cf0afd79d53d3a",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38b08ec21f474f57940a7ae8be7e704f",
            "value": 53
          }
        },
        "2f7b26a23dfd42788b5f807929ade5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f36c4b0b8042f8bf8cfc5c0d867c92",
            "placeholder": "​",
            "style": "IPY_MODEL_ee6428debd284e6b859b1abd066b86b9",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.45kB/s]"
          }
        },
        "76d0f2db357f40d38970476f09de126b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61c4706c88d41a997f3e9a84da1875b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41959f668eaa4de6b0804c5bedf286bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fc20f876ec746d6b0cf0afd79d53d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b08ec21f474f57940a7ae8be7e704f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82f36c4b0b8042f8bf8cfc5c0d867c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6428debd284e6b859b1abd066b86b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967899d2dff9406ab7d20d90a321f964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_335b66c62a1d48a8b679f63f06e7becf",
              "IPY_MODEL_211c52dcaa84465583006f22ef004c43",
              "IPY_MODEL_758b99d3d37f4625a41aba0fad77d95e"
            ],
            "layout": "IPY_MODEL_a61a41e447334d05a818f5cee5ea965a"
          }
        },
        "335b66c62a1d48a8b679f63f06e7becf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de516437264347489b2f43d8b3461b0a",
            "placeholder": "​",
            "style": "IPY_MODEL_74f32cf197a64c4081dc4c3a1f69ce17",
            "value": "config.json: 100%"
          }
        },
        "211c52dcaa84465583006f22ef004c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938bb9fa4d11455791e64da61978e4d1",
            "max": 556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bb5643b7c354436b885f7f10fed6ce3",
            "value": 556
          }
        },
        "758b99d3d37f4625a41aba0fad77d95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da8b344c21c04fadbe4df0138ffbe841",
            "placeholder": "​",
            "style": "IPY_MODEL_e55a3392c4054e50857835a01588c9e7",
            "value": " 556/556 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "a61a41e447334d05a818f5cee5ea965a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de516437264347489b2f43d8b3461b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f32cf197a64c4081dc4c3a1f69ce17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938bb9fa4d11455791e64da61978e4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb5643b7c354436b885f7f10fed6ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da8b344c21c04fadbe4df0138ffbe841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55a3392c4054e50857835a01588c9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5350a5cdc663450ab3fc3a0062610936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e554f40009494b8dfabcaeaf285ccf",
              "IPY_MODEL_38cd7872c90b4cb49064b7e6acb8e3cd",
              "IPY_MODEL_3cf6b3398add439fb20080de056d30d2"
            ],
            "layout": "IPY_MODEL_ccf6a12b669f4fd483162cdfce419051"
          }
        },
        "92e554f40009494b8dfabcaeaf285ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_660ed12fe98c425596f4c21fcdbcf11b",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7fdff6f0274dbab57e0ec27cd21fc0",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "38cd7872c90b4cb49064b7e6acb8e3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67319f85031c479cba6a831584e1033a",
            "max": 538971577,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab86b6e600f0448182d40e9ae4bd1959",
            "value": 538971577
          }
        },
        "3cf6b3398add439fb20080de056d30d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ffe8248c3a4991bc81051a5e2cad9d",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d56420a61a4d9597ba7c311e48c0f7",
            "value": " 539M/539M [00:03&lt;00:00, 162MB/s]"
          }
        },
        "ccf6a12b669f4fd483162cdfce419051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660ed12fe98c425596f4c21fcdbcf11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7fdff6f0274dbab57e0ec27cd21fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67319f85031c479cba6a831584e1033a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab86b6e600f0448182d40e9ae4bd1959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7ffe8248c3a4991bc81051a5e2cad9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d56420a61a4d9597ba7c311e48c0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a789ec9358244964a79b765e00e6af2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcfffe895d1343be908ecfb09d4b827a",
              "IPY_MODEL_5a1a3d7c1878410e80a7d5c447a4e17b",
              "IPY_MODEL_ffb6e9049bd8413da3ad1658c0875b3c"
            ],
            "layout": "IPY_MODEL_3710adebb39945a38baa871478aac9a1"
          }
        },
        "fcfffe895d1343be908ecfb09d4b827a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7624cba8b4cf425681ba55a485e441e0",
            "placeholder": "​",
            "style": "IPY_MODEL_08c4122f241b459f8a090b34011e70ac",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5a1a3d7c1878410e80a7d5c447a4e17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1655f166005c4883b9d739fe7587db6e",
            "max": 452,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ceca4abb3bc4291943d5ce1bb8118c7",
            "value": 452
          }
        },
        "ffb6e9049bd8413da3ad1658c0875b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c46e6e347241b4bd4f3bbed1c4a2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad7b93b4adb04200acfa7f31cd38d80a",
            "value": " 452/452 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "3710adebb39945a38baa871478aac9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7624cba8b4cf425681ba55a485e441e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c4122f241b459f8a090b34011e70ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1655f166005c4883b9d739fe7587db6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ceca4abb3bc4291943d5ce1bb8118c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7c46e6e347241b4bd4f3bbed1c4a2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7b93b4adb04200acfa7f31cd38d80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a236a1def874b15a0b9af13f73a3ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9ef75adffbd4c2a8877a693abb5b764",
              "IPY_MODEL_ea7a36b5f3fb4bb18ec8af5990c2280d",
              "IPY_MODEL_a47944ef9f8247478da61eb76e34ba2c"
            ],
            "layout": "IPY_MODEL_4f7e41db97614117b5db6441e52fa86f"
          }
        },
        "e9ef75adffbd4c2a8877a693abb5b764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa7f71657a4433396eaf1018d11eff7",
            "placeholder": "​",
            "style": "IPY_MODEL_eec49f701e6a42be9b635bb8fda3d7e3",
            "value": "vocab.txt: 100%"
          }
        },
        "ea7a36b5f3fb4bb18ec8af5990c2280d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abc8353d5a94c58bf43f2b9fb34313f",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9bac04da3b84cec9ecc685e2693da16",
            "value": 995526
          }
        },
        "a47944ef9f8247478da61eb76e34ba2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9311a651502a4c08a561b9b38c120d58",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7e2769b710405c86b99de7d3443156",
            "value": " 996k/996k [00:00&lt;00:00, 13.4MB/s]"
          }
        },
        "4f7e41db97614117b5db6441e52fa86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa7f71657a4433396eaf1018d11eff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec49f701e6a42be9b635bb8fda3d7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abc8353d5a94c58bf43f2b9fb34313f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bac04da3b84cec9ecc685e2693da16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9311a651502a4c08a561b9b38c120d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7e2769b710405c86b99de7d3443156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e6704c87f64b568fdb8c2a4665ad74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5ac468752034e41b14ba237988b1393",
              "IPY_MODEL_c7d4c873a9d64c1e91f75c9efecdb750",
              "IPY_MODEL_f46f1368706e4de8882c8794c131f104"
            ],
            "layout": "IPY_MODEL_305a5b7bce2f41399144a0428cc54d80"
          }
        },
        "c5ac468752034e41b14ba237988b1393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ef71bf86c44333908b6937fac2888c",
            "placeholder": "​",
            "style": "IPY_MODEL_09ac404bfd754f248ce5a2f147c736a9",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7d4c873a9d64c1e91f75c9efecdb750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f158db61687f4af59274465248f8e114",
            "max": 1961847,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37ac2c340c53486aab6119253ceb54f2",
            "value": 1961847
          }
        },
        "f46f1368706e4de8882c8794c131f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2822c5dcef4747b7a4ea2716f8818d",
            "placeholder": "​",
            "style": "IPY_MODEL_74cf21856d944f5b8cd0240aeaf49a22",
            "value": " 1.96M/1.96M [00:03&lt;00:00, 648kB/s]"
          }
        },
        "305a5b7bce2f41399144a0428cc54d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ef71bf86c44333908b6937fac2888c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ac404bfd754f248ce5a2f147c736a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f158db61687f4af59274465248f8e114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ac2c340c53486aab6119253ceb54f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac2822c5dcef4747b7a4ea2716f8818d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74cf21856d944f5b8cd0240aeaf49a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d079b323351424f925754c5eafaf2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4362219281294239b48eaa1c8041970f",
              "IPY_MODEL_2b3ef5aa3bae4c61b33e1d7888ee6150",
              "IPY_MODEL_6984f8e750c54e98a37786b17341af50"
            ],
            "layout": "IPY_MODEL_6bd84f8b8e17486d9c9d127133ef051b"
          }
        },
        "4362219281294239b48eaa1c8041970f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1cdf52756f143cc9a1d4c21a6f18fc4",
            "placeholder": "​",
            "style": "IPY_MODEL_7c9ecc66e7404ece99e86ce8c97a43f5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2b3ef5aa3bae4c61b33e1d7888ee6150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413ff24539b14a17bcf9aabd2917ccc9",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d554b87e0d474eca971de5c33d5f3faf",
            "value": 112
          }
        },
        "6984f8e750c54e98a37786b17341af50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b69f65545e4d67910976f7ff1a4e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_29fdec53aa4c48968f5c9116fbd5f832",
            "value": " 112/112 [00:00&lt;00:00, 8.89kB/s]"
          }
        },
        "6bd84f8b8e17486d9c9d127133ef051b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1cdf52756f143cc9a1d4c21a6f18fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9ecc66e7404ece99e86ce8c97a43f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "413ff24539b14a17bcf9aabd2917ccc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d554b87e0d474eca971de5c33d5f3faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21b69f65545e4d67910976f7ff1a4e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29fdec53aa4c48968f5c9116fbd5f832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ded1c207e1c44f3acd1b0bcdd3abdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d129ba5ae01d44d68c3269422440545f",
              "IPY_MODEL_651539eaeb2f4f7496282aef73f07364",
              "IPY_MODEL_6917331bfbb648119af41729077a89c0"
            ],
            "layout": "IPY_MODEL_2ce9388c56e04fa581f113c4702ad077"
          }
        },
        "d129ba5ae01d44d68c3269422440545f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d913f7f9da747fa970b08b1c7ed9015",
            "placeholder": "​",
            "style": "IPY_MODEL_32d9065242954d059135cf1bb9c4e29c",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "651539eaeb2f4f7496282aef73f07364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e19eff65f74629a4f14255e37aa0e4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc31119a106540daaf02664b67b9e54a",
            "value": 190
          }
        },
        "6917331bfbb648119af41729077a89c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1496cbca85294dfc8f216862a56c4040",
            "placeholder": "​",
            "style": "IPY_MODEL_f449050942ae46058b25066edf94576b",
            "value": " 190/190 [00:00&lt;00:00, 8.92kB/s]"
          }
        },
        "2ce9388c56e04fa581f113c4702ad077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d913f7f9da747fa970b08b1c7ed9015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d9065242954d059135cf1bb9c4e29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e19eff65f74629a4f14255e37aa0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc31119a106540daaf02664b67b9e54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1496cbca85294dfc8f216862a56c4040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f449050942ae46058b25066edf94576b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d42971c35fdc4f6d9c052639166a97a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c682132cb024f8ea88d2e9f6bb0e7ac",
              "IPY_MODEL_22180f8dde4d4764844ae6175893765d",
              "IPY_MODEL_fe57b466ccc54459b278d25c040be17c"
            ],
            "layout": "IPY_MODEL_060d67dd014e44568468dd8239ca319f"
          }
        },
        "4c682132cb024f8ea88d2e9f6bb0e7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5154155e38284e809194ec3338103071",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a7f02c5e944e269c28e3b18d05063c",
            "value": "2_Dense/config.json: 100%"
          }
        },
        "22180f8dde4d4764844ae6175893765d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f90b34aede44a781799c8b736ded21",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38361f21508f40f6a829e7bdf671bde3",
            "value": 114
          }
        },
        "fe57b466ccc54459b278d25c040be17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e2bfedb8184301aa0f2887fe3bd54b",
            "placeholder": "​",
            "style": "IPY_MODEL_419bbba1f1224c5fa72cd07602ac6e02",
            "value": " 114/114 [00:00&lt;00:00, 7.58kB/s]"
          }
        },
        "060d67dd014e44568468dd8239ca319f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5154155e38284e809194ec3338103071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a7f02c5e944e269c28e3b18d05063c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f90b34aede44a781799c8b736ded21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38361f21508f40f6a829e7bdf671bde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24e2bfedb8184301aa0f2887fe3bd54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "419bbba1f1224c5fa72cd07602ac6e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31607b2431914726b82721c143798110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d484fbb44464de4a7905415906b7b39",
              "IPY_MODEL_0518cab8c55e4b6d924f7ccf79bd09b6",
              "IPY_MODEL_2a447285cdde41b38d737588b4700738"
            ],
            "layout": "IPY_MODEL_6f99c9f5ae504cd28e8c6e04a9c5b21b"
          }
        },
        "3d484fbb44464de4a7905415906b7b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ffaaa7a3a7433fa3218a276152cd41",
            "placeholder": "​",
            "style": "IPY_MODEL_d5e2660c10fb4287850f019fbdf45474",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0518cab8c55e4b6d924f7ccf79bd09b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab91854e66ea48bbbe7a7bcec9cd1451",
            "max": 1575975,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1bef629a2f4d848b77ad181c95ee8c",
            "value": 1575975
          }
        },
        "2a447285cdde41b38d737588b4700738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1497c45e079f493db60d0a12211a1100",
            "placeholder": "​",
            "style": "IPY_MODEL_82cbcb4e56e44d5cb43fe955d8395a64",
            "value": " 1.58M/1.58M [00:00&lt;00:00, 17.8MB/s]"
          }
        },
        "6f99c9f5ae504cd28e8c6e04a9c5b21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ffaaa7a3a7433fa3218a276152cd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e2660c10fb4287850f019fbdf45474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab91854e66ea48bbbe7a7bcec9cd1451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1bef629a2f4d848b77ad181c95ee8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1497c45e079f493db60d0a12211a1100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cbcb4e56e44d5cb43fe955d8395a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GPU\n"
      ],
      "metadata": {
        "id": "ssHMxUo1PsXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install -qq llama-cpp-python\n",
        "!pip install -qq sentence_transformers"
      ],
      "metadata": {
        "id": "6vdbGKaV0sfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e2a2f3-3c4c-42b4-acec-4f11e305f2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD7pJITX0PeA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, runtime\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from llama_cpp import Llama\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_start_time = time.time()\n",
        "\n",
        "\n",
        "cfg_batch = 4096 * 2\n",
        "cfg_ctx = 2048\n",
        "cfg_model = f'ggml-model-q8_0.gguf'\n",
        "model_path = f'/content/drive/MyDrive/DACON/Hansol_QA/model/yanolja_axolotl_v0.2/{cfg_model}'"
      ],
      "metadata": {
        "id": "nbQsK97F0WqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "    n_batch=cfg_batch,\n",
        "    model_path=model_path,\n",
        "    n_ctx=cfg_ctx,\n",
        "    n_gpu_layers=-1,\n",
        ")\n",
        "# https://llama-cpp-python.readthedocs.io/en/latest/api-reference/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdoY7Bfv0l0A",
        "outputId": "f3facd99-c561-4203-b273-14fed1c7eaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 435 tensors from /content/drive/MyDrive/DACON/Hansol_QA/model/yanolja_axolotl_v0.2/ggml-model-q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 48\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,40960]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,40960]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,40960]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   97 tensors\n",
            "llama_model_loader: - type q8_0:  338 tensors\n",
            "llm_load_vocab: mismatch in special tokens definition ( 261/40960 vs 260/40960 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 40960\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 48\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 34B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 10.80 B\n",
            "llm_load_print_meta: model size       = 10.69 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 2 '</s>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.33 MiB\n",
            "llm_load_tensors: offloading 48 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 49/49 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   170.00 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size = 10779.52 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   384.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  384.00 MiB, K (f16):  192.00 MiB, V (f16):  192.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host input buffer size   =    64.04 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   656.01 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    32.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '48', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/datas/test_processed.csv')\n",
        "\n",
        "res_question = []\n",
        "res_answer = []\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"max_tokens\": 50000,\n",
        "    \"stop\":[\"<|im_end|>\"],\n",
        "    \"echo\":False,\n",
        "    \"seed\" : 42,\n",
        "    \"top_k\": 1,\n",
        "    # \"top_p\": 0,\n",
        "    # \"repeat_penalty\" : 1.2,\n",
        "    # \"temperature\" : 0.5,\n",
        "}\n",
        "\n",
        "\n",
        "for i, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
        "    instruction = \"당신은 인테리어 회사에 다니는 건축 전문가이다. \\\n",
        "    도배하자와 관련된 다양한 질문과 상황이 제시되면, 이에 대한 정확하고 신속한 응답을 제공해야한다.\\\n",
        "    예시는 다음과 같다.\\\n",
        "    질문: 중목구조 방식에 대해서 좀 더 자세히 알고 싶어요.\\\n",
        "    답변: 중목구조는 기본적으로 기중-보 방식과 유사하지만 구조용 목재로 큰 각재를 사용하여 건축하는 방식입니다. 이 방식은 건물 내부의 기둥이나 보가 중양이 되어 강도를 높일 수 있다는 것이 특징이며, 이는 건물을 더 안정적으로 만들어 줍니다. 중목구조 방식은 전체적으로 부재를 이용하기 때문에 건물이 흔들리는 것을 줄여주고, 건물의 수명을 연장시키는 등 여러 가지 장점을 갖고 있습니다.\\\n",
        "    \\\n",
        "    질문: 분말 소화기를 사용할 때에는 어떤 주의사항이 있을까요?\\\n",
        "    답변: 분말 소화기를 사용할 때 주의할 점은 몇 가지가 있습니다. 우선 압력계의 눈금 위치가 초록색에 있는지 확인하는 것이 중요합니다. 이외에 분말 소화기를 사용한 후에는 받침대를 사용하여 소화기 부식을 방지하고, 한 달에 한 번씩 흔들어 분말의 굳어짐을 방지해야 합니다. 또한, 직사광선과 고온 다습한 장소를 피하고, 사용 후 내부 약품을 완전히 제거해야 합니다. 이러한 주의사항을 지키면 분말 소화기를 보다 안전하게 사용할 수 있을 것입니다.\\\n",
        "    \\\n",
        "    질문: KMEW 세라믹 지붕재는 어떤 특징을 가지고 있나요?\\\n",
        "    답변: KMEW 세라믹 지붕재는 일본의 기업인 KMEW에서 개발한 지붕재로, 산화티타늄 처리를 통해 내구성을 높이고 환경친화적인 소재로 제작되었습니다. 이 지붕재는 태양광 및 자외선으로부터의 보호와 함께 오염물질의 분해를 돕는 기능을 갖고 있어, 건물의 외관을 보호하고 유지보수에 도움이 되는 장점을 가지고 있습니다.\\\n",
        "    \\\n",
        "    이렇듯 최대한 알고 있는 내용에 대해 자세히 설명해야 하며, 답변은 할 수 있는 한 길게 해야 한다. 실제 답변을 할 때에는 앞의 '답변:' 을 빼고 내용만 제공한다.\\n \"\n",
        "    questions_combined = row['질문1'] if not pd.isnull(row['질문1']) else \"\"\n",
        "    answers_combined = \"\"\n",
        "\n",
        "    question1 = f\"{instruction} {row['질문1']}\"\n",
        "    res1 = llm(question1, **generation_kwargs)\n",
        "    answer1 = res1[\"choices\"][0][\"text\"]\n",
        "    answers_combined += answer1\n",
        "\n",
        "    if not pd.isnull(row['질문2']):\n",
        "        questions_combined += \" \" + row['질문2']\n",
        "        question2 = f\"{instruction} {row['질문2']}\"\n",
        "        res2 = llm(question2, **generation_kwargs)\n",
        "        answer2 = res2[\"choices\"][0][\"text\"]\n",
        "        answers_combined += \"\\n\" + answer2\n",
        "\n",
        "    res_question.append(questions_combined)\n",
        "    res_answer.append(answers_combined)\n",
        "    print(answers_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3fc8ebc1358d4dce9fd88536e8364254",
            "b292d93826024b0d97186737e14a6383",
            "8869b283a7f44d62893726b9cfa47382",
            "7fd3c1d95ee645d7ab16e2c8bce41365",
            "46ed0c3bcc4a436091010a1ce53615d6",
            "3ee93dfa82e840079c0d69cd920f995a",
            "9083d3fd505b4393aaaa97c4fc239283",
            "c06881a7d05742ce852ce71159cf2e39",
            "f2ee36588a2146079ba573d3dbc5e0b6",
            "e0f0b1dc1ec440ec852509518c5f1083",
            "c94085ea360c4948a452ee16a5d25066"
          ]
        },
        "id": "GrRW2v8d02O7",
        "outputId": "7243eb27-69f8-483b-add0-2fc29d577d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/130 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fc8ebc1358d4dce9fd88536e8364254"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     230.67 ms /   270 runs   (    0.85 ms per token,  1170.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     407.85 ms /    14 tokens (   29.13 ms per token,    34.33 tokens per second)\n",
            "llama_print_timings:        eval time =   14269.99 ms /   269 runs   (   53.05 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   16197.36 ms /   283 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      50.19 ms /    69 runs   (    0.73 ms per token,  1374.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     318.04 ms /    13 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3577.35 ms /    68 runs   (   52.61 ms per token,    19.01 tokens per second)\n",
            "llama_print_timings:       total time =    4194.96 ms /    81 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   방청 페인트의 종류로는 광명단 페인트, 방청산화철 페인트, 알미늄 페인트, 역청질 페인트, 워시 프라이머, 크롬산아연 페인트, 규산염 페인트 등이 있습니다. 이러한 페인트들은 각각의 특성과 용도에 맞게 선택하여 사용할 수 있습니다. 광명단 페인트는 반사율이 높아서 더 밝은 공간으로 만들어주며, 방청산화철 페인트는 방청제가 첨가되어 방청 효과를 내는 페인트입니다. 알미늄 페인트는 금속 또는 철강 표면에 사용되어 내화, 방청 효과를 가지는 페인트입니다. 역청질 페인트는 강철, 철판, 강관 등 강철재에 방청처리용으로 사용되는 페인트로, 방청제의 첨가와 염모처리에 의해 방청효과가 향상되었습니다. 워시 프라이머는 철강, 알루미늄, 유리섬유, 금속, 플라스틱 등에 사용되는 중요한 물품의 부착용으로서 용도에 맞게 선정할 수 있습니다. 크롬산아연 페인트와 규산염 페인트도 각각의 특성과 용도에 따라 선택하여 사용할 수 있습니다.\n",
            "   원목사이딩의 단점은 가격대가 높을 뿐 아니라 관리가 어렵고 습기에 민감하여 뒤틀림, 부서짐, 수축/팽창이 발생할 수 있다는 점입니다. 또한 특히 곰팡이와 곤충에 노출될 경우 훼손될 가능성이 높다는 점도 감안해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      89.10 ms /   118 runs   (    0.76 ms per token,  1324.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     405.97 ms /    18 tokens (   22.55 ms per token,    44.34 tokens per second)\n",
            "llama_print_timings:        eval time =    6157.32 ms /   117 runs   (   52.63 ms per token,    19.00 tokens per second)\n",
            "llama_print_timings:       total time =    7115.03 ms /   135 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지에 녹은 자국이 발생하는 원인은 습기 때문입니다. 공간 내 습도가 높으면 도배지 안쪽의 금속이 녹아서 도배지에 베어나올 수 있습니다. 이로 인해 도배지 표면에 녹색 또는 갈색의 녹이 발생할 수 있습니다. 따라서 공간 내 습도를 적정 수준으로 유지하고, 필요할 경우 제습기를 이용하여 습도를 조절하는 것이 중요합니다. 또한, 도배작업 시에는 습기를 철저히 제거하고, 적절한 방법으로 방수 처리를 함으로써 이러한 문제를 예방할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      36.52 ms /    51 runs   (    0.72 ms per token,  1396.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.57 ms /     9 tokens (   26.84 ms per token,    37.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2616.46 ms /    50 runs   (   52.33 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    3078.41 ms /    59 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      67.08 ms /    97 runs   (    0.69 ms per token,  1446.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.68 ms /    12 tokens (   20.14 ms per token,    49.65 tokens per second)\n",
            "llama_print_timings:        eval time =    5045.17 ms /    96 runs   (   52.55 ms per token,    19.03 tokens per second)\n",
            "llama_print_timings:       total time =    5666.84 ms /   108 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 큐블럭의 단점은 주로 가격이 상대적으로 비싸다는 점, 그리고 균열이 일반 벽돌에 비해 더 쉽게 생길 수 있다는 것입니다. 또한 습기로 인해 하자가 발생할 가능성이 있는 것도 단점으로 꼽힙니다.\n",
            "   압출법 단열판의 장점은 습기에 강하고 곰팡이 및 세균 증식을 막을 수 있는 것입니다. 또한, 단열재 중에서는 열전도율이 가장 낮으며 시공이 간편하다는 점도 장점으로 꼽힙니다. 추가로 압출법 단열판은 가벼워서 운반이 용이하고 내구성이 뛰어나다는 점도 많은 사용자들에게 긍정적인 평가를 받고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     100.02 ms /   131 runs   (    0.76 ms per token,  1309.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     490.88 ms /    23 tokens (   21.34 ms per token,    46.86 tokens per second)\n",
            "llama_print_timings:        eval time =    6879.89 ms /   130 runs   (   52.92 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =    7997.90 ms /   153 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철골구조의 고층 건물에서 단열 효과를 높이는 방법은 여러 가지가 있습니다. 예를 들어, 내부에 단열재나 단열재 패널을 설치하는 것 외에도 외벽에 단열재나 단열재 코팅된 외장재를 사용하는 방법이 있습니다. 또한, 기밀성 단열재나 스프레이 단열재 등을 사용하여 건물의 기밀성을 향상시키고 단열 효과를 높이는 방법도 효과적입니다. 선택된 시공 방법은 건물의 구조, 설계, 그리고 환경적 요소에 따라 다를 수 있습니다. 따라서, 시공 전에 전문가의 상세한 검토와 조언을 받는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      50.25 ms /    72 runs   (    0.70 ms per token,  1432.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     328.70 ms /    15 tokens (   21.91 ms per token,    45.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3736.79 ms /    71 runs   (   52.63 ms per token,    19.00 tokens per second)\n",
            "llama_print_timings:       total time =    4349.60 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배 후 도배지가 완전히 건조되기까지 최소 일주일이 걸릴 수 있습니다. 건조 시간은 환경의 습도와 온도, 사용된 재료 등에 따라 다를 수 있기 때문에, 제조사의 권장사항을 따르는 것이 중요합니다. 최종적으로 건조 시간은 완전한 단단함과 안정성을 확보하기 위해 충분한 시간이 소요되므로 너무 서둘지 않는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      97.93 ms /   128 runs   (    0.77 ms per token,  1307.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.43 ms /    15 tokens (   22.10 ms per token,    45.26 tokens per second)\n",
            "llama_print_timings:        eval time =    6714.91 ms /   127 runs   (   52.87 ms per token,    18.91 tokens per second)\n",
            "llama_print_timings:       total time =    7672.84 ms /   142 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철근철골콘크리트는 철근과 철골, 그리고 콘크리트를 함께 사용하는 건축 구조입니다. 철근은 강도와 내구성을 제공하고, 철골은 구조를 지지하며, 콘크리트는 외부 마감재로 사용됩니다. 이러한 구조는 내화성과 내진성의 성능이 우수하며, 철골의 사용으로 인해 공간 활용이 용이합니다. 그러나 고층 건물에서는 아래층의 보나 기둥이 상당히 큰 단면을 가져야 하는 단점이 있습니다. 또한, 철근철골콘크리트는 다른 구조에 비해 비교적 비용이 많이 드는 편입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      38.44 ms /    55 runs   (    0.70 ms per token,  1430.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     412.80 ms /    20 tokens (   20.64 ms per token,    48.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2844.55 ms /    54 runs   (   52.68 ms per token,    18.98 tokens per second)\n",
            "llama_print_timings:       total time =    3472.32 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      48.67 ms /    68 runs   (    0.72 ms per token,  1397.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.03 ms /     9 tokens (   28.23 ms per token,    35.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3524.58 ms /    67 runs   (   52.61 ms per token,    19.01 tokens per second)\n",
            "llama_print_timings:       total time =    4053.40 ms /    76 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 오픈 플랜은 공간을 확장하고 연결감을 높이는 반면, 개별 공간은 개인 공간과 프라이버시를 제공합니다. 따라서 오픈 플랜은 활동적이고 소통을 선호하는 상황에 더 적합하며, 개별 공간은 개인 시간과 공간을 중요시하는 상황에 더 적합합니다.\n",
            "   합지벽지의 단점은 상대적으로 수명이 짧고 내구성이 약하며 오염이 생기면 청소가 어렵고 시간이 지나면 변색이 될 수 있다는 점입니다. 또한, 합지벽지는 보다 고급스러운 느낌을 줄 수 있는 다른 벽재에 비해 내구성이 상대적으로 약하다는 것을 의미합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      75.12 ms /    96 runs   (    0.78 ms per token,  1277.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.54 ms /    12 tokens (   21.38 ms per token,    46.78 tokens per second)\n",
            "llama_print_timings:        eval time =    5030.22 ms /    95 runs   (   52.95 ms per token,    18.89 tokens per second)\n",
            "llama_print_timings:       total time =    5761.59 ms /   107 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지 들뜸 현상은 주로 습도가 높은 환경에서 발생합니다. 습기가 도배지에 스며들거나 습기로 인해 도배지가 부풀어 오르면 벽면에서 떨어질 수 있습니다. 따라서 습도 관리가 중요하며, 제습기를 가동하거나 환기를 통해 실내 적정 습도를 유지하는 것이 도배지 들뜸 현상을 예방하는 데 도움이 됩니다. 또한, 전문가의 도움을 받아 보수 작업을 하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      73.72 ms /   107 runs   (    0.69 ms per token,  1451.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.70 ms /    12 tokens (   20.89 ms per token,    47.87 tokens per second)\n",
            "llama_print_timings:        eval time =    5611.41 ms /   106 runs   (   52.94 ms per token,    18.89 tokens per second)\n",
            "llama_print_timings:       total time =    6282.10 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지에 얼룩이 발생하는 원인은 다양합니다. 주요 원인으로는 100% 자연 소재로 만들어진 도배지의 품질과 내구성 차이가 있습니다. 또한 사용 환경, 예를 들어 습기, 먼지, 연기로 인한 오염이 발생할 수 있습니다. 또한 적절하지 않은 도배지 접착제 사용이나 잘못된 후처리 방법 역시 얼룩 발생의 원인이 될 수 있습니다. 이러한 문제들을 해결하기 위해서는 전문가의 도움을 받아 적절한 도배지와 재료를 선택하고, 사용 환경에 맞는 적절한 관리가 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     154.84 ms /   207 runs   (    0.75 ms per token,  1336.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     414.81 ms /    17 tokens (   24.40 ms per token,    40.98 tokens per second)\n",
            "llama_print_timings:        eval time =   10964.39 ms /   206 runs   (   53.23 ms per token,    18.79 tokens per second)\n",
            "llama_print_timings:       total time =   12332.23 ms /   223 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철골구조는 고층 건물의 건축에 적합한 여러 가지 이유가 있습니다.   첫째로, 철골구조는 다른 구조 방식에 비해 더 많은 하중을 견딜 수 있습니다. 이는 건물의 높이와 크기를 증가시킬 수 있게 해주며, 공간 활용 가능성을 확대시킵니다.   둘째로, 철골구조는 다른 구조 방식보다 시공이 빠르며, 공사 기간을 단축시킬 수 있습니다. 이는 건설 기간 동안의 비용을 절감할 수 있게 해주며, 프로젝트 마감을 앞당길 수 있습니다.  또한 철골구조는 건물의 외벽에는 그다지 하중이 걸리지 않기 때문에, 고층 건물의 외벽에서 발생하는 열전달 현상을 줄일 수 있습니다. 이는 건물 내부의 온도를 안정화시키고, 에너지 소비를 줄이는 데 도움을 줄 수 있습니다.   따라서 철골구조는 고층 건물의 건축에 적합하며, 안정적인 건물을 지을 수 있는 구조 방식로 선택됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     251.06 ms /   335 runs   (    0.75 ms per token,  1334.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     340.72 ms /    13 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
            "llama_print_timings:        eval time =   17879.44 ms /   334 runs   (   53.53 ms per token,    18.68 tokens per second)\n",
            "llama_print_timings:       total time =   19845.18 ms /   347 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   유성페인트는 주로 석유나 석탄에서 추출한 기름이나 화학물질로 만들어지며, 이들 중 일부는 인체에 유해한 영향을 미칠 수 있습니다. 유성페인트의 주요 단점은 다음과 같습니다.  1. 유해성: 유성페인트에는 벤젠, 톨루엔, 자일렌 등의 유해물질이 포함되어 있으며, 이러한 물질들은 호흡기나 피부 등을 통해 체내로 흡수될 수 있습니다. 장기간 노출되면 암, 호흡기 질환, 피부 질환 등의 건강 문제를 유발할 수 있습니다.  2. 냄새: 유성페인트는 강한 냄새를 가지고 있으며, 이는 작업자뿐만 아니라 주변 사람들에게도 불쾌감을 줄 수 있습니다.  3. 건조 시간: 유성페인트는 건조 시간이 길며, 이로 인해 작업 시간이 더 오래 걸릴 수 있습니다. 또한, 건조 과정에서 발생하는 열로 인해 작업자가 불편함을 느낄 수 있습니다.  4. 환경 오염: 유성페인트는 환경 오염을 유발할 수 있습니다. 유성페인트의 성분 중 일부는 대기 중에 방출되면 미세먼지나 오존 등의 오염물질을 생성할 수 있습니다.  5. 유지보수 어려움: 유성페인트는 물에 녹지 않기 때문에 청소나 보수 작업 시 추가적인 도구와 방법이 필요합니다.  6. 비용: 유성페인트는 일반적으로 수성페인트보다 가격이 비쌉니다.  따라서, 환경 및 건강에 더 많은 주의를 기울이고자 하는 경우, 유성페인트의 사용을 고려해 볼 필요가 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      54.95 ms /    80 runs   (    0.69 ms per token,  1456.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.57 ms /    11 tokens (   23.51 ms per token,    42.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4195.33 ms /    79 runs   (   53.11 ms per token,    18.83 tokens per second)\n",
            "llama_print_timings:       total time =    4760.51 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      54.14 ms /    67 runs   (    0.81 ms per token,  1237.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     349.37 ms /    14 tokens (   24.96 ms per token,    40.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3523.64 ms /    66 runs   (   53.39 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =    4226.56 ms /    80 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  훼손과 오염은 물리적인 변화의 유무를 기준으로 구분됩니다. 훼손은 물리적 충격이나 힘을 받아 상태가 변한 것을 말하며, 예를 들어 터짐이나 몰딩이 수정된 경우입니다. 반면에 오염은 물리적인 힘이나 충격으로 인한 변화가 아니라, 녹 오염이나 얼룩과 같은 물질의 부착으로 인해 상태가 변한 것을 의미합니다.\n",
            "  타공하자는 부실한 시공으로 인해 발생할 수 있습니다. 예를 들어, 적절하지 않은 도구로 작업하거나 타공 부위의 크기를 정확히 측정하지 않고 작업하면 타공불량이 발생할 수 있습니다. 이런 경우에는 전문가의 도움을 받아 적절한 도구와 기술을 사용하여 타공을 다시 시공하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     166.40 ms /   213 runs   (    0.78 ms per token,  1280.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     340.62 ms /    16 tokens (   21.29 ms per token,    46.97 tokens per second)\n",
            "llama_print_timings:        eval time =   11395.33 ms /   212 runs   (   53.75 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =   12879.90 ms /   228 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철근콘크리트는 기둥, 보, 내력벽, 바닥 슬라브 등의 주요 구조부가 철근 콘크리트 일체식 구조로 시공되며, 철근은 인장력과 압축력이 매우 강하고, 재료적 특징은 다음과 같습니다.  1. 인장강도: 철근은 인장력에 매우 강하며, 1mm의 철근은 약 5ton의 인장력을 견딥니다. 2. 압축강도: 또한 철근은 압축력에 강하며, 1mm의 철근은 약 120ton의 압축력을 견딥니다. 3. 경량성: 철근은 비교적 경량이어서 운반 및 설치가 용이합니다. 4. 내화성: 철근은 내화성이 뛰어나며, 화재 시 내구성이 유지됩니다. 5. 부식방지성: 철근은 물에 대한 부식성이 낮아 구조물의 내구성을 향상시킵니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      58.85 ms /    85 runs   (    0.69 ms per token,  1444.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.96 ms /    16 tokens (   20.81 ms per token,    48.05 tokens per second)\n",
            "llama_print_timings:        eval time =    4479.98 ms /    84 runs   (   53.33 ms per token,    18.75 tokens per second)\n",
            "llama_print_timings:       total time =    5156.10 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   방염벽지는 실크벽지와 합지벽지와는 다른 종류의 벽지입니다. 실크벽지는 종이벽지 위에 PVC 코팅이 되어 있고, 합지벽지는 종이를 여러 장 겹쳐 만든 벽지입니다. 방염벽지는 화재로부터 벽을 보호하는 역할을 하며, 실크벽지와 합지벽지와는 이 특징에서 다른 종류의 벽지로 분류됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      96.29 ms /   124 runs   (    0.78 ms per token,  1287.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     709.37 ms /    29 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
            "llama_print_timings:        eval time =    6592.72 ms /   123 runs   (   53.60 ms per token,    18.66 tokens per second)\n",
            "llama_print_timings:       total time =    7914.65 ms /   152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 높은 습도가 지속되는 환경에서는 도배지에 곰팡이가 발생할 수 있습니다. 습기가 도배지에 스며들거나 습기로 인해 도배지가 젖은 상태가 지속될 경우, 곰팡이 포자가 공기 중에 퍼져 도배지에 정착할 수 있습니다. 따라서 습기 관리가 중요하며, 습기를 제거하고 적절한 환기를 통해 실내 습도를 조절하는 것이 필요합니다. 또한, 도배지 주변에 습기가 스며들지 않도록 주의해야 합니다. 만약 곰팡이가 발생하였다면, 전문가의 도움을 받아 적절한 조치를 취하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      67.70 ms /    97 runs   (    0.70 ms per token,  1432.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.77 ms /    12 tokens (   21.48 ms per token,    46.55 tokens per second)\n",
            "llama_print_timings:        eval time =    5124.82 ms /    96 runs   (   53.38 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =    5779.44 ms /   108 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      56.55 ms /    79 runs   (    0.72 ms per token,  1397.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.02 ms /    14 tokens (   25.22 ms per token,    39.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4171.74 ms /    78 runs   (   53.48 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =    4857.02 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   모노롱브릭타일은 벽돌의 형태를 살리면서도 노출 콘크리트와 비슷한 분위기를 연출할 수 있는 타일입니다. 이러한 특징으로 전통적인 벽돌 벽보다는 좀 더 현대적이고 세련된 느낌을 연출할 수 있습니다. 또한, 브릭타일의 특성상 튼튼하고 내구성이 좋은 장점이 있습니다. 따라서 외부 벽면이나 실내 벽면에 사용되어 내구성과 디자인을 동시에 고려하는 사람들에게 인기가 있을 수 있습니다.\n",
            "   페인트 상도재는 최종 마감으로 칠하는 페인트로, 주도재와 하도재의 제품을 보호하고 유지보수하는 역할을 합니다. 이러한 기능을 통해 외부 표면에 노출되더라도 열과 기후에 강하며 내구성이 높습니다. 다만, 페인트 상도재는 주도재나 하도재보다 가격이 다소 비쌉니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      53.18 ms /    64 runs   (    0.83 ms per token,  1203.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     112.84 ms /     8 tokens (   14.11 ms per token,    70.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3378.89 ms /    63 runs   (   53.63 ms per token,    18.65 tokens per second)\n",
            "llama_print_timings:       total time =    3851.92 ms /    71 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     178.60 ms /   236 runs   (    0.76 ms per token,  1321.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.51 ms /    13 tokens (   27.19 ms per token,    36.77 tokens per second)\n",
            "llama_print_timings:        eval time =   12640.48 ms /   235 runs   (   53.79 ms per token,    18.59 tokens per second)\n",
            "llama_print_timings:       total time =   14104.02 ms /   248 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   준불연재료는 화재에 저항력을 가진 소재로, 일정 기간 동안 화재에 견딜 수 있는 능력을 지니고 있는 소재를 말합니다. 이러한 소재는 화재 안전규격을 충족시키는 데 사용되며, 화재 발생 시 인명과 재산을 보호하는 데 중요한 역할을 합니다.\n",
            "   유성페인트의 사용은 몇 가지 단점이 존재합니다. 첫째, 유성페인트에는 호흡기나 피부를 통해 체내로 흡수될 수 있는 벤젠, 톨루엔, 자일렌 등의 유해물질이 들어 있기 때문에 장기적으로 노출될 경우 암, 호흡기 질환, 피부 질환 등의 건강 문제를 유발할 수 있습니다. 둘째, 유성페인트는 강한 냄새가 나며, 이는 주변 환경에서 불쾌감을 유발할 수 있습니다. 또한, 유성페인트의 건조 시간이 수성페인트보다 길기 때문에 작업 시간이 더 오래 걸릴 수 있습니다. 마지막으로, 유성페인트는 환경 오염을 일으킬 수 있습니다. 유성페인트의 성분 중 일부는 대기 중에 방출되면 미세먼지나 오존 등의 오염물질을 생성할 수 있습니다. 이러한 이유로 유성페인트를 사용할 때에는 안전하고 적절한 환경에서 사용하고, 호흡기나 피부를 보호하기 위해 마스크 착용과 같은 개인보호구를 착용하는 것이 중요합니다. 또한, 작업 시에는 충분한 환기를 유지하여 공기 중의 유해물질 농도를 줄이는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      74.08 ms /   107 runs   (    0.69 ms per token,  1444.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     350.48 ms /    13 tokens (   26.96 ms per token,    37.09 tokens per second)\n",
            "llama_print_timings:        eval time =    5699.05 ms /   106 runs   (   53.76 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =    6469.25 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      91.39 ms /   114 runs   (    0.80 ms per token,  1247.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     445.28 ms /    19 tokens (   23.44 ms per token,    42.67 tokens per second)\n",
            "llama_print_timings:        eval time =    6081.02 ms /   113 runs   (   53.81 ms per token,    18.58 tokens per second)\n",
            "llama_print_timings:       total time =    7102.97 ms /   132 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   몰딩이 수정되는 환경적 요인은 다양합니다. 햇빛, 습기, 화학물질 또는 다른 외부요인에 노출될 때 수정이 발생할 수 있습니다. 특히, 고온 다습한 환경이나 강한 햇빛에 장기간 노출될 경우 몰딩이 수정될 수 있습니다. 또한, 몰딩이 화학물질이나 다른 외부요인에 노출될 때에도 수정이 발생할 수 있습니다. 이러한 환경적 요인들을 최대한 배제하여 몰딩을 보다 오랫동안 사용할 수 있도록 관리하는 것이 중요합니다.\n",
            "   벽지에 반점이 생겼을 때 유색반점 발생 시기가 벽지시공 후 1년 이내인 경우, 보수작업은 아래와 같이 해야 합니다. 먼저, 이염 방지제를 도포한 후에 개선 벽지로 전면 재시공하는 것이 필요합니다. 반점이 생긴 상태에서 아세톤 용제를 사용하여 함침하는 것은 유색 반점을 확대시키거나 신규 이염이 발생할 우려가 있으므로 추천되지 않습니다. 따라서 반점이 눈에 띄고, 개선이 불가능한 상황이라면 전문가의 도움을 받아야 합니다.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      39.50 ms /    57 runs   (    0.69 ms per token,  1443.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     435.90 ms /    18 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3006.41 ms /    56 runs   (   53.69 ms per token,    18.63 tokens per second)\n",
            "llama_print_timings:       total time =    3666.66 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타공 불량\"은 부실 시공으로 인해 발생하는 문제로, 적절하지 않은 도구로 작업하거나 타공 부위의 크기를 정확히 측정하지 않고 작업하면 발생할 수 있습니다. 이는 건물 구조물의 안정성에 영향을 미칠 수 있으므로 신중한 시공이 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.56 ms /    88 runs   (    0.81 ms per token,  1229.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     436.01 ms /    18 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4690.57 ms /    87 runs   (   53.91 ms per token,    18.55 tokens per second)\n",
            "llama_print_timings:       total time =    5600.32 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      81.57 ms /   116 runs   (    0.70 ms per token,  1422.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.89 ms /    12 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6197.12 ms /   115 runs   (   53.89 ms per token,    18.56 tokens per second)\n",
            "llama_print_timings:       total time =    6913.89 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  다이닝 룸을 고급스럽게 꾸미기 위해서는 먼저 고풍스럽고 정교한 가구를 선택해야 합니다. 다음으로는 크리스탈 조명을 활용하여 고급스러운 분위기를 연출할 수 있고, 풍부한 직물을 사용하여 고급스러움을 강조할 수 있습니다. 또한, 아트워크나 꽃 등을 활용하여 고급스러운 분위기를 연출할 수 있습니다. 이러한 아이템들을 조합하여 다이닝 룸을 고급스럽게 꾸밀 수 있습니다.\n",
            "  아레카 야자는 NASA에서 선정한 공기 정화식물 1위로 알려져 있는데, 포름알데히드, 트리클로로에틸렌, 벤젠 등의 실내 독성 물질인 VOC를 효과적으로 제거하여 공기를 정화하는 데 도움이 됩니다. 또한, 아레카 야자의 잎은 하루에 1리터의 수분을 공기 중으로 방출하여 실내 습도를 높이는 효과가 있습니다. 이를 통해 건강한 실내 환경을 유지하고 독성 물질을 제거하여 실내 공기의 질을 향상시키는 효과가 있다고 알려져 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      91.74 ms /   119 runs   (    0.77 ms per token,  1297.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     351.22 ms /    13 tokens (   27.02 ms per token,    37.01 tokens per second)\n",
            "llama_print_timings:        eval time =    6359.15 ms /   118 runs   (   53.89 ms per token,    18.56 tokens per second)\n",
            "llama_print_timings:       total time =    7307.43 ms /   131 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      64.72 ms /    92 runs   (    0.70 ms per token,  1421.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.61 ms /    12 tokens (   22.05 ms per token,    45.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4893.46 ms /    91 runs   (   53.77 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =    5522.51 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   석고는 습기를 흡수하고 물에 녹는 성질이 있기에 습도가 높으면 변형될 수 있습니다. 따라서 습기가 많은 환경에서는 석고제품을 사용할 때 습기 관리에 유의해야 합니다. 공간 내 습기를 줄이기 위해 제습기를 가동하거나 환기를 통해 적정한 습도를 유지하는 것이 중요합니다. 또한, 공간 내 습기 관리를 위해 제습기를 가동하는 것 외에도 석고제품을 설치할 때 습기 차단재를 적절히 사용하고, 공간 내부의 통풍을 유지하는 것이 도움이 될 수 있습니다.\n",
            "   피스 하자는 벽지 안쪽에 사용된 못이나 다른 작은 물체로 인해 발생하는 하자를 말합니다. 이러한 하자가 심할 경우 도배지가 터질 수 있으므로 주의해야 합니다. 피스 하자를 방지하기 위해서는 못이나 다른 작은 물체를 적절히 사용하고, 도배작업 시에는 피스 하자가 발생하지 않도록 주의해야 합니다. 만약 피스 하자가 발생한 경우, 전문가의 도움을 받아 보수를 진행하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      70.50 ms /    89 runs   (    0.79 ms per token,  1262.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     621.61 ms /    27 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
            "llama_print_timings:        eval time =    4753.81 ms /    88 runs   (   54.02 ms per token,    18.51 tokens per second)\n",
            "llama_print_timings:       total time =    5836.52 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "공동주택의 실내 공기질을 측정할 때, 샘플은 일반적으로 최저층에서 채취합니다. 이는 공동주택의 구조상 최저층이 가장 낮은 위치에 있기 때문에, 실내 공기 중의 농도가 가장 높을 것으로 예상되기 때문입니다. 또한, 최저층에서 채취한 샘플을 통해 공동주택의 실내 공기 상태를 보다 정확히 파악할 수 있기 때문에 이 방법을 채택하고 있습니다.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      92.04 ms /   131 runs   (    0.70 ms per token,  1423.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     442.18 ms /    19 tokens (   23.27 ms per token,    42.97 tokens per second)\n",
            "llama_print_timings:        eval time =    7025.08 ms /   130 runs   (   54.04 ms per token,    18.51 tokens per second)\n",
            "llama_print_timings:       total time =    7991.82 ms /   149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     145.03 ms /   196 runs   (    0.74 ms per token,  1351.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.68 ms /    15 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
            "llama_print_timings:        eval time =   10594.56 ms /   195 runs   (   54.33 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =   11864.61 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  파손된 타일을 교체하는 과정은 다음과 같습니다. 1. 먼저 파손된 타일을 제거합니다. 이 때, 타일 주변을 손상시키지 않도록 조심해야 합니다. 2. 타일이 제거되면, 남은 시멘트나 접착제를 철거하여 바닥을 깨끗하게 닦아줍니다. 3. 새로운 타일을 설치할 위치에 접착제를 발라줍니다.  4. 이후, 새로운 타일을 원하는 위치에 놓고 균등하게 눌러 밀착시킵니다.  5. 타일이 완전히 마르고 밀착된 후, 못 등으로 추가로 고정시켜 줄 수 있습니다.\n",
            "  겨울철 도배를 위한 주의사항을 안내해드리겠습니다.  1. 일정한 온도 유지 추운 겨울에는 도배풀이 얼어버릴 수가 있어 보일러나 전열기를 사용하여 적절한 실내온도를 유지해야 합니다.  2. 고열에 장시간 노출되지 않게 하기 추운 겨울에는 실내 온도를 높이기 위해 전열기를 장시간 사용하는 경우가 많은데, 도배지가 고열에 장기간 노출되면 색상이 변하거나 이음매가 벌어질 수 있습니다.  3. 성급한 환기 자제 도배 시공 직후 냄새를 제거하기 위해 환기를 시키는 것이 보통인데, 춥고 건조한 겨울에 환기를 시키면 도배지가 고르게 건조되지 않아 터질 수가 있어 2일 정도는 창문을 닫아 놓는게 좋습니다.  겨울철에는 온도와 습도에 특히 신경을 써줘야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     171.78 ms /   236 runs   (    0.73 ms per token,  1373.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     351.09 ms /    14 tokens (   25.08 ms per token,    39.88 tokens per second)\n",
            "llama_print_timings:        eval time =   12780.17 ms /   235 runs   (   54.38 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =   14444.20 ms /   249 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     101.41 ms /   128 runs   (    0.79 ms per token,  1262.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.53 ms /    12 tokens (   21.96 ms per token,    45.54 tokens per second)\n",
            "llama_print_timings:        eval time =    6908.53 ms /   127 runs   (   54.40 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    7810.37 ms /   139 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 유성페인트의 사용은 몇 가지 단점이 존재합니다. 첫째, 유성페인트에는 호흡기나 피부를 통해 체내로 흡수될 수 있는 벤젠, 톨루엔, 자일렌 등의 유해물질이 들어 있기 때문에 장기적으로 노출될 경우 암, 호흡기 질환, 피부 질환 등의 건강 문제를 유발할 수 있습니다. 둘째, 유성페인트는 강한 냄새가 나며, 이는 주변 환경에서 불쾌감을 유발할 수 있습니다. 또한, 유성페인트의 건조 시간이 수성페인트보다 길기 때문에 작업 시간이 더 오래 걸릴 수 있습니다. 마지막으로, 유성페인트는 환경 오염을 일으킬 수 있습니다. 유성페인트의 성분 중 일부는 대기 중에 방출돼 미세먼지나 오존 등의 오염물질을 생성할 수 있습니다. 이러한 이유로 유성페인트를 사용할 때에는 안전하고 적절한 환경에서 사용하고, 호흡기나 피부를 보호하기 위해 마스크 착용과 같은 개인보호구를 착용하는 것이 중요합니다. 또한, 환경부는 유성페인트의 위험에 대비해 수성페인트 사용을 권장하고 있습니다.\n",
            "   페인트 보관방법은 남은 페인트의 양에 따라 다릅니다. 만약, 남은 페인트의 양이 적다면 신문이나 헌 옷에 적신 다음 종량제 봉투에 버리는 것이 가능합니다. 남은 페인트 양이 6ml이상 100kg 미만일 경우 페기물 수탁업체를 통해 처리해야 하며, 100kg 이상이라면 구청 환경과에 신고해야 합니다. 신고시 준비해야할 서류는 폐기물처리계획서, 폐기물분석결과서,폐기물수탁확인서 각 1통입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      61.67 ms /    89 runs   (    0.69 ms per token,  1443.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.25 ms /    11 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4758.82 ms /    88 runs   (   54.08 ms per token,    18.49 tokens per second)\n",
            "llama_print_timings:       total time =    5376.89 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      60.08 ms /    73 runs   (    0.82 ms per token,  1215.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     345.09 ms /    14 tokens (   24.65 ms per token,    40.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3907.56 ms /    72 runs   (   54.27 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    4664.22 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   가장 비싼 바닥재로는 대리석 타일이 가장 많이 사용됩니다. 대리석은 자연스러운 아름다움과 내구성으로 유명하며, 고급스러운 분위기를 연출할 수 있습니다. 또한, 그만큼 가격이 높기 때문에 대리석은 비교적 고가의 바닥재로 알려져 있습니다. 하지만 비슷하게, 테라코타 타일, 목재 바닥재, 그리고 대형 석재 또한 비싼 바닥재로 알려져 있습니다.\n",
            "  유광 자기질 타일은 일반적으로 50년 정도의 기대수명을 가지고 있습니다. 이 기간 동안에는 색상과 광택이 유지되며, 견고한 표면을 유지할 수 있습니다. 또한, 유광 자기질 타일은 진열된 공간이나 가정 주방과 같이 상대적으로 낮은 트래픽을 가지는 공간에서 사용될 때 가장 효과적입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      94.44 ms /   116 runs   (    0.81 ms per token,  1228.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     358.07 ms /    15 tokens (   23.87 ms per token,    41.89 tokens per second)\n",
            "llama_print_timings:        eval time =    6244.13 ms /   115 runs   (   54.30 ms per token,    18.42 tokens per second)\n",
            "llama_print_timings:       total time =    7192.20 ms /   130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     110.25 ms /   145 runs   (    0.76 ms per token,  1315.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.26 ms /    12 tokens (   22.19 ms per token,    45.07 tokens per second)\n",
            "llama_print_timings:        eval time =    7832.60 ms /   144 runs   (   54.39 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    8797.81 ms /   156 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   풍수지리를 활용하여 집을 꾸밀 때 주의해야 할 점은 다양합니다. 가장 중요한 것은 문의 위치와 가구 배치입니다. 문의 위치는 풍기의 흐름을 조절하는 데 중요한 역할을 하며, 가구 배치는 집의 분위기를 조성하는 데 영향을 미칩니다. 또한, 색상 선택과 식물 배치 역시 풍수지리를 적용할 때 고려해야 할 중요한 요소입니다. 색상은 에너지의 흐름과 관련이 있으며, 식물은 공기를 정화하고 안정감을 가져다줍니다. 따라서 이러한 사항들을 주의하여 집을 꾸밀 때 풍수지리를 효과적으로 활용할 수 있습니다.\n",
            "   스탠드 조명을 선택할 때 주의할 점은 다양합니다. 먼저, 공간의 크기와 목적에 맞는 조명을 선택해야 합니다. 작은 공간에는 밝은 조명이 필요하지만, 큰 공간에는 밝은 조명이 과할 수 있습니다. 또한, 조명의 디자인과 재질을 주의하여 고려해야 합니다. 내부 공간의 분위기와 조명에 맞는 재질을 선택하여 조명의 안정성과 내구성을 고려해야 합니다. 또한, 조명의 에너지 소비량과 전구의 교체 주기 등을 고려하여 경제적인 면을 고려해야 합니다. 마지막으로, 조명의 설치 위치와 방향성, 조명의 조절 가능성, 그리고 주변 환경과 조명의 조화 등을 고려하여 적합한 조명을 선택해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      70.71 ms /    99 runs   (    0.71 ms per token,  1400.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     346.08 ms /    14 tokens (   24.72 ms per token,    40.45 tokens per second)\n",
            "llama_print_timings:        eval time =    5341.60 ms /    98 runs   (   54.51 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    6100.57 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      70.77 ms /    93 runs   (    0.76 ms per token,  1314.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     439.91 ms /    18 tokens (   24.44 ms per token,    40.92 tokens per second)\n",
            "llama_print_timings:        eval time =    5015.00 ms /    92 runs   (   54.51 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    5905.47 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   반점이 1년 이상 지속된 경우, 벽지 속지 내부에 주사기를 사용하여 아세톤 함침 후 건조시키는 방법이 효과적일 수 있습니다. 또한, 도배풀에 혼합하여 반점을 제거하는 시도도 할 수 있지만 1년 이상 지속된 경우 원자색 혹은 수채색 벽지 염료 또는 페인트를 표면으로부터 완전히 제거하기 어려울 수 있습니다. 따라서 반점이 1년 이상 지속된 경우에는 전문가의 조언을 구하는 것이 좋습니다.\n",
            "   불량 도배지를 사용할 경우 도배지의 수명이 단축될 수 있습니다. 불량 도배지는 내구성이 약하고 쉽게 변색되며, 시간이 지남에 따라 도배지가 손상될 수 있습니다. 따라서 도배지의 수명을 연장하기 위해서는 품질이 좋은 도배지를 선택하는 것이 좋습니다. 내구성이 뛰어난 도배지를 사용하면 도배지가 오랜 기간 동안 매력적으로 유지될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      73.99 ms /   104 runs   (    0.71 ms per token,  1405.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     113.80 ms /     8 tokens (   14.22 ms per token,    70.30 tokens per second)\n",
            "llama_print_timings:        eval time =    5589.12 ms /   103 runs   (   54.26 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    6130.04 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      48.39 ms /    57 runs   (    0.85 ms per token,  1177.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.89 ms /    11 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3042.25 ms /    56 runs   (   54.33 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    3653.03 ms /    67 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   평지붕의 단점은 경사지붕에 비해 에너지 손실이 크고, 단열 및 방수를 위한 시공비용이 많이 들며 누수의 위험이 있으며 다른 지붕재보다 수명이 짧은 것이 주요한 단점입니다. 또한, 평지붕은 눈과 물이 쌓일 수 있는 위험이 있으며 물이 효과적으로 배출되지 않아 물이logging될 수 있는 위험 또한 존재합니다. 이러한 문제를 관리하기 위해서는 정기적인 청소 및 유지보수가 필요합니다.\n",
            "   실크벽지의 교체 주기는 일반적으로 5년에서 7년 사이입니다. 그러나 사용 환경 및 유지 관리 상태에 따라 차이가 있을 수 있습니다. 주기적인 청소와 유지보수를 통해 실크벽지의 수명을 연장시킬 수 있으니 주기적인 관리가 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      59.28 ms /    86 runs   (    0.69 ms per token,  1450.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.23 ms /    16 tokens (   22.45 ms per token,    44.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4631.01 ms /    85 runs   (   54.48 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    5328.08 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      75.83 ms /   100 runs   (    0.76 ms per token,  1318.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     116.01 ms /     8 tokens (   14.50 ms per token,    68.96 tokens per second)\n",
            "llama_print_timings:        eval time =    5371.65 ms /    99 runs   (   54.26 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    5959.85 ms /   107 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   경량철골구조는 주로 주택, 창고, 농자재 등에 사용되며, 약 1.5~3mm 두께의 철골로 이루어져 있습니다. 이러한 경량철골구조는 주로 파이프, C형 채널, LEB 자재 등을 사용하여 건축물을 구성하는 구조체입니다. 이러한 구조물은 경제적이면서도 강도가 뛰어나기 때문에 많은 건물에서 사용됩니다.\n",
            "   철골구조의 장점은 건물의 외벽이 하중이 걸리지 않아 공간 활용이 용이하고, 고층 건물을 건설할 수 있다는 것입니다. 또한 철골은 높은 강도를 가지고 있어 안정성이 뛰어나며, 시공성이 우수하여 건설 기간을 단축할 수 있는 장점이 있습니다. 또한 철골은 재사용이 가능하고, 화재에 강한 성질을 가지고 있어 안전성이 높다는 점도 장점으로 꼽힙니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      99.46 ms /   138 runs   (    0.72 ms per token,  1387.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     350.53 ms /    16 tokens (   21.91 ms per token,    45.64 tokens per second)\n",
            "llama_print_timings:        eval time =    7473.70 ms /   137 runs   (   54.55 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    8412.39 ms /   153 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      78.45 ms /   100 runs   (    0.78 ms per token,  1274.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     107.45 ms /     7 tokens (   15.35 ms per token,    65.15 tokens per second)\n",
            "llama_print_timings:        eval time =    5351.89 ms /    99 runs   (   54.06 ms per token,    18.50 tokens per second)\n",
            "llama_print_timings:       total time =    5977.62 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   프리케스트콘크리트 구조는 PC라고도 불리며, 건축물의 벽, 슬래브(SLAB), 보 등의 콘크리트 부재를 공장에서 미리 제작하여 현장에서 조립하는 공법입니다. 이는 안정된 환경에서 품질관리와 대량생산이 가능하여 품질 확보 및 원가절감이 가능하며, 현장에서는 일부 구간 RC(철근 콘크리트) 공법과 병행하여 공장 생산 PC 부재와의 연결을 통해 공기 단축이 가능한 장점을 가지고 있습니다. 프리케스트콘크리트 구조는 건축물을 보다 신속하게 건설하고 품질을 관리할 수 있는 방법으로, 현재 건축산업에서 가장 대중적으로 사용되는 건설 방식 중 하나입니다.\n",
            "   조적식 구조는 벽돌 또는 콘크리트 블록을 모르타르로 점착하여 쌓는 구조 방식을 말합니다. 이 방식은 보편적으로 주택 및 작은 상업 시설에서 사용되며 내습, 내구성이 우수하고 내화성이 뛰어나지만, 수평방향의 외력에 상대적으로 취약합니다. 또한, 이 방식은 구조물의 변형을 최소화하기 위해 수평 및 수직 방향으로 보강이 필요하며, 이로써 구조물의 강도를 향상시킬 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      91.82 ms /   131 runs   (    0.70 ms per token,  1426.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     625.70 ms /    27 tokens (   23.17 ms per token,    43.15 tokens per second)\n",
            "llama_print_timings:        eval time =    7105.39 ms /   130 runs   (   54.66 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    8254.80 ms /   157 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   반려동물을 위한 가구로 낮은 높이의 가구와 패브릭 소재의 가구가 선택되는 이유는 두 가지입니다. 먼저, 낮은 높이의 가구를 선택하면 반려동물의 목과 관절을 보호할 수 있습니다. 이는 가구의 다리 부분에 공간이 부족하여 반려동물이 뛰어다니는 습성을 가질 수 있기 때문입니다. 또한, 패브릭 소재의 가구를 선택하면 가죽 소재의 가구보다 세탁이 쉽고 스크래치가 덜 발생할 수 있습니다. 이는 반려동물이 가구를 긁고 훼손하는 것을 방지하여 주인을 보호할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      74.70 ms /    93 runs   (    0.80 ms per token,  1245.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     438.40 ms /    18 tokens (   24.36 ms per token,    41.06 tokens per second)\n",
            "llama_print_timings:        eval time =    5002.88 ms /    92 runs   (   54.38 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =    5934.30 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   건물 내부에서 몰딩 수정을 예방하기 위해서는 주로 사용되는 환경 관리 방법은 습도 관리가 중요합니다. 고습도가 지속된다면 몰딩 소재가 팽창하거나 수축하여 변형될 수 있으므로, 적정한 습도를 유지하는 것이 중요합니다. 또한, 몰딩 주변을 청결하게 유지하고, 주기적으로 먼지나 이물질을 제거하는 것도 환경 관리에서 중요한 부분입니다. 이를 통해 몰딩 수정을 예방할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      50.49 ms /    73 runs   (    0.69 ms per token,  1445.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.80 ms /    15 tokens (   23.99 ms per token,    41.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3909.20 ms /    72 runs   (   54.29 ms per token,    18.42 tokens per second)\n",
            "llama_print_timings:       total time =    4558.18 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      66.35 ms /    87 runs   (    0.76 ms per token,  1311.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.87 ms /    13 tokens (   27.22 ms per token,    36.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4663.88 ms /    86 runs   (   54.23 ms per token,    18.44 tokens per second)\n",
            "llama_print_timings:       total time =    5442.51 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  KMEW 세라믹 지붕재의 단점은 주로 수입품이기 때문에 가격이 비싸다는 점이 있습니다. 또한, 설치가 다소 복잡할 수 있어 전문가의 도움이 필요할 수 있습니다. 또한, 무게가 상대적으로 무겁기 때문에 추가적인 지지 구조물이 필요할 수 있습니다. 이러한 점들을 감안하여 선택할 때에는 설치 및 유지 보수 비용을 고려해야 합니다.\n",
            "  세라믹 타일의 단점은 저온으로 구워내기 때문에 온도 변화에 민감하여 내장용으로만 사용되며, 경도가 상대적으로 약해 충격과 마모에 쉽게 영향을 받는다는 것입니다. 이는 세라믹 타일을 주로 실내나 경치 좋은 공간에서 사용하거나, 건물 건축 시 외부에서 적절한 보호를 받을 수 있는 부위에 사용하는 것을 권장하는 이유이기도 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      74.23 ms /   104 runs   (    0.71 ms per token,  1400.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     105.01 ms /     7 tokens (   15.00 ms per token,    66.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5615.33 ms /   103 runs   (   54.52 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    6162.61 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     114.96 ms /   151 runs   (    0.76 ms per token,  1313.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.36 ms /    11 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
            "llama_print_timings:        eval time =    8138.64 ms /   150 runs   (   54.26 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    9135.89 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   줄퍼티 마감은 석고보드의 이음메 부분을 메꾼 후 1차, 2차로 퍼티를 바르고 마감하는 작업을 의미합니다. 이 작업은 올퍼티 마감보다 저렴하고 간단하게 처리할 수 있는데, 이음메 부분의 배부름 현상이 있을 수 있고, 줄퍼티를 한 부분과 하지 않은 부분 사이에는 질감의 차이가 있을 수 있습니다. 이러한 특성으로 인해 주로 가게, 식당, 공장과 같은 상업 시설에 적합하게 사용됩니다.\n",
            "   액체방수공사는 콘크리트나 모르타르와 같은 표면에 액체 형태의 방수제를 도포하거나 침투시켜 방수 작업을 수행하는 공법입니다. 이 방법은 표면에 방수제를 도포하여 물의 침투를 막는 것뿐만 아니라, 방수제를 혼합한 모르타르를 사용하여 콘크리트 표면에 덧발라 침투를 막는 것으로, 건축물의 내구성과 유지보수를 위해 매우 중요한 작업입니다. 이러한 방수작업은 건물 내부의 공간 및 외부에서의 사용과 노출에 따라 여러 계층의 방수재 및 방수층을 적절하게 조합하여 시공됩니다. 이렇게 자연 현상으로부터 건축물을 보호하고 내구성을 높이는 방수작업은 건축 시 중요하게 고려해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      63.40 ms /    91 runs   (    0.70 ms per token,  1435.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     441.24 ms /    19 tokens (   23.22 ms per token,    43.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4924.05 ms /    90 runs   (   54.71 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    5731.82 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  페인트 하도재 없이 페인트를 바로 칠하는 것은 페인트의 내구성을 감소시키고 도막의 부착력을 약화시킬 수 있습니다. 이는 페인트의 내구 기간을 단축시키고 페인트 도막이 벽면에 고르게 밀착되지 않을 수 있습니다. 따라서 페인트를 바로 칠하기보다는 페인트 하도재를 사용하여 페인트의 내구성과 부착력을 향상시키는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      83.74 ms /   108 runs   (    0.78 ms per token,  1289.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.11 ms /    12 tokens (   22.01 ms per token,    45.44 tokens per second)\n",
            "llama_print_timings:        eval time =    5814.29 ms /   107 runs   (   54.34 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    6619.34 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      55.71 ms /    81 runs   (    0.69 ms per token,  1453.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.26 ms /    12 tokens (   22.19 ms per token,    45.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4345.31 ms /    80 runs   (   54.32 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    4922.21 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   나무재질의 바닥재를 처리하는 방법은 특수 규격 봉투(불연성 폐기물 마대)에 넣어서 배출하는 것이 좋습니다. 특수 규격 봉투를 구입할 수 있는 곳이 제한적이므로, 거주하는 지역의 구청이나 주민센터에서 미리 사전 문의하는 것이 좋습니다. 또한, 5톤 이상의 양은 전문 업체를 통해 수거 및 처리해야 합니다. 만약 바닥재를 재활용하거나 재사용하고 싶다면, 주변 건설업체나 재활용 업체에 문의하여 가능한 방법을 찾을 수 있습니다.\n",
            "   장판 처리방법은 구청이나 주민센터에서 생활폐기물 스티커를 구매한 후 배출해야 합니다. 하지만 장판의 크기에 따라 비용이 다르므로 사전에 크기를 확인하고 구매해야 합니다. 생활폐기물 스티커는 일정한 요금을 지불한 뒤 해당 지자체에서 정한 방법에 따라 처리될 수 있도록 허가를 받을 수 있는 스티커입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     115.10 ms /   152 runs   (    0.76 ms per token,  1320.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.31 ms /    14 tokens (   25.81 ms per token,    38.75 tokens per second)\n",
            "llama_print_timings:        eval time =    8215.11 ms /   151 runs   (   54.40 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    9300.81 ms /   165 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지에 생긴 반점은 주로 석고보드에 함유된 안료나 염료 등의 구성 물질이 도배지에 전이되어 나타난 현상으로 추정됩니다. 이러한 경우, 반점을 제거하기 위해서는 다음과 같은 방법을 시도해볼 수 있습니다.  1. 반점 위에 바인더나 수성프라이머를 도포하여 코팅하고 다시 도배하기  2. 반점이 생긴 석고보드를 부분적으로 잘라내고, 석고보드를 보강 후 재작업하기  3. 석고보드 전체 페인트를 제거하고, 새로 석고보드 페인트를 입혀 재작업하기  위 방법 중 상황에 적합한 방법을 선택하여 반점을 제거하고 도배지를 개선할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      63.44 ms /    90 runs   (    0.70 ms per token,  1418.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.77 ms /     9 tokens (   29.09 ms per token,    34.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4846.71 ms /    89 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5471.20 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   새집증후군의 원인은 휘발성 화학물질에 의한 것으로, 대부분의 경우 포름알데히드가 주 원인입니다. 새로 지은 집에 사용된 건축 자재나 가구 등에 포름알데히드가 사용되어 증상이 발생할 수 있습니다. 포름알데히드는 방부제나 접착제의 원료로 사용되며, 새집증후군 증상을 유발할 수 있는 물질로 알려져 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      58.73 ms /    71 runs   (    0.83 ms per token,  1209.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.29 ms /    14 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3793.46 ms /    70 runs   (   54.19 ms per token,    18.45 tokens per second)\n",
            "llama_print_timings:       total time =    4557.91 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     100.01 ms /   144 runs   (    0.69 ms per token,  1439.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     449.47 ms /    18 tokens (   24.97 ms per token,    40.05 tokens per second)\n",
            "llama_print_timings:        eval time =    7823.09 ms /   143 runs   (   54.71 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    8844.15 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 방청도료 도장 작업은 주로 좁은 부분에는 붓을 사용하고, 넓은 부분은 스프레이를 활용합니다. 보통 방청도료는 2~3회의 도장을 하는 것이 원칙이며, 각각의 도료 종류에 따라 적절한 시간을 두고 완전히 건조된 후에 페인팅 작업을 진행합니다.\n",
            "  콘크리트에 구멍을 뚫으려면 먼저 콘크리트에 사용될 드릴 비트를 선택해야 합니다. 보통 콘크리트에는 코어드릴 또는 해머드릴이 사용되며, 코어드릴은 대부분의 구멍에 적합하고, 해머드릴은 작은 구멍을 뚫기에 이상적입니다. 드릴링 전에 안전모와 안전고글을 착용하고, 깊이와 직경을 정확히 측정한 후 구멍을 뚫어야 합니다. 드릴링 중에는 윤활을 위해 물을 사용하고, 드릴을 사용하기 전에 귀를 보호하기 위해 귀마개나 이어링을 착용해야 합니다. 드릴을 깊이 푹 밀어 넣고 난 후에도 항상 조심해서 드릴을 빼야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     103.46 ms /   118 runs   (    0.88 ms per token,  1140.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     451.92 ms /    17 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
            "llama_print_timings:        eval time =    6330.06 ms /   117 runs   (   54.10 ms per token,    18.48 tokens per second)\n",
            "llama_print_timings:       total time =    7533.63 ms /   134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      57.41 ms /    84 runs   (    0.68 ms per token,  1463.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     352.75 ms /    16 tokens (   22.05 ms per token,    45.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4552.98 ms /    83 runs   (   54.86 ms per token,    18.23 tokens per second)\n",
            "llama_print_timings:       total time =    5224.49 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   실내 식물을 효과적으로 가꾸려면 먼저 자신이 가진 공간의 조명과 습도를 고려하여 적합한 식물을 선택해야 합니다. 고 산소 생산량을 가진 식물인 '스킨답텐'과 '벤자민 무림'은 대표적인 공기 정화식물 중 하나인데요. 또한, 간단한 관리와 높은 내구성을 가진 '스네이크 플랜트'나 '스파티필럼' 같은 관리가 쉬운 식물을 선택하는 것이 좋습니다. 이러한 요소를 고려하여 적절한 식물을 선택하면 효과적으로 실내 식물을 가꾸어 나갈 수 있을 것입니다.\n",
            "  인테리어에서 가장 많이 사용되는 도배재료는 페인트입니다. 페인트는 경제적이고 색상을 다양하게 선택할 수 있어 인기가 많습니다. 또한, 페인트는 작은 공간에 사용해도 시각적으로 넓어보이는 효과를 줄 수 있어 시공이 비교적 간편합니다. 이러한 이유로 페인트는 가장 다재다능하고 인기 있는 도배재료로 사용됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     133.63 ms /   177 runs   (    0.75 ms per token,  1324.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     538.54 ms /    22 tokens (   24.48 ms per token,    40.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9619.00 ms /   176 runs   (   54.65 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =   10998.90 ms /   198 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   원목마루는 두께가 약 3mm 이상인 원목으로 만들어진 바닥재로, 평당 가격은 20만원에서 30만원 사이입니다. 이 바닥재는 열전도율이 매우 높아 난방 효율이 우수하며, 아름다운 겉면과 좋은 쿠션감을 가지고 있습니다. 그러나 습기에 취약하고 표면이 두꺼워 온돌에 시공할 경우 갈라질 수 있는 점에 유의해야 합니다.  \n",
            " 롱브릭타일은 모노롱브릭타일이라고도 불리며, 전통적인 벽돌의 형태를 가진 시멘트 벽돌과는 다르게 더 긴 형태를 가진 타일입니다. 이러한 형태로 와이드 벽돌로도 불리며, 노출 콘크리트와 유사한 분위기를 연출할 수 있습니다. 따라서, 현대적이고 독특한 디자인을 선호하는 사람들 사이에서 인기가 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      98.14 ms /   127 runs   (    0.77 ms per token,  1294.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     363.35 ms /    16 tokens (   22.71 ms per token,    44.03 tokens per second)\n",
            "llama_print_timings:        eval time =    6888.89 ms /   126 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    7868.39 ms /   142 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     124.34 ms /   172 runs   (    0.72 ms per token,  1383.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.32 ms /    16 tokens (   22.46 ms per token,    44.53 tokens per second)\n",
            "llama_print_timings:        eval time =    9348.27 ms /   171 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =   10453.21 ms /   187 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   침실을 아늑하게 꾸미기 위해서는 부드러운 조명, 포근한 이불, 그리고 나무 가구를 활용하는 것이 좋습니다. 또한 침실에는 개인적인 취향이 반영될 수 있는 작은 소품과 감각적인 조명을 활용하여 포인트를 주는 것도 좋은 방법입니다. 예를 들어, 식물을 배치하거나 개인이 선호하는 색상의 소품을 활용하는 것으로도 아늑한 분위기를 조성할 수 있습니다. 또한 드레스룸이나 수납 공간을 충분히 마련하여 침실을 깔끔하게 정리하는 것도 중요합니다.침실을 아늑하게 만들기 위해서는 부드러운 조명, 포근한 이불, 그리고 나무 가구를 활용하는 것이 좋습니다.\n",
            "   아이가 있는 집을 꾸밀 때 고려해야 할 안전 요소는 다양합니다. 우선, 날카로운 가구나 소품을 배치하지 않도록 주의해야 합니다. 또한, 계단이 있는 경우에는 안전 가드를 설치하여 아이가 미끄러지는 사고를 방지해야 합니다. 의류나 이불 등에도 부착된 장식품이 없는지 확인해야 하며, 무거운 가구나 장식품은 벽면에 적절히 고정하여 아이가 만지거나 넘지 않도록 주의해야 합니다. 또한, 커튼이나 카펫 등은 아이의 목이나 손에 감기지 않도록 주의해야 합니다. 아이가 떨어뜨릴 수 있는 물건이 없는지 확인하고, 뜨거운 물질이나 화재 요소는 아이의 손에 닿지 않도록 주의해야 합니다. 마지막으로, 아이가 놀기 편안한 공간을 마련하기 위해 안전을 고려하여 가구 배치 및 장식품을 설치하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     119.38 ms /   160 runs   (    0.75 ms per token,  1340.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     352.27 ms /    16 tokens (   22.02 ms per token,    45.42 tokens per second)\n",
            "llama_print_timings:        eval time =    8687.71 ms /   159 runs   (   54.64 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    9771.65 ms /   175 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     105.32 ms /   138 runs   (    0.76 ms per token,  1310.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     367.82 ms /    15 tokens (   24.52 ms per token,    40.78 tokens per second)\n",
            "llama_print_timings:        eval time =    7481.63 ms /   137 runs   (   54.61 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    8530.31 ms /   152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  컬러매치를 위해서는 대비 컬러와 조화 컬러를 활용하는 것이 중요합니다. 주요 색상과 보조 색상을 조합하여 공간의 분위기를 조절하고, 색상의 밝고 어두운 정도를 고려하여 조화로운 매치를 만들어야 합니다. 또한, 특정 색상을 강조하는 방법으로 액센트 컬러를 활용하는 것도 효과적입니다. 예를 들어, 액센트 벽지나 소품, 조명 등을 활용하여 공간에 포인트 컬러를 주는 것이 한가지 팁입니다. 또한, 공간의 크기나 형태에 따라 적합한 컬러 스키마를 선택하는 것도 중요합니다. 마지막으로, 실제로 카탈로그나 색깔 샘플을 이용하여 실제 공간에 어떻게 보일지 미리 시뮬레이션하는 것이 도움이 될 수 있습니다.\n",
            "   복도나 협소한 공간을 확장시키기 위해서는 몇 가지 방법을 활용할 수 있습니다. 먼저, 큰 거울을 사용하여 공간을 시각적으로 확장시킬 수 있습니다. 거울은 반사 효과로 공간을 확장시켜주는데, 특히 광택이 도는 표면의 거울을 사용하면 더욱 효과적입니다. 또한, 밝은 컬러의 벽지나 가구를 활용하여 공간에 활기를 불어넣을 수 있습니다. 밝은 색상은 공간을 확장시키고, 환한 분위기를 연출해 협소한 공간을 보다 넓어 보이게 만들어줍니다. 마지막으로, 슬림한 디자인의 가구를 선택하여 협소한 공간에 적합한 가구를 활용하여 쾌적한 분위기를 조성할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      84.22 ms /   114 runs   (    0.74 ms per token,  1353.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     636.34 ms /    26 tokens (   24.47 ms per token,    40.86 tokens per second)\n",
            "llama_print_timings:        eval time =    6182.50 ms /   113 runs   (   54.71 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    7341.85 ms /   139 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  그라스울 보온판은 우수한 흡음 성능을 가지고 있어서, 소음을 줄이고 공간의 음향 환경을 개선하는 데 효과적입니다. 이 제품은 대부분의 빈틈이 밀폐되어 있고, 각 재료 간의 접착력이 우수하기 때문에 외부 소음이나 진동을 효과적으로 차단할 수 있습니다. 또한, 그라스울은 가벼운 유리섬유로 만들어져 있어서 부드러운 느낌을 주며, 공간을 부드럽게 만들어주는 역할을 합니다. 따라서 실내 소음을 줄이고 쾌적한 환경을 조성하는 데 도움이 됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.18 ms /    99 runs   (    0.77 ms per token,  1299.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     526.73 ms /    22 tokens (   23.94 ms per token,    41.77 tokens per second)\n",
            "llama_print_timings:        eval time =    5352.77 ms /    98 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    6340.57 ms /   120 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "미네랄울 보온판은 고속 회전원심공법으로 제조되는 것이 특징입니다. 이 방법은 섬유질의 원료를 사용하여 보온판의 섬유 구조를 형성하는데, 고속으로 회전하면서 원심력을 이용하여 섬유를 고정시킵니다. 그 결과, 미네랄울 보온판은 고속 회전원심공법의 사용으로 인해 섬유 구조가 균일하게 형성되어 높은 성능을 발휘할 수 있습니다.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      54.55 ms /    77 runs   (    0.71 ms per token,  1411.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.06 ms /    14 tokens (   25.43 ms per token,    39.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4134.44 ms /    76 runs   (   54.40 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    4804.10 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      65.66 ms /    79 runs   (    0.83 ms per token,  1203.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.66 ms /    15 tokens (   23.84 ms per token,    41.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4237.32 ms /    78 runs   (   54.32 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    5046.30 ms /    93 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   일반적으로 도배작업 이후 필름 시공을 권장합니다. 도배 이후 필름을 시공하는 것이 일반적이며, 이는 벽지 위에 붙은 필름의 부착력이 떨어질 수 있기 때문이며 미관상에서도 호불호가 갈리기 때문입니다. 그러나 시공 조율이 어려울 경우, 순서를 바꿔서 진행하는 것도 가능합니다.\n",
            "  낡은 목재 가구의 흠집을 가리는 것은 목재 펜스틱으로 채우고, 이후에 같은 색상의 나무 왁스로 마무리하는 것이 좋습니다. 이렇게 하면 목재의 아름다움을 되살리고, 가구를 더욱 아름답게 보존할 수 있습니다. 또한, 목재 가구에 대한 자세한 정보는 전문가의 조언을 구하는 것도 좋은 방법입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.24 ms /   101 runs   (    0.71 ms per token,  1417.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     352.23 ms /    15 tokens (   23.48 ms per token,    42.59 tokens per second)\n",
            "llama_print_timings:        eval time =    5457.32 ms /   100 runs   (   54.57 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    6213.83 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      87.20 ms /   111 runs   (    0.79 ms per token,  1272.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.45 ms /    16 tokens (   22.59 ms per token,    44.27 tokens per second)\n",
            "llama_print_timings:        eval time =    6013.60 ms /   110 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    6948.35 ms /   126 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   입구나 복도에 사용할 페인트는 내구성이 뛰어나고 세정이 쉬운 것이 중요합니다. 또한, 페인트는 방수성이 있어야 하며, 청색 또는 검정색과 같은 진한 색상을 선택하는 것이 좋습니다. 이러한 특징을 가진 페인트는 유성 페인트나 수성 페인트 중에서 선택할 수 있습니다. 유성 페인트는 특히 내수성이 강하며 청색 또는 검정색과 같은 진한 색상을 제공하므로 좋은 선택지가 될 수 있습니다.\n",
            "   입구나 복도를 환영적으로 꾸미기 위해서는 몇 가지 간단한 방법을 활용할 수 있습니다. 우선, 따뜻한 조명을 사용하여 분위기를 조명해 주세요. 또한, 스토리지 솔루션을 활용하여 깔끔하고 정리된 인상을 주는 동시에 공간 활용을 늘릴 수 있습니다. 그리고 마지막으로, 공간을 개성있게 만들어줄 수 있는 작은 개인적 요소들을 추가하는 것도 좋은 방법입니다. 사진, 인사말, 예쁜 식물 등을 활용하여 집 안에서만 보이는 공간이 아닌 외부에 있는 입구나 복도에도 개인적인 터치를 느낄 수 있도록 하세요.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      59.20 ms /    86 runs   (    0.69 ms per token,  1452.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     440.18 ms /    18 tokens (   24.45 ms per token,    40.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4635.82 ms /    85 runs   (   54.54 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    5412.94 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      82.13 ms /   105 runs   (    0.78 ms per token,  1278.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     453.13 ms /    19 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5668.25 ms /   104 runs   (   54.50 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    6665.62 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지가 먼지나 연기에 노출되면 오염이 발생할 수 있습니다. 특히 연기는 도배지에 오염을 일으킬 수 있으며, 특히 담배 연기는 도배지에 얼룩을 남길 수 있습니다. 또한, 먼지나 연기가 도배지에 머무르거나 축적되면 오염이 발생할 수 있습니다. 따라서 주기적인 청소 및 관리로 도배지의 오염을 방지하는 것이 좋습니다.\n",
            "  습도가 높으면 환경이 곰팡이에게 이상적이므로 곰팡이가 빠르게 성장할 수 있습니다. 습기가 오랫동안 유지되면 벽면이나 기타 표면에 곰팡이가 생길 가능성이 높아지므로 습도 관리에 주의를 기울이는 것이 중요합니다.습기를 줄이기 위해서는 제습기를 가동하거나 환기를 통해 실내를 건조하게 만들어야 합니다. 또한, 공간 내 습기를 흡수하기 위해 건조기나 제습기를 사용하는 것도 도움이 될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     142.10 ms /   190 runs   (    0.75 ms per token,  1337.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     363.56 ms /    16 tokens (   22.72 ms per token,    44.01 tokens per second)\n",
            "llama_print_timings:        eval time =   10311.55 ms /   189 runs   (   54.56 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =   11586.29 ms /   205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      70.78 ms /   100 runs   (    0.71 ms per token,  1412.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     355.93 ms /    14 tokens (   25.42 ms per token,    39.33 tokens per second)\n",
            "llama_print_timings:        eval time =    5401.05 ms /    99 runs   (   54.56 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    6159.50 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   방청페인트의 시공방법은 다음과 같습니다. 1. 피도면 정리: 방청페인트를 도장하기 전에 페인트를 도장할 표면을 청소하고 평탄하게 다듬어 줍니다. 먼지나 오염물을 제거하고, 필요하다면 균열이나 결점을 보수합니다. 2. 방청도료 도장: 표면을 광택이 없는 상태로 만들고 나서 첫 번째 층의 방청도료를 도장합니다. 방청도료는 스프레이를 사용하여 균일하게 도포해야 하며, 각 층이 건조한 후에 다음 층이 도장됩니다. 3. 상도작업: 방청도료가 완전히 건조한 후에 마지막으로 상도작업을 수행합니다. 이는 페인트의 내구성과 광택을 높이기 위한 작업으로, 페인트의 표면을 매끈하고 광택있게 마무리해 줍니다.\n",
            "   배관공사 시 통기구를 설치하는 이유는 주로 두 가지입니다. 첫 번째는 악취를 제거하기 위해서입니다. 통기구는 배수관에서 나는 악취를 외부로 배출하여 실내 환경을 개선시킵니다. 두 번째는 배수도의 원활한 기능을 도와주는 것입니다. 통기구를 통해 공기가 완충되어 배수관에서 발생하는 고압을 완화시켜 스스로 자유롭게 흐를 수 있게 해줍니다. 이를 통해 배수관의 누수나 파열 등을 예방할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      61.58 ms /    82 runs   (    0.75 ms per token,  1331.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.94 ms /    12 tokens (   22.50 ms per token,    44.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4394.83 ms /    81 runs   (   54.26 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    5051.31 ms /    93 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      83.46 ms /   115 runs   (    0.73 ms per token,  1377.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     446.06 ms /    17 tokens (   26.24 ms per token,    38.11 tokens per second)\n",
            "llama_print_timings:        eval time =    6248.39 ms /   114 runs   (   54.81 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    7200.95 ms /   131 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   유성발수제의 장점은 물이 소지에 침투하는 것을 근본적으로 막아주어, 동결이나 염에 의한 손상을 예방할 수 있다는 것입니다. 또한, 건물의 외관을 쾌적하게 보존시켜주고, 시간이 지나도 변색이나 오염물질이 쌓이는 것을 방지하여 건물의 외관을 오랜 시간 동안 깨끗하게 유지할 수 있는 것이 장점입니다.\n",
            "   규산질계 침투성 도포 방수공사는 콘크리트 표면에 무기질의 활성 실리카 성분을 포함한 침투성 물질을 도포하여 콘크리트의 간극이나 공극에 침투시켜 수밀하게 만들어 방수층을 형성하는 공사입니다. 이 방법은 노출된 외부 콘크리트 표면, 노출된 실내 콘크리트 표면, 외부 제물치장 콘크리트 표면, 실내 제물치장 콘크리트 표면에 적용됩니다. 이를 통해 건물의 내구성과 방수 기능을 향상시키는 효과를 얻을 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      63.15 ms /    84 runs   (    0.75 ms per token,  1330.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     351.18 ms /    13 tokens (   27.01 ms per token,    37.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4511.66 ms /    83 runs   (   54.36 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    5252.84 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      51.54 ms /    68 runs   (    0.76 ms per token,  1319.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     538.88 ms /    21 tokens (   25.66 ms per token,    38.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3640.74 ms /    67 runs   (   54.34 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    4512.42 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있는데, 이는 습기가 몰딩 소재에 스며들거나 습기로 인해 소재가 팽창하거나 수축함에 따른 것입니다. 이러한 변형은 실내 습도 관리나 적절한 소재 선택으로 예방할 수 있습니다. 혹은 이미 변형이 발생했다면 전문가의 도움을 받아 재보수하는 것이 좋습니다.\n",
            "  내부와 외부 온도의 큰 차이로 인해 도배지에 결로가 발생하여 곰팡이가 발생할 수 있습니다. 따라서 온도 관리가 중요하며, 온도 차이를 줄이기 위해 적정한 난방 및 환기가 필요합니다. 만약 곰팡이 발생이 지속된다면, 전문가의 도움을 받아 적절한 대책이 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     111.02 ms /   137 runs   (    0.81 ms per token,  1234.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     360.91 ms /    15 tokens (   24.06 ms per token,    41.56 tokens per second)\n",
            "llama_print_timings:        eval time =    7411.67 ms /   136 runs   (   54.50 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    8493.38 ms /   151 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      86.95 ms /   117 runs   (    0.74 ms per token,  1345.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     447.14 ms /    17 tokens (   26.30 ms per token,    38.02 tokens per second)\n",
            "llama_print_timings:        eval time =    6352.99 ms /   116 runs   (   54.77 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    7348.29 ms /   133 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 소품을 선택할 때 주의해야 하는 요소는 다양합니다. 먼저, 전체적인 분위기와 조화로움을 고려해야 합니다. 소품이 방의 분위기를 가로막거나 어울리지 않는 경우 분리된 느낌을 줄 수 있으므로 조화롭게 어울리는 아이템을 선택해야 합니다. 또한, 크기와 색상을 조절하여 공간에 균형을 유지하는 것이 중요합니다. 크기가 너무 큰 소품은 공간을 가로막을 수 있고, 너무 작은 소품은 무력할 수 있으므로 적절한 크기를 유의해야 합니다. 또한, 감각적인 디자인과 자연스러운 배치는 공간을 아름답게 만드는 데 중요한 역할을 합니다. 따라서 이러한 요소들을 고려하여 소품을 선택해야 합니다.\n",
            "  활기차운 주방을 꾸미기 위해서는 몇 가지 요소를 추가하는 것이 좋습니다. 첫째로, 활기찬 분위기를 위해 밝은 컬러 스키마와 함께 따뜻한 조명을 활용할 수 있습니다. 또한, 식물을 배치하여 자연의 느낌을 더할 수 있습니다. 더불어, 개방형 수납을 활용하여 주방 내의 물건들을 공개적으로 보여주며, 주방 가전제품이나 주방용품의 색상을 활기차게 선택할 수 있습니다. 이러한 조치들을 통해 주방을 활기차게 꾸밀 수 있을 것입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      84.26 ms /   109 runs   (    0.77 ms per token,  1293.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     362.47 ms /    15 tokens (   24.16 ms per token,    41.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5877.20 ms /   108 runs   (   54.42 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    6771.70 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.22 ms /   106 runs   (    0.72 ms per token,  1390.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     377.10 ms /    16 tokens (   23.57 ms per token,    42.43 tokens per second)\n",
            "llama_print_timings:        eval time =    5746.35 ms /   105 runs   (   54.73 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    6575.68 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   초배지는 벽의 표면을 매끄럽게 만들기 위한 목적으로 사용되며, 페인트와 달리 물기에 반응하여 강력하게 접착됩니다. 따라서 초배지를 바른 후 페인트를 칠하려고 하면 페인트가 제대로 벽에 밀착되지 않을 수 있습니다. 이는 페인트가 벽에 고르게 발리지 못하게 되어 시각적으로도 좋지 않을 수 있습니다. 때문에 초배지로 처리된 벽에 페인트를 직접 칠하는 것보다는 페인트용 밑트러기를 사용하여 페인트를 고르게 발리는 것이 좋습니다.\n",
            "   속건형 유성 발수제는 유성계 발수제로 도장 후 용제가 증발되면서 발수효과를 발휘하는 것을 의미합니다. 이러한 발수제는 보통 용융형 발수제와는 다르게 도장 후 발수 효과가 나타나는 제품으로, 특히 수성 도료와 함께 사용할 때 우수한 발수 성능을 발휘하는 특징을 가지고 있습니다. 이러한 발수제는 건축물의 외벽 또는 콘크리트 표면과 같은 다양한 재료에 사용될 수 있으며, 우수한 방수 특성을 보유하고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      93.25 ms /   122 runs   (    0.76 ms per token,  1308.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.13 ms /    36 tokens (    8.00 ms per token,   124.94 tokens per second)\n",
            "llama_print_timings:        eval time =    6598.58 ms /   121 runs   (   54.53 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    7489.33 ms /   157 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   벽지에 반점이 생겼을 때, 벽지 아세톤 용제 함침 방법을 사용할 경우 벽지 재시공이 필요한 상황입니다. 이 방법은 벽지에 반점이 생겼을 때, 알코올 또는 아세톤 용제를 사용하여 함침하는 방법이며, 이는 벽지 시공 전에 필요한 단계입니다. 벽지 아세톤 용제 함침 방법은 벽지의 재시공을 결정짓는 방법 중 하나로, 반점이 생겨난 이유를 파악하는 데 도움이 됩니다. 따라서 벽지에 반점이 생겼을 경우, 전문가의 도움을 받아 적절한 조치를 취하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      58.59 ms /    85 runs   (    0.69 ms per token,  1450.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =      75.43 ms /     5 tokens (   15.09 ms per token,    66.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4588.79 ms /    84 runs   (   54.63 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    4994.39 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      61.88 ms /    86 runs   (    0.72 ms per token,  1389.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.54 ms /    11 tokens (   24.59 ms per token,    40.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4634.35 ms /    85 runs   (   54.52 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    5265.73 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   석구조는 주로 석재로 쌓아 만든 건축물을 의미합니다. 이러한 구조는 주로 궁전, 불사, 탑비 등의 고건물에서 볼 수 있습니다. 하지만 석구조는 풍압력, 지진력, 그리고 기타 인위적인 횡력에 대해 극히 취약하기 때문에 고층 건물에는 부적합합니다. 따라서 고층 건물을 건설할 경우에는 보강구조가 필요합니다.\n",
            "   기둥-보 구조 방식은 건물을 지탱하는 구조물을 기둥(천정을 받치는 세로 구조물)과 보(지지하는 수평 구조물)의 결합을 통해 구현하는 건축 방식입니다. 이 방식은 주로 상업 건물이나 대규모 주택 등에서 사용되며, 과거에는 통나무 구조에서 파생되었지만 현재는 전형적인 플랫폼 구조와 결합하여 사용되기도 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      77.94 ms /   103 runs   (    0.76 ms per token,  1321.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.66 ms /    11 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
            "llama_print_timings:        eval time =    5568.31 ms /   102 runs   (   54.59 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    6317.83 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      66.34 ms /    92 runs   (    0.72 ms per token,  1386.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.18 ms /    12 tokens (   22.35 ms per token,    44.75 tokens per second)\n",
            "llama_print_timings:        eval time =    4966.02 ms /    91 runs   (   54.57 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    5611.67 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   원목마루의 단점은 주로 비용 측면에서 언급됩니다. 원목마루는 다른 바닥재에 비해 비용이 비싸며, 특히 실내 습기나 온습도 변화에 쉽게 영향을 받기 때문에 유지 보수 비용 또한 높을 수 있습니다. 또한, 원목은 특히 습기에 민감하기 때문에 습기에 노출될 경우 변형이나 손상의 우려가 있습니다. 따라서 실내 환경이나 예산 등을 고려할 때 원목마루를 선택할 때 고려해야 하는 단점들입니다.\n",
            " 도배지를 처리하는 방법 중 하나는 폐기물 스티커를 부착하는 것입니다. 이 스티커는 동사무소, 편의점, 일반 슈퍼 등에서 구매할 수 있습니다. 또한, 아파트의 경우에는 경비실에 비치되어 있을 수 있으니 해당 시설의 담당자나 관리사무실에 문의하여 얻을 수도 있습니다. 폐기물을 적절히 처리함으로써 환경을 보호하고 깨끗한 공간을 유지할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      95.95 ms /   122 runs   (    0.79 ms per token,  1271.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     358.15 ms /    14 tokens (   25.58 ms per token,    39.09 tokens per second)\n",
            "llama_print_timings:        eval time =    6609.56 ms /   121 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    7578.39 ms /   135 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     100.21 ms /   131 runs   (    0.76 ms per token,  1307.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.76 ms /    13 tokens (   27.52 ms per token,    36.34 tokens per second)\n",
            "llama_print_timings:        eval time =    7092.58 ms /   130 runs   (   54.56 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    8090.01 ms /   143 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   마감재의 하자 여부를 판단하기 위해서는 몇 가지 요소를 고려해야 합니다. 첫째로는 설계도서와의 일치 여부가 있습니다. 마감재가 설계도서에 명시된 내용과 일치하는지 확인해야 합니다. 둘째로는 기능상의 문제, 예를 들어 마감재가 쉽게 파손되거나 사용상의 문제가 있는지를 확인해야 합니다. 그 다음으로는 미관상의 문제 여부도 중요합니다. 마감재의 외관이나 마감재들 간의 조화가 보존되었는지 확인해야 합니다. 마지막으로, 안전상의 문제 여부도 고려해야 합니다. 마감재가 안전에 영향을 미치는 문제가 있는지를 확인하고 조치해야 합니다.\n",
            "   새집증후군을 예방하는 방법은 목재 가구나 건축자재 등에 사용된 화학물질을 최소화하는 것이 중요합니다. 포르말린이 사용되지 않은 목재 가구를 선택하고, 휘발성 유기화합물을 방출하는 방향제 및 화학물질 함유 제품을 사용하지 않도록 주의해야 합니다.  또한 실내 흡연을 피하고, 공기 청정식물을 키우며, 실내 환기를 자주 시키는 것도 중요한 예방 방법입니다. 공기 청정기를 사용하여 공기 중의 유해 물질을 제거하는 것도 도움이 될 수 있습니다. 또한 주거 공간이나 사무실의 습도와 온도를 적절히 유지하여 건강한 환경을 유지하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      62.54 ms /    90 runs   (    0.69 ms per token,  1439.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.21 ms /    10 tokens (   25.72 ms per token,    38.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4847.92 ms /    89 runs   (   54.47 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5465.75 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   강마루 바닥재의 장점은 다양합니다. 먼저, 강마루는 다른 바닥재에 비해 열전도율이 높아서 난방 효율이 뛰어나며, 동시에 심미성이 뛰어나고 사계절이 있는 우리 기후에 적합하다는 점이 있습니다. 또한 강마루는 유지보수가 간편하고 내구성이 뛰어나서 오랫동안 사용할 수 있는 것도 장점 중 하나입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      78.56 ms /   103 runs   (    0.76 ms per token,  1311.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     446.13 ms /    17 tokens (   26.24 ms per token,    38.11 tokens per second)\n",
            "llama_print_timings:        eval time =    5566.75 ms /   102 runs   (   54.58 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    6508.27 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  새집증후군을 예방하기 위해 창문을 열어 환기하는 것은 중요한 예방조치 중 하나입니다. 신축이나 리모델링 후 휘발성 유기물질이 발생할 수 있으며, 이는 실내 공기를 오염시키고 건강 문제를 유발할 수 있습니다. 따라서 창문을 열어 자연 환기를 유도하는 것이 도움이 됩니다. 또한, 실내 식물을 통해 공기 중의 유해물질을 흡수하는 데에 도움이 되므로, 생활 속에서 자연스러운 방법으로 공기를 정화하는 것도 좋은 선택입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      64.86 ms /    87 runs   (    0.75 ms per token,  1341.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     354.92 ms /    14 tokens (   25.35 ms per token,    39.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4711.89 ms /    86 runs   (   54.79 ms per token,    18.25 tokens per second)\n",
            "llama_print_timings:       total time =    5458.02 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      92.88 ms /   124 runs   (    0.75 ms per token,  1335.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.93 ms /    16 tokens (   22.50 ms per token,    44.45 tokens per second)\n",
            "llama_print_timings:        eval time =    6698.61 ms /   123 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    7644.76 ms /   139 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 도배 후 바닥이나 몰딩, 벽지에 붙은 도배풀을 제거하려면 먼저 걸레로 부드럽게 쓸어내야 합니다. 만약 이것만으로 제거되지 않는 경우에는 도배풀 제거제를 사용하여 깨끗하게 닦아내야 합니다. 옷 안에 제거제를 묻힌 후 도배풀이 묻은 부분을 가볍게 문지르고, 다시 걸레로 살짝 닦아내면 됩니다.\n",
            "   옥상 방수용 탄성 에멀전 페인트의 장점은 건조 후 이음매 없이 연속적으로 형성된 도막이 뛰어난 내수성을 가지고 있어 건물의 충격이나 수축과 팽창에도 도막이 갈라지거나 손상되지 않으며, 침수가 장기간 반복되는 옥외폭로 조건에서도 소지 부착성과 내구성을 유지할 수 있는 것입니다. 또한, 이 제품은 탄성과 인장강도를 보유하여 방수성을 유지할 수 있으며, 콘크리트에 우수한 부착력을 가지고 있어 건물의 옥상에 방수 코팅으로 사용하기에 효과적입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      86.02 ms /   122 runs   (    0.71 ms per token,  1418.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     527.90 ms /    21 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_print_timings:        eval time =    6662.89 ms /   121 runs   (   55.07 ms per token,    18.16 tokens per second)\n",
            "llama_print_timings:       total time =    7697.52 ms /   142 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   침하 현상을 최소화하기 위해서는 통나무구조 방식의 건물에서 몇 가지 디테일을 고려해야 합니다. 먼저, 건물의 설계 단계에서부터 침하 현상을 고려하여 적절한 대책을 마련해야 합니다. 예를 들어, 침하 지역을 예상하여 건물의 설계 및 건설 시 이를 고려하여 적절한 방수 시스템을 설치하는 것이 중요합니다. 또한, 침하 현상이 발생할 경우 이를 완화하기 위해 건물 주변의 배수 시스템을 설치하는 것도 고려해야 합니다. 마지막으로, 침하 현상이 발생할 경우 이를 신속히 수리하고 복구하기 위해 전문가의 조언을 구하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     175.98 ms /   237 runs   (    0.74 ms per token,  1346.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     367.25 ms /    14 tokens (   26.23 ms per token,    38.12 tokens per second)\n",
            "llama_print_timings:        eval time =   12947.61 ms /   236 runs   (   54.86 ms per token,    18.23 tokens per second)\n",
            "llama_print_timings:       total time =   14414.15 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MSDS(Material Safety Data Sheet)는 물질안전보건자료로, 화학 물질의 잠재적 위험에 대한 정보와 안전한 취급, 보관 및 폐기에 대한 지침을 담은 문서입니다. MSDS는 작업장 내 화학물질에 대한 유해한 노출로부터 근로자를 보호하기 위해 산업안전보건공단, 환경공단, 미국의 OSHA(산업안전보건국)와 같은 규제 기관에서 요구합니다. MSDS는 화학물질의 유해성, 위험성, 응급조치 요령, 취급 방법 등을 설명한 자료로, 사업주는 MSDS 상의 유해성·위험성 정보, 취급·저장방법, 응급조치요령, 독성 등의 정보를 통하여 사업장에서 취급하는 화학물질에 대한 정보를 얻어 관리하며, 근로자는 직업병이나 재해사고로부터 자신을 예방할 수 있게 됩니다. MSDS는 산업안전보건법에 따라 제조사는 반드시 작성하여야 하며, 각 국가마다 MSDS 양식이 다르지만, 현재는 전세계가 모두 동일한 양식과 체계의 MSDS를 사용하고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      69.36 ms /    85 runs   (    0.82 ms per token,  1225.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     630.80 ms /    25 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4574.81 ms /    84 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5664.68 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   에나멜 계열 페인트를 선택할 때는 주로 내구성과 광택을 고려합니다. 이러한 특징을 가진 페인트는 주로 목재나 금속 등 표면이 잘 녹지 않는 재료에 사용되며, 고열에 가열하여 제작되어 내구성이 강화됩니다. 따라서 실내 공간에서 자주 사용되는 페인트로, 특별히 광택이 필요하거나 내구성이 요구되는 부분에 적합합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      57.81 ms /    83 runs   (    0.70 ms per token,  1435.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     360.57 ms /    14 tokens (   25.76 ms per token,    38.83 tokens per second)\n",
            "llama_print_timings:        eval time =    4467.20 ms /    82 runs   (   54.48 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5163.62 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     176.98 ms /   237 runs   (    0.75 ms per token,  1339.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.19 ms /    15 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
            "llama_print_timings:        eval time =   12909.79 ms /   236 runs   (   54.70 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =   14393.58 ms /   251 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 라돈을 측정하는 방법은 일반적으로 평수와 폭으로 나누어 계산합니다. 평수는 건물의 길이(앞면)를 말하고, 폭은 건물의 넓이(옆면)를 나타냅니다. 따라서 라돈을 계산할 때는 평수와 폭을 합한 후 곱하여 (평수 * 폭) / 2로 나누어 계산합니다. 이렇게 하면 라돈을 정확히 측정할 수 있습니다.\n",
            "   MSDS(Material Safety Data Sheet)는 물질안전보건자료로, 화학 물질의 잠재적 위험에 대한 정보와 안전한 취급, 보관 및 폐기에 대한 지침을 담은 문서입니다. MSDS는 작업장 내 화학물질에 대한 유해한 노출로부터 근로자를 보호하기 위해 산업안전보건공단, 환경공단, 미국의 OSHA(산업안전보건국)와 같은 규제 기관에서 요구합니다. MSDS는 화학물질의 유해성, 위험성, 응급조치 요령, 취급 방법 등을 설명한 자료로, 사업주는 MSDS 상의 유해성·위험성 정보, 취급·저장방법, 응급조치요령, 독성 등의 정보를 통하여 사업장에서 취급하는 화학물질에 대한 정보를 얻어 관리하며, 근로자는 직업병이나 재해사고로부터 자신을 예방할 수 있게 됩니다. MSDS는 산업안전보건법에 따라 제조사는 반드시 작성하여야 하며, 각 국가마다 MSDS 양식이 다르지만, 현재는 전세계가 모두 동일한 양식과 체계의 MSDS를 사용하고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      87.72 ms /   112 runs   (    0.78 ms per token,  1276.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.93 ms /    14 tokens (   25.49 ms per token,    39.22 tokens per second)\n",
            "llama_print_timings:        eval time =    6059.91 ms /   111 runs   (   54.59 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    6989.23 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      52.77 ms /    68 runs   (    0.78 ms per token,  1288.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.84 ms /    10 tokens (   26.88 ms per token,    37.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3639.03 ms /    67 runs   (   54.31 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    4246.42 ms /    77 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 새집증후군을 해결하기 위한 대책으로는 천연 소재를 사용하고 포름알데히드 처리를 하지 않은 자재를 사용해야 합니다. 뿐만 아니라, 신규 주택으로 이사하기 전에는 실내 난방 온도를 30도 이상으로 8시간 정도 유지하여 휘발성 유기물질을 제거하는 것이 좋습니다. 또한, 창문을 열어 자연 환기를 유도하는 것도 도움이 됩니다. 추가로, 실내 식물을 통해 공기 중의 유해물질을 흡수하는 데에 도움이 되므로, 생활 속에서 자연스러운 방법으로 공기를 정화하는 것도 좋은 선택입니다.\n",
            "   소화기에는 여러 종류가 있습니다. 주로 사용되는 소화기로는 ABC 소화기, 분말 소화기, 이산화탄소 소화기 등이 있습니다. 하지만 이외에도 물 소화기, 거품 소화기, 물 분무 소화기 등의 다양한 종류가 있으며, 사용 용도에 따라 적합한 소화기를 선택하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      69.92 ms /    86 runs   (    0.81 ms per token,  1229.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     450.55 ms /    20 tokens (   22.53 ms per token,    44.39 tokens per second)\n",
            "llama_print_timings:        eval time =    4647.97 ms /    85 runs   (   54.68 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    5578.52 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   질석벽지는 아트월이나 현관 입구에 많이 사용되는 벽지 중 하나입니다. 이러한 벽지의 특징은 검정색이며 질감이 있는 것입니다. 이러한 특성으로 인해 고급스러운 분위기를 연출하며, 벽면 보호에도 효과적입니다. 특히 질석벽지는 쉽게 닦일 수 있고 청결함을 유지할 수 있어 현관 입구나 아트월 등에서 많이 활용됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      68.85 ms /    97 runs   (    0.71 ms per token,  1408.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     455.66 ms /    18 tokens (   25.31 ms per token,    39.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5264.49 ms /    96 runs   (   54.84 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    6127.68 ms /   114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      75.46 ms /   100 runs   (    0.75 ms per token,  1325.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     441.63 ms /    18 tokens (   24.53 ms per token,    40.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5377.55 ms /    99 runs   (   54.32 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    6293.82 ms /   117 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 도배지를 붙인 석고보드를 이동시키는 것은 도배지에 훼손을 일으킬 수 있는 위험한 작업입니다. 따라서 석고보드를 이동해야 하는 경우, 도배 작업을 다시 해야 할 수 있습니다. 때문에 석고보드를 이동하기 전에 도배 작업을 다시 하는 것이 좋습니다. 추가로 석고보드를 이동하는 동안에는 도배지가 꽈배기 모양으로 꼬일 수 있으므로 주의가 필요합니다.\n",
            "  건조시간이 충분하지 않으면 도배지가 꼬일 수 있는 이유는 도배지가 완전히 건조되지 않은 상태에서 벽면이 변하거나 수축할 때 발생할 수 있기 때문입니다. 따라서 제조사에서 권장하는 건조기간 동안 도배를 완전히 건조시켜야 합니다. 만약 충분한 건조시간을 주지 않으면, 도배지가 제대로 고정되지 않아 꼬임이 발생할 수 있습니다. 따라서 건조기간 동안에는 온도와 습도를 꾸준히 관리하여 적절한 건조를 보장하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      53.35 ms /    74 runs   (    0.72 ms per token,  1387.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     719.30 ms /    29 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4002.99 ms /    73 runs   (   54.84 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    5044.82 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  폴리에스테르 흡음 단열재는 배수 기능이 있는 제품이기 때문에 주로 욕실이나 주방 등의 습기가 많은 공간에 적합합니다. 이 제품은 물을 흡수하고 물길을 막아주는 역할을 하여, 습기를 제어하는 데 도움이 됩니다. 따라서 습기가 많은 욕실이나 주방 등의 공간에서 효과적으로 사용할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      62.90 ms /    89 runs   (    0.71 ms per token,  1415.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     364.42 ms /    16 tokens (   22.78 ms per token,    43.91 tokens per second)\n",
            "llama_print_timings:        eval time =    4816.88 ms /    88 runs   (   54.74 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    5545.38 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배 후 제조사에서 권장하는 건조시간을 지키지 않으면 도배지가 제대로 건조되지 않아 터짐 하자가 발생할 수 있습니다. 따라서 제조사에서 추천하는 건조시간을 준수하는 것이 매우 중요합니다. 만약 건조시간을 지키지 않을 경우, 터짐 현상이 발생할 수 있으며 이는 도배 시에 따른 부실한 건조로 인해 발생할 수 있습니다. 따라서 제조사에서 권장하는 건조시간을 준수하여 적절한 건조 시간을 확보하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      82.27 ms /   103 runs   (    0.80 ms per token,  1252.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     448.01 ms /    19 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
            "llama_print_timings:        eval time =    5565.00 ms /   102 runs   (   54.56 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    6549.84 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   내단열 방식의 열교 문제는 외단열 시스템에서 발생하지 않는 열교 문제가 내부에서 발생한다는 것입니다. 이로 인해 열이 손실되고, 곰팡이가 발생할 수 있습니다. 또한 내단열 방식은 외단열 시스템에 비해 열저항이 낮아서 온실 효과나 습기 문제에 더 취약할 수 있습니다. 따라서 내단열 방식을 선택할 때에는 이러한 열교 문제와 열저항 문제를 고려하여 적절한 설계 및 시공이 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     147.19 ms /   198 runs   (    0.74 ms per token,  1345.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     525.54 ms /    22 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10797.87 ms /   197 runs   (   54.81 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =   12273.02 ms /   219 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     192.10 ms /   254 runs   (    0.76 ms per token,  1322.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.79 ms /     9 tokens (   28.64 ms per token,    34.91 tokens per second)\n",
            "llama_print_timings:        eval time =   13872.10 ms /   253 runs   (   54.83 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =   15326.62 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지가 찢어진 하자는 터짐 하자로 분류됩니다. 터짐 하자가 발생하는 원인 - 책임소재 - 해결방법에 대해 설명드리겠습니다. 1. 기존 실크 벽지 불완전 제거 원인 : 기존 실크 벽지를 제대로 제거하지 않은 경우 터짐 하자가 발생할 수 있습니다. 책임소재 : 시공자 해결 방법 : 시공사에 연락하여 재시공을 요청할 수 있습니다. 2. 절단 부위 과소 원인 : 도배지 절단 부위가 구조물에 비해 과소하게 절단돼 장력을 이기지 못하고 찢어질 수 있습니다. 책임소재 : 시공자 해결 방법 : 시공사에 연락하여 재시공을 요청할 수 있습니다. 3. 불량 도배지 원인 : 도배지가 불량일 경우 내구성이 약해 찢어질 수 있습니다. 책임소재 : 제조사 해결 방법 : 불량 도배지를 제거하고 교체해야 합니다.\n",
            "   도배지가 찢어진 하자는 터짐 하자로 분류됩니다. 터짐 하자가 발생하는 원인과 책임소재 그리고 해결 방법에 대해 설명드리겠습니다.  1. 기존 실크 벽지 불완전 제거 원인: 기존 실크 벽지를 제대로 제거하지 않으면 새로운 도배지가 제대로 부착되지 않고 터짐 하자가 발생할 수 있습니다. 책임소재: 도배를 시행한 시공자 또는 시공업체 해결 방법: 시공자에게 연락하여 재시공을 요청해야 합니다.  2. 절단 부위 과소 원인: 절단 부위의 크기가 충분하지 않으면 장력을 이기지 못하고 도배지가 찢어질 수 있습니다. 책임소재: 도배작업을 수행한 시공자 또는 시공업체 해결 방법: 시공자에게 연락하여 재시공을 요청해야 합니다.  3. 불량 도배지 원인: 도배지의 품질이 좋지 않거나 불량일 경우 내구성이 약해져 터짐 하자가 발생할 수 있습니다. 책임소재: 도배지를 제조한 제조사 해결 방법: 불량 도배지를 제거하고 품질이 우수한 도배지로 교체해야 합니다.  터짐 하자의 경우 안전을 위해 전문가의 의견을 받아 문제를 신속히 해결하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      46.66 ms /    66 runs   (    0.71 ms per token,  1414.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     446.93 ms /    17 tokens (   26.29 ms per token,    38.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3545.96 ms /    65 runs   (   54.55 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    4263.08 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   면진장치는 지진 발생 시 건물의 토대를 보호해주는 역할을 합니다. 이 장치는 지진으로 인한 지반의 이동을 흡수하여 건물의 토대가 균등하게 변형되지 않도록 방지합니다. 이를 통해 건물의 안전성을 유지하고 지진으로 인한 피해를 최소화하는 역할을 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      63.22 ms /    78 runs   (    0.81 ms per token,  1233.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     363.61 ms /    15 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
            "llama_print_timings:        eval time =    4201.60 ms /    77 runs   (   54.57 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    4994.55 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      52.00 ms /    75 runs   (    0.69 ms per token,  1442.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.21 ms /     9 tokens (   29.47 ms per token,    33.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4029.35 ms /    74 runs   (   54.45 ms per token,    18.37 tokens per second)\n",
            "llama_print_timings:       total time =    4591.27 ms /    83 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 페인트 상도재는 최종 마감으로 칠하는 페인트로, 주도재와 하도재의 제품을 보호하고 유지보수하는 역할을 합니다. 이러한 기능을 통해 외부 표면에 노출되더라도 열과 기후에 강하며 내구성이 높습니다. 다만, 페인트 상도재는 주도재나 하도재보다 가격이 다소 비쌉니다.\n",
            "   강화마루는 저렴한 가격과 시공비로 지은 장점이 있습니다. 또한, 강화마루는 충격과 흠집에 강한 속성을 가지고 있어서 내구성이 좋습니다. 또한 시공, 유지보수, 그리고 철거가 용이하며, 접착 시공 없이 설치할 수 있어서 친환경적이라는 점도 장점으로 꼽힙니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     116.00 ms /   150 runs   (    0.77 ms per token,  1293.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     450.97 ms /    17 tokens (   26.53 ms per token,    37.70 tokens per second)\n",
            "llama_print_timings:        eval time =    8127.37 ms /   149 runs   (   54.55 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    9313.30 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   경질우레탄폼은 우수한 단열효과와 탁월한 압축강도를 가지고 있어 시공이 간단하며, 높은 내부식성과 내수성을 갖추고 있어 다양한 환경에서 사용이 가능합니다. 또한, 경질우레탄폼은 무독성과 친환경적인 소재로써 안전성이 높고, 난연성 및 방염성 재료로서 화재로부터 건물을 보호하는 역할을 합니다.  이러한 특성으로 인해 경질우레탄폼은 건물의 단열재로 선택되어 많은 건축가들과 시공업체에게 인기를 끌고 있습니다. 또한, 경질우레탄폼은 비교적 저렴한 가격으로 구매할 수 있어 경제적인 선택으로 평가받고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      67.15 ms /    97 runs   (    0.69 ms per token,  1444.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.75 ms /    14 tokens (   25.70 ms per token,    38.92 tokens per second)\n",
            "llama_print_timings:        eval time =    5245.75 ms /    96 runs   (   54.64 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    5990.94 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      84.11 ms /   107 runs   (    0.79 ms per token,  1272.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     448.31 ms /    19 tokens (   23.60 ms per token,    42.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5797.38 ms /   106 runs   (   54.69 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    6793.29 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 상도작업은 건축물의 외벽 또는 내부 공간에 방청도료가 완전히 건조된 후, 원하는 색상의 에나멜이나 조합페인트 등을 사용하여 마무리하는 작업입니다. 이러한 과정을 통해 건축물의 외관을 보호하고 미적 가치를 높일 수 있습니다. 만약 무엇이든 믿을만한 완성품을 만들 수 있게 해 주는 전문가의 조언이나 도움이 필요하다면, 상도작업을 전문으로 하는 전문가에게 상담을 받는 것이 좋습니다.\n",
            "  인테리어에서 공간을 넓게 보이도록 하는 방법은 다양한데, 먼저 큰 거울을 사용하여 공간을 확장시킬 수 있습니다. 또한, 밝은 컬러의 벽지나 가구를 선택하여 공간을 환한 느낌으로 만들 수 있습니다. 또한, 열린 책장을 활용하여 공간을 차지하지 않으면서도 책과 장식품을 보관할 수 있는 실용적인 수납 공간을 만들어 공간을 더 넓게 느끼게 할 수 있습니다. 이러한 방법들을 활용하여 작은 공간을 더 넓어 보이도록 꾸밀 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     246.38 ms /   339 runs   (    0.73 ms per token,  1375.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     358.42 ms /    16 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
            "llama_print_timings:        eval time =   18621.66 ms /   338 runs   (   55.09 ms per token,    18.15 tokens per second)\n",
            "llama_print_timings:       total time =   20544.25 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지가 울음 현상을 보일 때, 이는 도배지가 평평하지 않고 국소적으로 볼록하게 튀어나오는 현상을 의미합니다. 울음 현상이 발생하는 주요 원인과 그에 따른 책임소재 및 해결 방법은 다음과 같습니다.  1. **습도가 높은 경우**    - 원인: 습기로 인해 도배지가 부풀어 오르거나 습기가 도배지에 스며들 때 울음 현상이 발생할 수 있습니다.    - 책임소재: 건물의 소유자나 거주자가 습기 관리에 책임이 있습니다.    - 해결 방법: 제습기를 가동하거나 환기를 통해 실내 습도를 적정 수준으로 유지하고, 전문가의 도움을 받아 보수 작업을 진행해야 합니다.  2. **벽면의 손상**    - 원인: 벽면에 손상이 있을 경우 손상 부분을 통해 습기가 유입하여 울음 현상이 발생할 수 있습니다.    - 책임소재: 벽면 손상을 유발한 주체가 책임을 집니다.    - 해결 방법: 손상된 벽을 복원하고 평평하게 균형을 맞춘 후 재작업이 필요하며, 이러한 복원 작업은 전문가의 도움을 받는 것이 좋습니다.  3. **온도의 불안정**    - 원인: 도배지의 팽창과 수축이 반복되면서 울음 현상이 발생할 수 있습니다.    - 책임소재: 거주자가 온도 관리에 책임이 있습니다.    - 해결 방법: 온도를 적정 수준으로 유지하고, 제습기를 가동하여 습도와 온도의 변화를 최소화해야 합니다.  이러한 원인과 그에 따른 책임소재 및 해결 방법을 고려하여 도배지의 울음 현상을 예방하고 적절히 대처할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.61 ms /    94 runs   (    0.76 ms per token,  1312.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     434.42 ms /    17 tokens (   25.55 ms per token,    39.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5064.82 ms /    93 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5958.30 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      40.08 ms /    58 runs   (    0.69 ms per token,  1447.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     366.16 ms /    14 tokens (   26.15 ms per token,    38.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3111.42 ms /    57 runs   (   54.59 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    3706.40 ms /    71 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 실내공기의 측정위치는 사무실 안에서 공기질이 가장 나쁠 것으로 예상되는 2곳 이상에서 측정해야 합니다. 또한, 측정은 사무실 바닥면으로부터 0.9미터 이상 1.5미터 이하의 높이에서 진행해야 합니다. 그러나 사무실 면적이 500제곱미터를 초과하는 경우에는 500제곱미터마다 1곳씩 추가하여 측정지점을 설정해야 합니다.\n",
            "   아파트 도배 평수는 일반적으로 분양 평수의 2.5배를 사용합니다. 이는 일반적인 규모의 아파트 도배 작업에 적용되는 규칙적인 계산 방식입니다. 도배 작업을 위한 재료 및 공사비 등을 산정할 때 유용하게 사용될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      87.65 ms /   113 runs   (    0.78 ms per token,  1289.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.60 ms /    15 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6094.17 ms /   112 runs   (   54.41 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    7023.04 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      84.76 ms /   120 runs   (    0.71 ms per token,  1415.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     362.59 ms /    14 tokens (   25.90 ms per token,    38.61 tokens per second)\n",
            "llama_print_timings:        eval time =    6505.17 ms /   119 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    7358.01 ms /   133 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지에 생기는 얼룩은 다양한 원인에 의해 발생할 수 있습니다. 주로 습기가 도배지에 스며들거나, 공기 중의 먼지나 연기가 도배지에 축적되어 얼룩이 발생할 수 있습니다. 따라서 공간 내 습도를 적정 수준으로 유지하고, 주기적으로 환기를 통해 도배지를 건조하게 유지하는 것이 중요합니다. 또한, 얼룩이 발생하면 즉시 걸레 등을 사용하여 얼룩을 닦아내는 것이 좋습니다. 만약 얼룩이 지워지지 않는다면, 도배지 전체를 교체해야 할 수도 있습니다.\n",
            "   건물 자체의 구조적 결함으로 인해 석고수정이 발생할 수 있습니다. 이는 건물 구조의 불안정함으로 인해 벽이나 천장의 석고보드가 균일하지 않게 변형되는 것을 의미합니다. 일반적인 경우에는 이러한 문제는 건물 주변의 흙이나 기반부의 결함, 또는 지진이나 외부 충격으로 인한 구조적인 변형 등이 원인이 됩니다. 따라서 이러한 경우에는 건물 주변의 토양 구조 및 건물의 설계 및 건설 과정을 면밀하게 검토하여 문제가 발생한 원인을 파악해야 합니다. 해결 방법은 구조적 결함을 우선적으로 해결하고, 석고수정을 보수하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      79.81 ms /    96 runs   (    0.83 ms per token,  1202.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     362.61 ms /    16 tokens (   22.66 ms per token,    44.12 tokens per second)\n",
            "llama_print_timings:        eval time =    5163.52 ms /    95 runs   (   54.35 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    6069.06 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   대리석 타일은 대리석으로 만들어진 타일을 말합니다. 일반적으로 평당 40~50만원의 비용이 소요됩니다. 이러한 타일은 열전도율이 매우 높아 난방비를 절감할 수 있는 장점이 있습니다. 또한, 깔끔한 느낌을 주고 공간을 실제보다 넓게 느끼게 해주는 효과가 있습니다. 하지만 대리석 타일은 시공 난이도가 높은 편이며 비용이 상대적으로 비싼 편이기도 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      97.33 ms /   129 runs   (    0.75 ms per token,  1325.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     347.59 ms /    13 tokens (   26.74 ms per token,    37.40 tokens per second)\n",
            "llama_print_timings:        eval time =    6977.80 ms /   128 runs   (   54.51 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    7940.62 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   외단열 시공 시 외부 환경 조건은 매우 중요합니다. 외단열은 건물의 콘크리트 골조와 외장재 사이에 단열재를 부착하는 방식으로, 단열재가 외부로 노출되기 때문에 환경 조건에 따라 부식 및 손상이 발생할 수 있습니다. 따라서 외단열 시공 시에는 습기, 먼지, 오염물질 등의 외부 요인을 고려해야 하며, 이에 따라 적절한 설계 및 시공이 필요합니다. 외부 환경 조건에 따라 단열재의 재질 및 설치 방법 등을 고려하여 건물을 보다 견고하게 보호할 수 있도록 신중한 계획 및 시공이 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      62.45 ms /    79 runs   (    0.79 ms per token,  1265.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     354.48 ms /    13 tokens (   27.27 ms per token,    36.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4250.79 ms /    78 runs   (   54.50 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    5017.61 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   스탠드 조명은 이동이 가능한 조명으로, 필요에 따라 위치를 자유롭게 변경할 수 있는 휴대용 조명입니다. 주로 실내 공간에서 사용되며, 조명 기능 뿐만 아니라 소품으로서의 역할 또한 함께 합니다. 다양한 디자인으로 제공되며, 이동성이 좋은 것이 장점이지만 작은 공간에는 부적합하며, 불안정하게 설치할 경우 파손될 수 있는 단점도 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      73.17 ms /   107 runs   (    0.68 ms per token,  1462.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     354.07 ms /    15 tokens (   23.60 ms per token,    42.36 tokens per second)\n",
            "llama_print_timings:        eval time =    5788.61 ms /   106 runs   (   54.61 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    6563.71 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      92.64 ms /   119 runs   (    0.78 ms per token,  1284.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     364.34 ms /    14 tokens (   26.02 ms per token,    38.43 tokens per second)\n",
            "llama_print_timings:        eval time =    6440.88 ms /   118 runs   (   54.58 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    7414.75 ms /   132 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   실크벽지의 얼룩을 지우는 방법은 먼저 부드러운 천에 따뜻한 물을 조금 묻힌 후 얼룩이 있는 곳을 가볍게 닦아보세요. 만약 얼룩이 지워지지 않는다면 중성세제나 알코올을 이용하여 얼룩을 제거할 수 있습니다. 하지만, 얼룩이 더욱 심각한 경우 실크벽지를 교체하거나 전문가의 도움을 받는 것이 좋습니다. 왜냐하면 실크벽지는 민감한 소재이기 때문에 무리하게 처리할 경우 손상을 입을 수 있기 때문입니다.\n",
            "   적절하지 않은 설치로 인해 제품의 품질이 영향을 받을 수 있습니다. 예를 들어, 제품의 사용 용도에 맞지 않는 환경이나 방식대로 설치할 경우 내구성이 약해지거나 기능이 제한될 수 있습니다. 또한, 부적절한 설치로 인해 제품의 안전성이 영향을 받을 수 있으며, 사용 시에는 오작동이 발생하거나 원하는 성능을 내지 못할 수도 있습니다. 따라서 제품의 품질을 유지하기 위해서는 적절한 설치 및 사용 용도에 맞는 환경 선택이 중요합니다. 만약 제품에 이미 설치된 상태가 품질이 영향을 받는다고 판단된다면 전문가의 도움을 받아 재설치하거나 적합한 대안을 찾는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      59.75 ms /    86 runs   (    0.69 ms per token,  1439.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     364.71 ms /    15 tokens (   24.31 ms per token,    41.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4654.70 ms /    85 runs   (   54.76 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    5362.33 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   차음재의 차음 성능은 dB 단위의 투과손실로 평가됩니다. 이 값은 100dB에서 시작하여 수치가 클수록 차음 성능이 좋은 재료로 해석됩니다. 투과손실 값이 높은 재료는 소음을 효과적으로 차단하지 못하는 것으로 여겨지며, 값이 낮은 재료는 우수한 차음 성능을 가진 재료로 간주됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      73.07 ms /    90 runs   (    0.81 ms per token,  1231.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     449.82 ms /    17 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4835.49 ms /    89 runs   (   54.33 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    5762.25 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      83.84 ms /   122 runs   (    0.69 ms per token,  1455.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.04 ms /    14 tokens (   25.50 ms per token,    39.21 tokens per second)\n",
            "llama_print_timings:        eval time =    6624.34 ms /   121 runs   (   54.75 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    7466.20 ms /   135 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  공동주택의 실내 공기질을 측정하기 위해서는 최대한 많은 세대에서 시료를 채취하는 것이 좋습니다. 일반적으로는 100세대에서 3세대를 선택하고, 100세대가 증가할 때마다 1세대를 추가하는 방식으로 시료를 채취합니다. 그러나 공동주택의 크기와 구조에 따라 적합한 시료 채취 방법이 달라질 수 있으므로, 전문가의 조언을 구하는 것이 좋습니다.\n",
            "   마감재의 하자 여부를 판단하기 위해서는 몇 가지 요소를 고려해야 합니다. 첫째로는 설계도서와의 일치 여부가 있습니다. 마감재가 설계도서에 명시된 내용과 일치하는지 확인해야 합니다. 둘째로는 기능상의 문제, 예를 들어 마감재가 쉽게 파손되거나 사용상의 문제가 있는지를 확인해야 합니다. 그 다음으로는 미관상의 문제 여부도 중요합니다. 마감재의 외관이나 마감재들 간의 조화가 보존되었는지 확인해야 합니다. 마지막으로, 안전상의 문제 여부도 고려해야 합니다. 마감재가 안전에 영향을 미치는 문제가 있는지를 확인하고 조치해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      90.87 ms /   116 runs   (    0.78 ms per token,  1276.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     454.65 ms /    18 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
            "llama_print_timings:        eval time =    6305.18 ms /   115 runs   (   54.83 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    7343.52 ms /   133 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  실크벽지의 얼룩을 제거하려면 부드러운 천을 물에 적신 후 얼룩이 있는 곳을 가볍게 닦아내세요. 이때 강한 압력을 가하지 않도록 주의하고, 너무 급하게 마찰하지 않도록 주의하세요. 만약 이 방법으로 얼룩이 제거되지 않는다면, 실크벽지의 표면 손상을 막고자 하는 목적으로 설계된 세탁액을 사용하여 조금씩 묻힌 천으로 얼룩을 가볍게 닦아보세요. 그래도 얼룩이 사라지지 않는다면 실크벽지를 교체하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     131.38 ms /   174 runs   (    0.76 ms per token,  1324.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     443.99 ms /    17 tokens (   26.12 ms per token,    38.29 tokens per second)\n",
            "llama_print_timings:        eval time =    9447.40 ms /   173 runs   (   54.61 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =   10719.49 ms /   190 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   페인트 처리 시 페인트의 양에 따라 처리 절차와 방법이 달라질 수 있습니다. 만약 페인트 양이 적다면, 신문이나 헌 옷에 적신 다음 종량제 봉투에 버리는 것이 가능합니다. 그러나 페인트 양이 6ml이상 100kg 미만일 경우, 페기물 수탁업체를 통해 처리해야 하며, 100kg 이상이라면 구청 환경과에 신고해야 합니다. 신고시 준비해야할 서류는 폐기물처리계획서, 폐기물분석결과서,폐기물수탁확인서 각 1통입니다. 만약 페인트가 재사용 가능한 양이라면, 깨끗한 컨테이너에 담아서 보관하고, 장기간 보관 시에는 상판에 날짜와 페인트 종류를 표시하여 보관하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      79.74 ms /   115 runs   (    0.69 ms per token,  1442.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     348.63 ms /    13 tokens (   26.82 ms per token,    37.29 tokens per second)\n",
            "llama_print_timings:        eval time =    6238.93 ms /   114 runs   (   54.73 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    7048.27 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     128.51 ms /   172 runs   (    0.75 ms per token,  1338.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =      98.86 ms /     6 tokens (   16.48 ms per token,    60.69 tokens per second)\n",
            "llama_print_timings:        eval time =    9379.74 ms /   171 runs   (   54.85 ms per token,    18.23 tokens per second)\n",
            "llama_print_timings:       total time =   10300.53 ms /   177 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 건설 산업은 주로 건물이나 다른 시설물을 설계하고 건설하는 일련의 프로세스를 의미합니다. 주로 건축과 토목을 포함하며, 건물을 짓는 것부터 도로, 다리, 터널, 댐 등의 시설물을 건설하는 작업을 포함합니다. 건설 산업은 설계 및 계획, 자재 조달, 건설, 시공, 테스트 및 시정, 그리고 최종적으로 인계 및 유지보수까지의 단계를 거쳐서 진행됩니다. 이러한 일련의 프로세스를 통해 사회 인프라 및 생활 환경을 개선시키고, 경제 성장을 지원하는 중요한 역할을 합니다.\n",
            "   토목은 목재, 철재, 토석 등을 활용하여 도로, 교량, 항만, 제방, 철도, 건물, 상하수도 등을 건설하는 공사를 말합니다. 이는 인프라와 토목 공사를 통해 사회 인프라의 발전과 안정성을 확보하는 데 중요한 역할을 합니다. 토목은 공중건축물에 쓰이는 요소와 건물 지반 구축에 필요한 요소를 모두 포함하고 있습니다. 예를 들어, 도로 건설에 필요한 굴뚝 및 빙하 제거 보호법, 교량 건설에 필요한 교량 건설법, 항만 앞 바다 물결로부터 일정한 벙 있는 공간의 선박인 바다 저류제 등이 있습니다. 또한 상하수도, 무역선, 축지 등에서 사용하는 보강토 사용 법, 다리, 방파제, 댐 등에서 사용하는 컨크리트 사용 법 등이 포함됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      58.66 ms /    77 runs   (    0.76 ms per token,  1312.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.21 ms /    15 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4123.27 ms /    76 runs   (   54.25 ms per token,    18.43 tokens per second)\n",
            "llama_print_timings:       total time =    4855.18 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      72.30 ms /    97 runs   (    0.75 ms per token,  1341.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     367.94 ms /    16 tokens (   23.00 ms per token,    43.49 tokens per second)\n",
            "llama_print_timings:        eval time =    5262.84 ms /    96 runs   (   54.82 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    6066.88 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 제진 구조란 지진이 발생했을 때 건물이 받는 지진 에너지를 최소화하기 위해 설계된 구조를 말합니다. 주로 건물의 기초나 건물 구조물에 충격을 완화시키는 장치 등을 설치하여 지진으로 인한 피해를 최소화하고 건물의 안전성을 높이는데 사용됩니다. 지진 구조는 지진 발생 시 건물의 안전성을 높이는 데 중요한 역할을 합니다.\n",
            "  중목구조 방식은 기본적으로 기중-보 방식과 유사하지만 구조용 목재로 큰 각재를 사용하여 건축하는 방식입니다. 이 방식은 건물 내부 기둥이나 보가 중양이 되어 강도를 높일 수 있다는 것이 특징이며, 이는 건물의 안정성을 향상시키는 데 도움이 됩니다. 중목구조 방식은 전체적으로 부재를 이용하기 때문에 건물이 흔들리는 것을 줄여주고, 건물의 수명을 연장시키는 등 여러 가지 장점을 갖고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      96.94 ms /   122 runs   (    0.79 ms per token,  1258.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     542.90 ms /    24 tokens (   22.62 ms per token,    44.21 tokens per second)\n",
            "llama_print_timings:        eval time =    6573.48 ms /   121 runs   (   54.33 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =    7724.26 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      48.54 ms /    70 runs   (    0.69 ms per token,  1442.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     344.07 ms /    15 tokens (   22.94 ms per token,    43.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3780.45 ms /    69 runs   (   54.79 ms per token,    18.25 tokens per second)\n",
            "llama_print_timings:       total time =    4406.67 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 작은 공간의 홈오피스에 원목사이딩을 사용하는 경우, 단점은 주로 두 가지입니다. 첫 번째로, 원목사이딩은 다른 재료에 비해 비용이 상대적으로 높을 수 있습니다. 특히 작은 공간에서는 이러한 비용이 더 크게 느껴질 수 있습니다. 두 번째로, 원목사이딩은 다른 재료에 비해 설치 및 유지보수가 어려울 수 있습니다. 이는 또한 작은 공간에서 더 크게 나타날 수 있습니다. 따라서 작은 공간의 홈오피스에 원목사이딩을 사용할 때에는 이러한 단점을 고려하여 적절한 대안을 찾는 것이 중요합니다.\n",
            "  작은 공간의 홈오피스에 원목사이딩을 할 때 가장 큰 단점은 비용이 상대적으로 높다는 것입니다. 또한, 원목사이딩은 특히 습기에 민감하기 때문에 습도를 조절하는 데 민감할 수 있습니다. 이로 인해 추가적인 습기 제어 시스템이 필요할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      47.71 ms /    69 runs   (    0.69 ms per token,  1446.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     347.10 ms /    13 tokens (   26.70 ms per token,    37.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3721.47 ms /    68 runs   (   54.73 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    4340.91 ms /    81 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.48 ms /    88 runs   (    0.81 ms per token,  1231.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.03 ms /     9 tokens (   29.34 ms per token,    34.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4738.59 ms /    87 runs   (   54.47 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5478.89 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   알루미늄징크의 단점으로는 시공이 잘못될 경우 울음 현상이 발생하며, 또한 리얼징크보다 비교적 더 비싼 가격이 단점으로 언급됩니다. 이 외에도 알루미늄징크는 다른 금속과의 접촉에 의해 부식이 발생할 수 있어 부식 방지를 위한 추가적인 방법이 필요할 수 있습니다.\n",
            "   아이소핑크의 장점은 습기에 강하고 곰팡이 및 세균 증식을 막을 수 있다는 것입니다. 이 외에도 아이소핑크는 단열재 중에서 열전도율이 가장 낮은 편이며 시공이 간편하다는 점이 있습니다. 추가로 아이소핑크는 가벼워서 운반이 용이하고 내구성이 뛰어나다는 점도 장점으로 꼽힙니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.10 ms /   111 runs   (    0.69 ms per token,  1458.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     442.91 ms /    19 tokens (   23.31 ms per token,    42.90 tokens per second)\n",
            "llama_print_timings:        eval time =    6025.64 ms /   110 runs   (   54.78 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    6909.54 ms /   129 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  겨울철 도배 작업 시 실내 온도를 일정하게 유지해야 하는 이유는 도배 풀이 얼어버릴 수 있기 때문입니다. 따라서 온도를 일정하게 유지하여 도배 풀이 얼어버리는 상황을 방지해야 합니다. 만약 도배 작업 중에 온도가 일정하게 유지되지 않는다면, 도배 풀이 얼어버릴 수 있고 이는 도배 작업의 품질을 떨어뜨릴 수 있습니다. 따라서 실내 온도를 일정하게 유지하여 도배 작업의 품질을 유지하고 좋은 결과를 얻을 수 있도록 해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.04 ms /    89 runs   (    0.80 ms per token,  1252.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.09 ms /    16 tokens (   22.44 ms per token,    44.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4803.19 ms /    88 runs   (   54.58 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    5635.38 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      58.56 ms /    84 runs   (    0.70 ms per token,  1434.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     100.30 ms /     6 tokens (   16.72 ms per token,    59.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4512.67 ms /    83 runs   (   54.37 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =    4951.85 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철골구조는 화재 발생 시 내구성이 약해지며, 이는 건물의 붕괴로 이어질 수 있습니다. 따라서 화재 안전성을 높이기 위해서는 내화재 보강이 필요합니다. 내화재는 화재에 저항성이 있는 소재로, 일정 시간 동안 화재에 견딜 수 있는 능력을 지니고 있습니다. 이를 통해 건물 구조물이 화재로부터 보호되고 안전을 유지할 수 있습니다.\n",
            "     벽돌구조는 건물을 구성하는 벽체와 기초 등을 벽돌과 석회모르타르를 사용하여 쌓는 구조물을 말합니다. 이는 건물을 짓는 데 기본적으로 사용되는 방법으로, 블록, 석재, 타일 등 다양한 재료와 함께 사용되기도 합니다. 이러한 구조는 미관적인 측면 뿐만 아니라 강도와 내구성 면에서도 매우 탁월한 장점을 지니고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      60.66 ms /    84 runs   (    0.72 ms per token,  1384.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =      95.09 ms /     6 tokens (   15.85 ms per token,    63.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4511.18 ms /    83 runs   (   54.35 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    4973.82 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      65.55 ms /    86 runs   (    0.76 ms per token,  1312.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.75 ms /    11 tokens (   24.25 ms per token,    41.24 tokens per second)\n",
            "llama_print_timings:        eval time =    4638.18 ms /    85 runs   (   54.57 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    5324.02 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 석구조는 주로 석재로 쌓아 만든 건축물을 의미합니다. 이러한 구조는 주로 궁전, 불사, 탑비 등의 고건물에서 볼 수 있습니다. 하지만 석구조는 풍압력, 지진력, 그리고 기타 인위적인 횡력에 대해 극히 취약하기 때문에 고층 건물에는 부적합합니다. 따라서 고층 건물을 건설할 경우에는 보강구조가 필요합니다.\n",
            "   기둥-보 구조 방식은 건물을 지탱하는 구조물을 기둥(천정을 받치는 세로 구조물)과 보(지지하는 수평 구조물)의 결합을 통해 구현하는 건축 방식입니다. 이 방식은 주로 상업 건물이나 대규모 주택 등에서 사용되며, 과거에는 통나무 구조에서 파생되었지만 현재는 전형적인 플랫폼 구조와 결합하여 사용되기도 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      42.33 ms /    60 runs   (    0.71 ms per token,  1417.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.23 ms /    13 tokens (   27.63 ms per token,    36.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.17 ms /    59 runs   (   54.70 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    3828.30 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      59.85 ms /    77 runs   (    0.78 ms per token,  1286.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.36 ms /    11 tokens (   24.49 ms per token,    40.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4141.85 ms /    76 runs   (   54.50 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    4801.79 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 포세린 타일의 단점으로는 시공 방법에 따라 하자 발생률이 높을 수 있고, 오염에 취약하다는 점이 있습니다. 또한, 폴리싱된 표면이나 고층에서의 사용에는 적합하지 않을 수 있습니다. 따라서, 실 사용 환경과 시공 방법을 고려해야 합니다.\n",
            "   셀룰로오스의 단점으로는 정밀한 시공능력이 요구된다는 점이 있습니다. 이는 경험이 부족한 시공자나 초보자에게는 시공이 어려울 수 있다는 것을 의미합니다. 또한, 셀룰로오스는 습기에 노출되면 빨리 상할 수 있는 경향이 있기도 합니다. 때문에 적절한 방수 처리와 유지보수가 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      92.74 ms /   115 runs   (    0.81 ms per token,  1239.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     524.99 ms /    21 tokens (   25.00 ms per token,    40.00 tokens per second)\n",
            "llama_print_timings:        eval time =    6226.98 ms /   114 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    7375.31 ms /   135 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      77.92 ms /   101 runs   (    0.77 ms per token,  1296.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.98 ms /    14 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
            "llama_print_timings:        eval time =    5437.16 ms /   100 runs   (   54.37 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =    6291.46 ms /   114 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 욕실을 부드럽게 꾸밀려면 연한 파스텔 컬러와 부드러운 조명이 효과적입니다. 또한, 자연적인 소재로 만들어진 욕실 가구 및 소품을 활용하여 부드러운 느낌을 강조할 수 있습니다. 예를 들어, 목재나 자연 돌재료를 사용한 가구, 식물이 들어간 장식품 등을 활용할 수 있습니다. 또한 플러피한 타월이나 부드러운 샤워 커튼 등을 활용하여 부드러운 감성을 강조할 수 있습니다. 이러한 조합을 통해 욕실을 부드럽게 꾸밀 수 있습니다.\n",
            "   바닥재를 선택할 때 반려동물을 고려하여 쿠션이 있는 바닥재가 적합합니다. 쿠션이 있는 바닥재는 반려동물의 관절에 부담을 주지 않으며, 층간 소음을 줄여주는 효과가 있습니다. 또한, 바닥재의 재질을 선택한다면 미끄러지지 않는 재질을 고르는 것이 좋습니다. 미끄러지지 않는 바닥재는 반려동물이 뛰어다니는 습성을 고려하여 다칠 위험을 줄여주고 다리 관절에 부담을 주지 않습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      43.83 ms /    60 runs   (    0.73 ms per token,  1369.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     360.20 ms /    15 tokens (   24.01 ms per token,    41.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3218.68 ms /    59 runs   (   54.55 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    3843.52 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      79.73 ms /   114 runs   (    0.70 ms per token,  1429.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     358.25 ms /    15 tokens (   23.88 ms per token,    41.87 tokens per second)\n",
            "llama_print_timings:        eval time =    6171.75 ms /   113 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    6991.34 ms /   128 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   팬던트 라이트는 천장에 길게 늘어뜨린 전선을 통해 조명을 제공하는 조명기구입니다. 이러한 조명은 다양한 디자인과 소재로 제공되어 공간에 세련된 분위기를 조성할 수 있습니다. 그러나 청소가 어렵고 전구를 교체하는 것이 어려울 수 있는 단점이 있습니다.\n",
            "  바닥재를 선택할 때 고려해야 할 중요한 요소는 사용 공간의 특성, 가구와의 조화, 편리한 청소 및 유지보수, 내구성 및 방수성입니다. 사용 공간의 특성과 가구와의 조화뿐만 아니라, 바닥재의 색상과 재질을 고려하여 어울리는 조합을 선택하는 것이 중요합니다. 또한, 바닥재의 재질에 따라 청소 및 유지보수가 용이하므로 이 역시 고려해야 합니다. 마지막으로 내구성 및 방수성을 고려하여 바닥재를 선택해야 합니다. 이러한 요소들을 종합적으로 고려하여 바닥재를 선택하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      59.90 ms /    74 runs   (    0.81 ms per token,  1235.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     449.37 ms /    18 tokens (   24.97 ms per token,    40.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3979.89 ms /    73 runs   (   54.52 ms per token,    18.34 tokens per second)\n",
            "llama_print_timings:       total time =    4828.07 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   속건형 유성 발수제의 장점은 건물의 수명을 연장시키는 데 있습니다. 이 제품은 건물의 표면에 도장되어 수분이 침투하는 것을 방지하여 백화현상과 철근의 부식을 방지합니다. 이를 통해 건물의 외관을 보호하고 내구성을 향상시켜 수명을 연장시키는 효과를 얻을 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      96.78 ms /   136 runs   (    0.71 ms per token,  1405.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     362.28 ms /    15 tokens (   24.15 ms per token,    41.40 tokens per second)\n",
            "llama_print_timings:        eval time =    7413.81 ms /   135 runs   (   54.92 ms per token,    18.21 tokens per second)\n",
            "llama_print_timings:       total time =    8342.51 ms /   150 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   주방은 식탁이 있는 다이닝 공간과 음식을 조리하는 조리대에 따라 추천하는 조명이 달라집니다. 식탁 위에는 팬던트 조명을 설치하여 식사하는 사람들 간의 집중도를 높일 수 있습니다. 또한 조리대에는 눈에 피로가 없을 정도로 밝은 조명을 사용하는 것이 좋습니다. 적정 조도는 조리 공간은 200lux를 기준으로 150~300lux, 식탁은 100lux를 기준으로 60~150lux가 적당합니다. 따라서 각 구역에 맞는 적절한 조명을 선택하여 주방 환경을 개선할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      79.51 ms /   105 runs   (    0.76 ms per token,  1320.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     630.61 ms /    26 tokens (   24.25 ms per token,    41.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5699.02 ms /   104 runs   (   54.80 ms per token,    18.25 tokens per second)\n",
            "llama_print_timings:       total time =    6832.88 ms /   130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      40.64 ms /    59 runs   (    0.69 ms per token,  1451.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.45 ms /     9 tokens (   29.27 ms per token,    34.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3141.48 ms /    58 runs   (   54.16 ms per token,    18.46 tokens per second)\n",
            "llama_print_timings:       total time =    3638.76 ms /    67 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   생기 넘치는 식물과 아트워크를 부착할 때 밀풀은 좋은 재료입니다. 밀풀은 도배 작업 시에 주로 사용되며, 접착력이 강하여 식물이나 아트워크를 벽에 안정적으로 부착할 수 있습니다. 또한, 밀풀은 건조 시간이 오래 걸리지 않고 냄새가 적은 편이며, 청결한 환경에서 사용할 수 있는 장점이 있습니다. 그러므로 생기 넘치는 식물이나 아트워크를 부착할 때 밀풀을 사용하는 것을 권장합니다.\n",
            "   밀풀은 시공 후 2~3일 동안 접착력이 발생하지 않는 점이 있습니다. 또한, 유통기한이 상대적으로 짧고 보관에 주의해야 합니다. 습기에 노출되면 파손되거나 변형될 수 있으므로 적절한 환경에서 보관 및 사용하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      86.22 ms /   111 runs   (    0.78 ms per token,  1287.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.66 ms /    13 tokens (   27.44 ms per token,    36.45 tokens per second)\n",
            "llama_print_timings:        eval time =    5990.76 ms /   110 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    6913.06 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      85.45 ms /   121 runs   (    0.71 ms per token,  1416.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.72 ms /    14 tokens (   25.48 ms per token,    39.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6574.89 ms /   120 runs   (   54.79 ms per token,    18.25 tokens per second)\n",
            "llama_print_timings:       total time =    7432.25 ms /   134 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   철근콘크리트 구조는 콘크리트의 압축 강도를 살려내는 동시에 철근으로 인장 강도를 보완하여 구축된 구조체입니다. 일반적으로 도심에서 많이 사용되며 내구성, 내화 및 내진 성능이 우수합니다. 그러나 고층 건물의 경우 아래층의 보나 기둥이 상당히 큰 단면을 가져야 하는 단점이 있습니다. 이러한 구조는 건축물의 안정성을 높이는 데에 사용되며, 철근의 양은 건물의 규모와 종류에 따라 달라집니다.\n",
            "   통나무구조 방식은 원형 또는 각형의 내력벽으로 하고 나머지 바닥이나 지붕구조는 2x4경량 목구조와 동일한 구조로 구성된다. 주로 통나무를 쌓아 벽체를 만들기 때문에 1층 높이에서 7~12cm의 침하가 장기적으로 발생할 수 있으며, 이에 따라 창문틀 등의 개구부에는 침하를 고려하여 디테일을 설계해야 합니다. 통나무구조 방식은 자연적이고 따뜻한 분위기를 연출해내기 때문에 주택 및 휴양시설에서 선호되는 구조 방식 중 하나입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      67.17 ms /    79 runs   (    0.85 ms per token,  1176.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     442.17 ms /    18 tokens (   24.56 ms per token,    40.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4250.68 ms /    78 runs   (   54.50 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    5147.59 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   공명형 흡음재는 특정 주파수에 한정적으로 적용되는 것이 특징입니다. 이러한 특성으로 인해 특정 주파수 범위에서 효과적으로 소리를 흡수할 수 있으며, 이외의 주파수에 대해서는 상대적으로 적은 효과를 보입니다. 따라서 공명형 흡음재를 사용할 때에는 주로 목표 주파수 범위에서 소리를 제어하고자 하는 상황에 적합합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      65.56 ms /    94 runs   (    0.70 ms per token,  1433.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =      96.58 ms /     6 tokens (   16.10 ms per token,    62.12 tokens per second)\n",
            "llama_print_timings:        eval time =    5079.25 ms /    93 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    5549.50 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      94.55 ms /   122 runs   (    0.78 ms per token,  1290.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.63 ms /    12 tokens (   22.22 ms per token,    45.01 tokens per second)\n",
            "llama_print_timings:        eval time =    6592.84 ms /   121 runs   (   54.49 ms per token,    18.35 tokens per second)\n",
            "llama_print_timings:       total time =    7479.62 ms /   133 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   결로가 발생하는 원인은 고온 다습환경에서 수분이 축적되어 발생할 수 있습니다. 특히, 외부의 차가운 표면과 실내의 높은 습도가 결합하여 발생하는 경우가 많습니다. 이러한 환경에서는 벽면이나 창틀 등의 재료 표면에 수분이 응축되어 결로가 발생하게 됩니다. 따라서, 적절한 환기와 습기 관리가 필요하며, 고온 다습환경을 방지하는 것이 결로 예방에 큰 도움이 됩니다.\n",
            "   결로를 방지하기 위해서는 주로 사용되는 시공방법이 있습니다. 먼저, 건물 내부의 습도를 적정 수준으로 유지하기 위해 제습기를 운영하고 환기를 철저히 해야 합니다. 또한, 건물 내부의 온도와 습도를 조절하기 위해 건물 외부의 단열재를 충분히 설치하는 것이 중요합니다. 특히, 단열재의 밀착 시공이 중요하며, 단열재 사이의 이음부를 통한 열교를 방지하기 위해 충분한 단열재를 사용해야 합니다. 그 외에도 건물의 외부 기상 조건 및 주변 환경 등을 고려하여 적절한 시공 방법을 선택해야 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     110.23 ms /   147 runs   (    0.75 ms per token,  1333.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     447.11 ms /    20 tokens (   22.36 ms per token,    44.73 tokens per second)\n",
            "llama_print_timings:        eval time =    7976.25 ms /   146 runs   (   54.63 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    9082.42 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      82.23 ms /   112 runs   (    0.73 ms per token,  1362.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     355.17 ms /    14 tokens (   25.37 ms per token,    39.42 tokens per second)\n",
            "llama_print_timings:        eval time =    6076.69 ms /   111 runs   (   54.74 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    6943.01 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   베란다를 활용하여 야외 라운지를 만드는 것은 매우 간단합니다. 먼저, 편안한 의자나 소파, 작은 탁자, 그리고 식물들을 추가하여 아늑한 분위기를 조성할 수 있습니다. 심플한 쿠션이나 패드를 사용하여 좌석에 편안함을 더할 수 있습니다. 또한, 간절기에는 전기나 가스 히터를 추가하여 추가적인 편안함을 느낄 수도 있습니다. 또한, 베란다의 가장자리에 연출이나 조명을 추가하여 분위기를 연출할 수도 있습니다. 마지막으로, 베란다에 있는 공간을 활용하여 작은 식물을 키우거나 꽃들을 심어서 자연적인 분위기를 조성할 수도 있습니다. 이러한 요소들을 추가하여 베란다를 야외 라운지 공간으로 변신시킬 수 있습니다.\n",
            "   현대적인 거실을 만들기 위해서는 미니멀한 디자인과 현대적인 가구, 간결한 컬러 팔레트를 선택하는 것이 중요합니다. 특히 중요한 것은 색감의 조화와 균형이며, 흰색, 회색, 베이지 등의 중립적인 컬러를 혼용하여 안정적이고 모던한 느낌을 연출할 수 있습니다. 또한, 간결한 가구와 공간 활용을 고민하여 수납 공간을 활용하는 것도 좋은 방법입니다. 전체적으로 깔끔하고 세련된 디자인을 추구하면 현대적인 거실을 완성할 수 있을 것입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      94.54 ms /   121 runs   (    0.78 ms per token,  1279.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     450.56 ms /    18 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6523.28 ms /   120 runs   (   54.36 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    7590.73 ms /   138 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 페인트 작업 시 유해물질을 최소화하기 위해서는 몇 가지 주의사항을 준수해야 합니다. 먼저, 페인트 작업 시에는 적절한 환기 시설을 설치하여 공기 중의 유해물질을 최소화하는 것이 중요합니다. 또한, 페인트 선택 시에는 환경 친화적인 물질을 함유한 제품을 선택하여 유해물질을 더욱 줄일 수 있습니다. 또한, 페인트 작업 시에는 안전장비를 착용하여 작업자 스스로의 건강을 보호하는 것이 중요합니다. 이러한 주의사항을 준수하여 페인트 작업 시 유해물질을 최소화하고 안전한 환경을 유지할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      71.68 ms /   103 runs   (    0.70 ms per token,  1437.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     344.42 ms /    13 tokens (   26.49 ms per token,    37.74 tokens per second)\n",
            "llama_print_timings:        eval time =    5596.54 ms /   102 runs   (   54.87 ms per token,    18.23 tokens per second)\n",
            "llama_print_timings:       total time =    6356.27 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   흡음재 중 판 진동형은 벽과 일정 간격을 두고 설치되는 얇고 통기성이 없는 판으로, 소리가 전달될 때 이 판이 진동하여 마찰에 의해 소리가 소멸되는 형태의 흡음재입니다. 이러한 판상형 흡음재는 주로 소리를 흡수하는 것보다는 저주파의 진동음을 소멸시키는 데 주로 사용되며, 따라서 전체적인 흡음률은 높지 않은 특징을 가지고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      60.93 ms /    80 runs   (    0.76 ms per token,  1313.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.22 ms /    11 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4308.87 ms /    79 runs   (   54.54 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    4956.12 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      57.90 ms /    75 runs   (    0.77 ms per token,  1295.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     348.85 ms /    15 tokens (   23.26 ms per token,    43.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.01 ms /    74 runs   (   54.55 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    4739.75 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   점토벽돌은 다른 벽돌에 비해 유지보수가 비교적 쉽고 저렴하며, 흙이 주 원료로 사용되기 때문에 친환경적입니다. 또한 다른 벽돌에 비해 열 및 소리를 잘 흡수하여 훌륭한 단열 및 소음 차단 특성을 가지고 있으며, 내구성이 뛰어나서 오랜 기간 동안 사용할 수 있는 것이 장점입니다.\n",
            "   도료와 벽지는 각각의 장단점을 가지고 있습니다. 도료는 다양한 색상과 마무리 효과를 제공하며 경제적이고 사용이 간편한 재료로 평가받습니다. 반면에 벽지는 패턴과 텍스처를 추가하여 공간에 풍부한 느낌을 주는 장점이 있습니다. 선택은 개인의 취향과 사용하고자 하는 공간의 목적에 따라 다를 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      62.34 ms /    91 runs   (    0.69 ms per token,  1459.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.00 ms /    12 tokens (   22.33 ms per token,    44.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4911.95 ms /    90 runs   (   54.58 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    5538.80 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      57.20 ms /    65 runs   (    0.88 ms per token,  1136.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.44 ms /    11 tokens (   23.68 ms per token,    42.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3462.21 ms /    64 runs   (   54.10 ms per token,    18.49 tokens per second)\n",
            "llama_print_timings:       total time =    4117.64 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   강화마루는 원목 무늬 필름지가 하드코팅 처리된 바닥재를 의미합니다. 일반적으로 평당 7~12 만원의 가격대를 가지고 있습니다. 이 바닥재는 온도나 습도에 의한 변색이 거의 없고, 강도가 뛰어나 수명이 긴 장점이 있습니다. 하지만, 필름지로 코팅처리되어 있기 때문에 질감이나 보행감이 조금 떨어진다는 단점이 있습니다.\n",
            "   징크판넬의 단점은 다른 징크에 비해 수명이 상대적으로 짧다는 것입니다. 또한, 시공이 잘못될 경우 쉽게 녹슬 수 있으며, 특히 자극적인 환경에 노출되는 경우에는 빠른 손상이 발생할 수 있습니다. 따라서, 적절한 시공 및 유지보수가 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      55.61 ms /    80 runs   (    0.70 ms per token,  1438.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     547.81 ms /    22 tokens (   24.90 ms per token,    40.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4318.69 ms /    79 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    5179.35 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      96.33 ms /   127 runs   (    0.76 ms per token,  1318.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     447.98 ms /    18 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
            "llama_print_timings:        eval time =    6874.80 ms /   126 runs   (   54.56 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    7951.57 ms /   144 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  타공하자가 있는 벽을 통해 습기가 유입하는 경우, 벽장 부위에 결로가 발생할 수 있습니다. 타공불량으로 인해 습기가 유입되면 온도가 낮은 벽장 부위에서 결로가 생기거나 이미 발생한 결로가 심해질 수 있습니다. 따라서 타공하자가 있는 벽을 통해 습기가 유입되는 것을 방지하는 것이 중요합니다.\n",
            "  타공하자로 인해 벽장 부위가 노출되면, 습기가 유입되어 결로가 발생할 수 있습니다. 따라서 벽장 부위의 결로를 방지하기 위해서는 타공하자를 신중하게 처리해야 합니다. 먼저, 타공을 할 때는 적절한 크기와 안전한 위치를 선택하여 벽돌이나 모르타르를 손상시키지 않도록 주의해야 합니다. 또한, 타공 후에는 벽돌이나 모르타르를 밀실하게 채워주고, 외부에서 오는 습기나 먼지 등으로부터 보호할 수 있도록 방수 처리를 해주는 것이 좋습니다. 이렇게 함으로써 벽장 부위의 결로를 방지할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      82.98 ms /   116 runs   (    0.72 ms per token,  1397.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     733.12 ms /    29 tokens (   25.28 ms per token,    39.56 tokens per second)\n",
            "llama_print_timings:        eval time =    6295.90 ms /   115 runs   (   54.75 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    7507.97 ms /   144 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      66.52 ms /    73 runs   (    0.91 ms per token,  1097.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     114.05 ms /     8 tokens (   14.26 ms per token,    70.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3896.14 ms /    72 runs   (   54.11 ms per token,    18.48 tokens per second)\n",
            "llama_print_timings:       total time =    4528.13 ms /    80 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  물 누수로 인해 발생한 곰팡이와 곰팡이 냄새를 제거하는 가장 좋은 방법은 물 누수가 발생한 부분을 신속하게 수리하고, 그 후에 곰팡이를 철저히 제거하는 것입니다. 곰팡이 제거를 위해서는 곰팡이 제거제를 사용하거나 식초와 물을 섞은 용액을 이용하여 깨끗이 닦아내야 합니다. 이후에는 곰팡이 방지 페인트를 사용하여 냄새와 재생장을 방지할 수 있습니다. 곰팡이 방지 페인트를 사용하는 것은 상당히 효과적이므로 권장됩니다.\n",
            "   펫테리어는 반려동물과의 생활을 고려한 편의성을 높이면서도 주거 공간의 인테리어를 고려하는 스타일을 말합니다. 즉, 반려동물과의 함께 생활하는 가정 내부의 디자인을 향상시키는 것을 목표로 하고 있습니다. 이를 위해 편안하면서도 세련된 디자인을 도입하여 반려동물과 사람이 함께 편안하게 생활할 수 있는 환경을 조성하는 것이 목표입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      66.82 ms /    92 runs   (    0.73 ms per token,  1376.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.45 ms /    13 tokens (   27.19 ms per token,    36.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4973.73 ms /    91 runs   (   54.66 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    5726.72 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      68.77 ms /    95 runs   (    0.72 ms per token,  1381.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     456.83 ms /    19 tokens (   24.04 ms per token,    41.59 tokens per second)\n",
            "llama_print_timings:        eval time =    5115.65 ms /    94 runs   (   54.42 ms per token,    18.37 tokens per second)\n",
            "llama_print_timings:       total time =    5990.00 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배지를 너무 작게 자르면 도배지 끝 부분에 장력이 크게 작용하여 벽면에서 떨어질 수 있습니다. 또한, 도배지 크기가 작으면 도배지가 부착된 벽면의 크기를 정확히 반영하지 못해 시공이 부실할 수 있습니다. 따라서 도배지를 자를 때에는 충분한 여유를 가지고 잘라야 하며, 부분적으로라도 시공된 도배지를 다시 잘라내는 것이 좋습니다.\n",
            "  높은 습도로 인해 도배 풀의 접착력이 떨어지면 도배지 패턴이 이어지지 않을 수 있습니다. 습도가 높은 상태에서는 도배풀이 제대로 건조되지 않고 끼는 경우가 발생할 수 있어요. 따라서 습도가 높은 상태에서 도배를 진행할 때에는 특히 접착제의 품질과 사용 방법에 유의해야 합니다.습기를 제거하고 낮추는 등의 보완 조치를 취할 수 있지만, 전문가의 도움이 필요할 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      75.33 ms /   102 runs   (    0.74 ms per token,  1353.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     457.43 ms /    18 tokens (   25.41 ms per token,    39.35 tokens per second)\n",
            "llama_print_timings:        eval time =    5528.64 ms /   101 runs   (   54.74 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    6457.21 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  알러지가 있는 사람은 매끄럽고 평평한 벽지를 선택하는 것이 좋습니다. 이는 먼지나 알러지 유발물질이 벽지에 적게 축적되어 청소가 쉽고 유지보수가 용이하기 때문입니다. 또한, 평평한 표면의 벽지는 디자인적으로도 더 깔끔하고 현대적인 느낌을 줄 수 있습니다. 따라서 알러지가 있는 사람은 벽지를 선택할 때 이러한 점을 고려하여 매끄럽고 평평한 벽지를 선택하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      40.34 ms /    58 runs   (    0.70 ms per token,  1437.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     545.24 ms /    24 tokens (   22.72 ms per token,    44.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3111.80 ms /    57 runs   (   54.59 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    3889.58 ms /    81 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   아파트 도배 평수는 일반적으로 분양 평수의 2.5배를 사용합니다. 이는 일반적인 규모의 아파트 도배 작업에 적용되는 규칙적인 계산 방식입니다. 도배 작업을 위한 재료 및 공사비 등을 산정할 때 유용하게 사용될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      93.85 ms /   122 runs   (    0.77 ms per token,  1300.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     350.94 ms /    14 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
            "llama_print_timings:        eval time =    6624.77 ms /   121 runs   (   54.75 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    7589.61 ms /   135 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      56.63 ms /    81 runs   (    0.70 ms per token,  1430.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     355.60 ms /    13 tokens (   27.35 ms per token,    36.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4365.77 ms /    80 runs   (   54.57 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    5044.20 ms /    93 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   마감재의 하자 여부를 판단하기 위해서는 몇 가지 요소를 고려해야 합니다. 첫째로는 설계도서와의 일치 여부가 있습니다. 마감재가 설계도서에 명시된 내용과 일치하는지 확인해야 합니다. 둘째로는 기능상의 문제, 예를 들어 마감재가 쉽게 파손되거나 사용상의 문제가 있는지를 확인해야 합니다. 그 다음으로는 미관상의 문제 여부도 중요합니다. 마감재의 외관이나 마감재들 간의 조화가 보존되었는지 확인해야 합니다. 마지막으로, 안전상의 문제 여부도 고려해야 합니다. 마감재가 안전에 영향을 미치는 문제가 있는지를 확인하고 조치해야 합니다.\n",
            "   라돈을 측정하는 방법은 일반적으로 평수와 폭의 방법을 사용합니다. 평수는 건물의 가로줄을 측정하고, 폭은 건물의 세로줄을 측정하여 두 값을 곱하여 계산합니다. 이렇게 하면 건물의 총 평수를 알 수 있습니다. 만약 건물이 비정형적인 구조이거나 복잡한 지붕 구조를 가지고 있다면, 전문가의 도움을 받아 라돈을 측정하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      88.25 ms /   114 runs   (    0.77 ms per token,  1291.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     362.64 ms /    16 tokens (   22.67 ms per token,    44.12 tokens per second)\n",
            "llama_print_timings:        eval time =    6170.95 ms /   113 runs   (   54.61 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    7112.40 ms /   129 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      44.38 ms /    64 runs   (    0.69 ms per token,  1442.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.39 ms /    11 tokens (   24.04 ms per token,    41.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3453.38 ms /    63 runs   (   54.82 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    3973.15 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   이산화탄소 소화기는 이산화탄소(CO2)를 높은 압력으로 압축하여 액화시킨 후, 단단한 철제 용기에 넣은 소화기입니다. 이 종류의 소화기는 B, C급 화재에 대한 소화기능이 있으며, 물을 뿌리는 대신에 사용하기 적합하며 냉각 효과와 질식 효과가 큽니다. 이산화탄소 소화기는 전기기기, 기름, 페인트 등의 화재에 적합하며 전기를 차단한 후 안전하게 사용할 수 있습니다.\n",
            "   분말 소화기는 탄산수소 나트륨 분말을 사용하여 불을 질식시키는 소화기입니다. 이 소화기는 불연성 고압 가스에 의해 분말이 방출되어 불을 질식시키는 방식으로 작동합니다. 이를 통해 화재를 질식시키고 확산을 막을 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      60.94 ms /    80 runs   (    0.76 ms per token,  1312.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.94 ms /    11 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
            "llama_print_timings:        eval time =    4313.00 ms /    79 runs   (   54.59 ms per token,    18.32 tokens per second)\n",
            "llama_print_timings:       total time =    4966.58 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.82 ms /   105 runs   (    0.73 ms per token,  1366.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     364.38 ms /    15 tokens (   24.29 ms per token,    41.17 tokens per second)\n",
            "llama_print_timings:        eval time =    5700.75 ms /   104 runs   (   54.81 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =    6529.52 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   면진장치는 건물의 지반에서 발생하는 진동 에너지를 흡수하여 건물에 전달되는 진동을 줄여주는 장치입니다. 주로 지진이나 기타 지반의 진동으로 인한 피해를 방지하기 위해 사용됩니다. 면진장치는 건물의 지반에 설치되어 진동 에너지의 흡수와 전달을 조절하여 건물의 안전성을 향상시키는 역할을 합니다.\n",
            "   면진구조는 건물의 구조적인 요소 중 하나로, 주로 벽돌이나 콘크리트 블록을 사용하여 벽체를 구축하는 방식을 말합니다. 이 방식은 모던한 건물 디자인에서 많이 사용되며 내습, 내구성이 좋고 내화 구조적인 특징이 있습니다. 그러나 비싼 가격대와 다른 외장재에 비해 시공비가 많이 드는 단점이 있습니다. 면진구조는 건물의 외관을 꾸밀 때 주로 사용되며, 내구성과 안정성을 확보하는 데 도움이 됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      43.53 ms /    63 runs   (    0.69 ms per token,  1447.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     448.96 ms /    17 tokens (   26.41 ms per token,    37.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3390.15 ms /    62 runs   (   54.68 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =    4090.67 ms /    79 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      61.42 ms /    73 runs   (    0.84 ms per token,  1188.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.76 ms /    12 tokens (   22.31 ms per token,    44.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3907.81 ms /    72 runs   (   54.28 ms per token,    18.42 tokens per second)\n",
            "llama_print_timings:       total time =    4596.00 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 외단열재는 건물의 내부 온도를 유지하는 데 도움을 주는 장점이 있습니다. 이러한 재료는 열전달을 차단하여 건물 내부의 온도가 급격히 변화하는 것을 방지하는 역할을 합니다. 이로써 건물 내부의 온도를 안정화시키고 에너지 소비를 줄이는 데 도움을 줄 수 있습니다.\n",
            "   외단열재의 장점은 주로 두 가지입니다. 첫 번째로, 외단열재는 실내 공간을 보다 효율적으로 활용할 수 있도록 해주며, 두 번째로 실내 온도를 안정적으로 유지시켜 에너지 소비를 줄일 수 있습니다. 이러한 특징으로 인해 외단열재는 건물 내부의 공간을 최대한 활용하면서도 에너지 효율성을 향상시킬 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      54.61 ms /    78 runs   (    0.70 ms per token,  1428.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.75 ms /     9 tokens (   29.64 ms per token,    33.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4190.25 ms /    77 runs   (   54.42 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    4769.91 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      81.71 ms /   106 runs   (    0.77 ms per token,  1297.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.48 ms /    16 tokens (   22.34 ms per token,    44.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5737.86 ms /   105 runs   (   54.65 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    6636.47 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   외단열과 내단열의 가장 큰 차이점은 열 전달 계수의 차이입니다. 외단열은 내단열보다 열 전달 계수가 높아서 열이 더 잘 전달됩니다. 이는 건물 내부의 온도가 일정하게 유지되기 어렵다는 것을 의미합니다. 내단열은 외부 온도의 변화로부터 보호받는 내부 온도가 일정하게 유지될 수 있습니다.\n",
            "   외단열 시공방법은 내단열 시공방법보다 단열효과가 좋으며, 이는 건물 내부의 온도 변화로 인한 결로현상 발생이 적다는 것을 의미합니다. 내단열 시공방법은 외단열 시공방법보다 열교로 인한 결로현상이 발생할 가능성이 높아서 단열 효과가 상대적으로 떨어집니다. 따라서 외단열 시공방법이 내단열 시공방법보다 단열 효과 측면에서 우수한 방법을 제공한다고 볼 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      42.14 ms /    61 runs   (    0.69 ms per token,  1447.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.49 ms /    12 tokens (   21.79 ms per token,    45.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3260.88 ms /    60 runs   (   54.35 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    3766.67 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      64.29 ms /    89 runs   (    0.72 ms per token,  1384.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     122.29 ms /     8 tokens (   15.29 ms per token,    65.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4793.54 ms /    88 runs   (   54.47 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    5278.85 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 현재 가장 인기 있는 바닥재 종류는 대리석 타일입니다. 대리석 타일은 자연스러운 아름다움과 내구성으로 유명하며, 고급스러운 분위기를 연출할 수 있습니다. 또한 유지보수가 비교적 간편하고 내구성이 뛰어나기 때문에 많은 사람들에게 선호되고 있습니다.\n",
            "   가장 비싼 바닥재로는 대리석 타일이 가장 많이 사용됩니다. 대리석은 자연스러운 아름다움과 내구성으로 유명하며, 고급스러운 분위기를 연출할 수 있습니다. 또한, 그만큼 가격이 높기 때문에 대리석은 비교적 고가의 바닥재로 알려져 있습니다. 하지만 비슷하게, 테라코타 타일, 목재 바닥재, 그리고 대형 석재 또한 비싼 바닥재로 알려져 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     140.34 ms /   185 runs   (    0.76 ms per token,  1318.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.06 ms /    11 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
            "llama_print_timings:        eval time =   10072.21 ms /   184 runs   (   54.74 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =   11227.60 ms /   195 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   포세린 타일은 밀도와 강도가 뛰어나고 변형이 적고 반영구적인 특징이 있어, 주방, 화장실, 현관 등의 습기가 많은 실내나 실외에서 사용하기에 적합한 재료입니다. 이러한 특성으로 인해 포세린 타일은 시간이 지나도 모양을 유지하고 쉽게 변색되지 않는 장점이 있습니다. 또한, 미세한 공간에 적합한 크기의 타일을 제작하여 디자인의 다양성을 증대시킬 수 있기 때문에 실내 장식에 다양한 활용이 가능합니다.  하지만 포세린 타일은 표면이 미끄러울 수 있다는 단점이 있어, 주방이나 화장실의 바닥재로 사용할 때 미끄러짐에 대비하기 위해 특별한 처리가 필요할 수 있습니다. 또한, 포세린 타일은 설치가 까다로워서 전문가의 도움이 필요한 경우가 많습니다.이러한 특징들을 고려하여 적절한 사용처를 선정하여 활용하는 것이 중요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.58 ms /    97 runs   (    0.79 ms per token,  1266.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     359.61 ms /    16 tokens (   22.48 ms per token,    44.49 tokens per second)\n",
            "llama_print_timings:        eval time =    5217.02 ms /    96 runs   (   54.34 ms per token,    18.40 tokens per second)\n",
            "llama_print_timings:       total time =    6099.56 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      76.68 ms /   111 runs   (    0.69 ms per token,  1447.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.84 ms /    13 tokens (   27.53 ms per token,    36.33 tokens per second)\n",
            "llama_print_timings:        eval time =    6016.40 ms /   110 runs   (   54.69 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    6816.25 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  중목구조 방식은 기본적으로 기중-보 방식과 유사하지만 구조용 목재로 큰 각재를 사용하여 건축하는 방식입니다. 이 방식은 건물 내부 기둥이나 보가 중양이 되어 강도를 높일 수 있다는 것이 특징이며, 이는 건물의 안정성을 향상시키는 데 도움이 됩니다. 중목구조 방식은 전체적으로 부재를 이용하기 때문에 건물이 흔들리는 것을 줄여주고, 건물의 수명을 연장시키는 등 여러 가지 장점을 갖고 있습니다.\n",
            "   철근콘크리트 구조는 콘크리트의 압축 강도를 살려내는 동시에 철근으로 인장 강도를 보완하여 구축된 구조체입니다. 일반적으로 도심에서 많이 사용되며 내구성, 내화 및 내진 성능이 우수합니다. 그러나 고층 건물의 경우 아래층의 보나 기둥이 상당히 큰 단면을 가져야 하는 단점이 있습니다. 이러한 구조는 건축물의 안정성을 높이는 데에 사용되며, 철근의 양은 건물의 규모와 종류에 따라 달라집니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     100.18 ms /   131 runs   (    0.76 ms per token,  1307.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.44 ms /    10 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
            "llama_print_timings:        eval time =    7101.00 ms /   130 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    8002.84 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      68.44 ms /    98 runs   (    0.70 ms per token,  1431.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.95 ms /    12 tokens (   22.41 ms per token,    44.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5311.12 ms /    97 runs   (   54.75 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    5972.06 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   도배 작업을 위해 필요한 도배지의 양은 주로 도배할 평수에 따라 결정됩니다. 일반적으로는 도배할 평수를 5로 나눈 값을 사용하여 필요한 롤 수를 계산합니다. 예를 들어, 32평 아파트의 경우 도배평수는 80평(32*2.5)이므로 5로 나눈 값인 16롤만큼의 도배지가 필요합니다. 하지만 작업자의 숙련도, 작업환경, 그리고 집의 구조에 따라 실제 필요한 양은 달라질 수 있습니다. 따라서 정확한 도배지의 양을 알기 위해서는 전문가의 견적 상담을 받는 것이 좋습니다.\n",
            "   벽에 구멍을 메우는 방법은 다음과 같습니다.  1. 먼저 구멍 주변을 깨끗하게 솔로 닦고 분진을 제거합니다. 2. 다음으로 시멘트 혹은 석고보드를 사용하여 구멍을 메웁니다. 필요할 경우, 특수한 부직포 패드를 사용하여 구멍 주변을 메우는 것이 좋습니다. 3. 메운 부분이 말랐을 때, 고르게 페인트를 칠하여 완만한 마감을 합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      93.18 ms /   118 runs   (    0.79 ms per token,  1266.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     544.43 ms /    21 tokens (   25.93 ms per token,    38.57 tokens per second)\n",
            "llama_print_timings:        eval time =    6384.69 ms /   117 runs   (   54.57 ms per token,    18.33 tokens per second)\n",
            "llama_print_timings:       total time =    7541.55 ms /   138 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     190.12 ms /   245 runs   (    0.78 ms per token,  1288.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     448.66 ms /    18 tokens (   24.93 ms per token,    40.12 tokens per second)\n",
            "llama_print_timings:        eval time =   13378.50 ms /   244 runs   (   54.83 ms per token,    18.24 tokens per second)\n",
            "llama_print_timings:       total time =   15071.82 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   경질우레탄폼 보온판은 주로 외단열 시공에 사용됩니다. 이러한 시공은 건물의 콘크리트 골조가 완성된 후 우레탄폼을 사용하여 건물의 외부 표면을 감싸는 방식으로 진행됩니다. 이를 통해 건물 내부의 온도를 안정화하고 에너지 효율성을 향상시키는 효과를 얻을 수 있습니다. 외부에서 직접 작업하기 때문에 날씨의 영향을 많이 받으므로 너무 더운 날이나 습한 날에는 작업하기 어렵습니다. 따라서 작업 시에는 숙련된 시공자의 지도 하에서 안전하게 진행되어야 합니다.\n",
            "   경질우레탄폼 보온판을 사용한 외단열 시공은 건물의 외부 벽면에 폴리우레탄 스프레이를 사용하여 연속적으로 단열재를 설치하는 방식으로, 기존 벽체나 외장재 위에 바로 단열재를 설치하는 시공 방법입니다. 이 방법은 외부에서 바로 열에 접근할 수 있기 때문에 단열재의 성능이 우수하며, 결로나 곰팡이와 같은 하자가 발생하는 경우를 최소화할 수 있습니다.  하지만 경질우레탄폼 보온판을 사용한 외단열 시공은 전문 시공자에게 의존하는 경우가 많아 시공비가 상대적으로 높을 수 있습니다. 또한, 외부에서 바로 열에 접근하기 때문에 열팽창이나 수축이 발생할 수 있으며, 이로 인해 외장재나 창틀이 변형될 수 있는 단점이 있습니다.  따라서 경질우레탄폼 보온판을 사용한 외단열 시공은 외부 벽면에 시공할 때 기존 창틀이나 외장재와의 조화를 고려하여 적절한 설치 위치를 선정하는 것이 중요합니다. 또한, 시공 전에는 외부 온도와 습도를 고려하여 적합한 시공 날짜를 선택하는 것이 필요합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      83.38 ms /   102 runs   (    0.82 ms per token,  1223.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     452.31 ms /    19 tokens (   23.81 ms per token,    42.01 tokens per second)\n",
            "llama_print_timings:        eval time =    5500.15 ms /   101 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
            "llama_print_timings:       total time =    6487.21 ms /   120 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  질석벽지는 아트월이나 현관 입구에 많이 사용되는 이유는 그 특별한 질감과 미적 가치 때문입니다. 질석벽지는 자연석으로 만들어진 벽지로, 입체감이 풍부하여 고급스러운 분위기를 연출할 수 있습니다. 또한, 다양한 색상과 질감을 제공하여 건물의 외관을 더욱 화려하게 만들어줍니다. 이러한 특징으로 인해 질석벽지는 주로 아트월이나 현관 입구에 사용되어 건물의 첫 인상을 더욱 고급스럽게 만들어줍니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     102.09 ms /   146 runs   (    0.70 ms per token,  1430.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     543.64 ms /    22 tokens (   24.71 ms per token,    40.47 tokens per second)\n",
            "llama_print_timings:        eval time =    7935.58 ms /   145 runs   (   54.73 ms per token,    18.27 tokens per second)\n",
            "llama_print_timings:       total time =    9085.00 ms /   167 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  시트 방수공사는 건물의 외벽이나 지붕 등에 방수용으로 제조된 고무계, 아크릴계, 고무 아크릴계 등의 액상형 재료를 발라 방수층을 형성하는 작업으로, 액체방수를 하고 2차로 시공하는 방식으로 진행됩니다. 이 방법은 건물의 수명을 연장시키고, 수분으로 인한 파손을 방지하여 건물의 안전성을 향상시키는 효과를 가지고 있습니다. 또한, 시트 방수공사는 건물 내부의 온도를 안정화시켜 주어 에너지 소비를 절감하는 데 도움을 줄 수 있습니다. 따라서 건물의 에너지 절감 효과를 얻기 위해 시트 방수공사를 통한 방수층 형성은 중요한 작업입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =     121.26 ms /   156 runs   (    0.78 ms per token,  1286.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.18 ms /    15 tokens (   23.81 ms per token,    42.00 tokens per second)\n",
            "llama_print_timings:        eval time =    8469.65 ms /   155 runs   (   54.64 ms per token,    18.30 tokens per second)\n",
            "llama_print_timings:       total time =    9609.72 ms /   170 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      48.66 ms /    68 runs   (    0.72 ms per token,  1397.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =      79.54 ms /     5 tokens (   15.91 ms per token,    62.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3659.49 ms /    67 runs   (   54.62 ms per token,    18.31 tokens per second)\n",
            "llama_print_timings:       total time =    4016.48 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   내진설계에서 안정성을 높이는 방법은 다양합니다. 먼저, 건물의 기초 및 지반을 개선하여 내진 성능을 향상시킬 수 있습니다. 예를 들어, 기초를 보강하거나 지반을 안정화시키고, 건물 주변의 토양을 개선함으로써 내진 성능을 향상시킬 수 있습니다. 또한, 건물의 구조적 결함을 제거하여 안정성을 높일 수 있습니다. 예를 들어, 건물의 불균형을 조정하거나 구조적 결함을 제거함으로써 내진 성능을 향상시킬 수 있습니다. 마지막으로, 건물의 내진 설계를 개선하여 안정성을 높일 수 있습니다. 예를 들어, 내진 시스템을 업그레이드하거나 새로운 내진 설계를 도입함으로써 내진 성능을 향상시킬 수 있습니다.\n",
            "   내진구조는 건물의 구조물을 건물 외부에 설치하는 방식을 말합니다. 이는 건물의 벽체나 기초 등을 외벽으로 삼는 것으로, 내력벽으로 구축되고 보강되어 건물의 하중을 지탱합니다. 이러한 구조는 건물의 안정성을 확보하여 오랜 기간 동안 사용할 수 있도록 설계됩니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      79.14 ms /   100 runs   (    0.79 ms per token,  1263.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     357.83 ms /    13 tokens (   27.53 ms per token,    36.33 tokens per second)\n",
            "llama_print_timings:        eval time =    5416.93 ms /    99 runs   (   54.72 ms per token,    18.28 tokens per second)\n",
            "llama_print_timings:       total time =    6295.39 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      41.00 ms /    58 runs   (    0.71 ms per token,  1414.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.22 ms /    14 tokens (   25.44 ms per token,    39.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3100.87 ms /    57 runs   (   54.40 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =    3689.50 ms /    71 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   분말 소화기를 사용할 때 주의할 점은 압력계의 눈금 위치가 초록색에 있는지 확인하는 것뿐만 아니라, 받침대를 사용하여 소화기 부식을 방지하고, 한 달에 한 번씩 흔들어 분말의 굳어짐을 방지해야 합니다. 또한, 직사광선과 고온 다습한 장소를 피하고, 사용 후 내부 약품을 완전히 제거해야 합니다. 이러한 주의사항을 준수하여 분말 소화기를 보다 안전하게 사용할 수 있습니다.\n",
            "   아파트 도배 평수는 일반적으로 분양 평수의 2.5배를 사용합니다. 이는 일반적인 규모의 아파트 도배 작업에 적용되는 규칙적인 계산 방식입니다. 도배 작업을 위한 재료 및 공사비 등을 산정할 때 유용하게 사용될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      78.80 ms /    97 runs   (    0.81 ms per token,  1230.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.99 ms /    13 tokens (   27.23 ms per token,    36.72 tokens per second)\n",
            "llama_print_timings:        eval time =    5202.18 ms /    96 runs   (   54.19 ms per token,    18.45 tokens per second)\n",
            "llama_print_timings:       total time =    6065.08 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   압출법 보온판의 장점은 습기에 강하고 곰팡이 및 세균 증식을 막을 수 있는 것입니다. 또한, 단열재 중에서는 열전도율이 가장 낮으며 시공이 간편하다는 점도 장점으로 꼽힙니다. 추가로 압출법 보온판은 가벼워서 운반이 용이하고 내구성이 뛰어나다는 점도 많은 사용자들에게 긍정적인 평가를 받고 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      86.08 ms /   123 runs   (    0.70 ms per token,  1428.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     637.41 ms /    26 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
            "llama_print_timings:        eval time =    6702.52 ms /   122 runs   (   54.94 ms per token,    18.20 tokens per second)\n",
            "llama_print_timings:       total time =    7841.40 ms /   148 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   평지붕의 누수 문제를 방지하기 위해 수성 벽체용 탄성 방수 도료를 사용하는 것은 좋은 방법입니다. 이 도료는 벽체에 사용될 때 뛰어난 방수 기능을 제공하면서도 유연하게 늘어나는 특성을 가지고 있어, 누수 문제를 방지하는 데 도움이 됩니다. 또한, 내구성이 뛰어나고 화학물질에 강하며 마모에도 강한 특성을 가지고 있어, 오랫동안 방수 기능을 유지할 수 있습니다. 이러한 특성으로 인해 수성 벽체용 탄성 방수 도료는 평지붕의 누수 문제를 방지하는 데 효과적으로 사용될 수 있습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      87.39 ms /   106 runs   (    0.82 ms per token,  1212.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.33 ms /    10 tokens (   26.63 ms per token,    37.55 tokens per second)\n",
            "llama_print_timings:        eval time =    5709.60 ms /   105 runs   (   54.38 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =    6548.41 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      64.35 ms /    91 runs   (    0.71 ms per token,  1414.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =      96.46 ms /     6 tokens (   16.08 ms per token,    62.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4927.89 ms /    90 runs   (   54.75 ms per token,    18.26 tokens per second)\n",
            "llama_print_timings:       total time =    5392.11 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   석고수정은 주로 건물이 오래되거나 지진 등의 외부 충격으로 인해 발생합니다. 특히 건물 내부의 습도가 높거나 습기가 유입되는 경우 석고수정이 발생할 가능성이 높아집니다. 따라서 건물의 소유자나 거주자는 습기 관리에 신경 써야 합니다. 제습기를 가동하거나 환기를 통해 건물 내부의 적정 습도를 유지하는 것이 중요합니다. 또한 건물의 외부에 충격이나 압력을 받을 경우 석고수정이 발생할 수 있으므로 이 역시 조심해야 합니다.\n",
            "   석고수정이 발생하는 경우, 먼저 벽을 두드려 진동을 느끼거나 눈에 띄는 변형이 있는지 확인해야 합니다. 만약 석고수정이 발견된다면, 전문가의 도움을 받아 부분적인 수정 또는 전체적인 재작업을 하는 것이 좋습니다. 또한, 습기를 피하고 적절한 환기를 유지하여 석고보드의 수명을 연장시키는 것이 중요합니다. 만약 석고수정이 발생한 상황에서는 전문가의 조언을 구하는 것이 좋습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      85.69 ms /   108 runs   (    0.79 ms per token,  1260.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.62 ms /    10 tokens (   26.76 ms per token,    37.37 tokens per second)\n",
            "llama_print_timings:        eval time =    5790.07 ms /   107 runs   (   54.11 ms per token,    18.48 tokens per second)\n",
            "llama_print_timings:       total time =    6629.01 ms /   117 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     753.31 ms\n",
            "llama_print_timings:      sample time =      54.97 ms /    79 runs   (    0.70 ms per token,  1437.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.49 ms /    10 tokens (   26.45 ms per token,    37.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4280.93 ms /    78 runs   (   54.88 ms per token,    18.22 tokens per second)\n",
            "llama_print_timings:       total time =    4861.00 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  카페트의 기대수명은 주로 6년으로 알려져 있습니다. 그러나 이는 사용빈도, 관리방법, 그리고 카펫의 품질 등에 따라 달라질 수 있습니다. 만약 카펫을 자주 사용하고 청소를 규칙적으로 해주며 질 좋은 카펫을 구매한다면, 수명을 늘릴 수 있습니다. 또한, 카펫의 수명을 연장하기 위해서는 햇빛에 노출되지 않도록 주의해야 하며, 실내 습도를 적절히 유지하는 것도 중요합니다. 이러한 관리와 유지보수를 통해 카펫의 수명을 늘릴 수 있습니다.\n",
            "   오리지널징크의 장점은 다른 징크에 비해 수명이 길며 다양한 패턴과 디자인이 가능하다는 점입니다. 또한, 친환경적이고 금속 부식에 대한 내식성이 뛰어나 유지보수가 용이하다는 특징이 있습니다. 이러한 이점들로 인해 오리지널징크는 건물 외벽 및 지붕재로 널리 사용되고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/datas/test.csv')\n",
        "\n",
        "res_question = []\n",
        "res_answer = []\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"max_tokens\": 2048,\n",
        "    \"stop\":[\"<|im_end|>\"],\n",
        "    \"echo\":False,\n",
        "    \"seed\" : 42,\n",
        "    # \"top_k\":1,\n",
        "    # \"top_p\":0.1,\n",
        "    # \"repeat_penalty\" : 1.5,\n",
        "    # \"temperature\" : 0,\n",
        "}\n",
        "\n",
        "for i, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
        "    instruction = \"-당신은 친절하게 답변하는 도배하자 처리 전문가입니다. \\\n",
        "                   -설명은 이해하기 쉽고 명료하게 합니다.\\\n",
        "                   -건축구조, 마감재, 마감하자, 시공, 인테리어,타 마감하자,기타 측면에서 대답합니다.\\\n",
        "                   -그 외의 것들에 대한 질문에는 '잘 모르겠습니다'라고 답변합니다.\\\n",
        "                   제시된 모든 질문에 대해 상세하고 명확한 설명을 제공하시오.\"\n",
        "    question_with_instruction = f\"{instruction} {row['질문']}\"\n",
        "\n",
        "    print('\\n', row['질문'])\n",
        "    res = llm(question_with_instruction, **generation_kwargs)\n",
        "    answer = res[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "    res_question.append(row['질문'])\n",
        "    res_answer.append(answer)\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "1AB9tdKp18su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res = pd.DataFrame(res_question)\n",
        "df_res['answer'] = res_answer\n",
        "df_res.to_csv(f'/content/drive/MyDrive/DACON/Hansol_QA/results/infer_answers/gguf_test_yanolja_axolotl_v0.2_inst_topk_1_fewshot.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "vZlMfBt-3S2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelEmb = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "pred_emb = modelEmb.encode(res_answer)"
      ],
      "metadata": {
        "id": "yWycx18wB7mz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "2461b42b8de64e1492db4f6f57cbb8b6",
            "a295fdbf0325482daef804c3fa1480ab",
            "3612d5b126904022852780de0265025a",
            "7f054857dd9a46b4a6944d88f46af0f6",
            "373ac36437da42fc802e2f1f5f62c953",
            "79bc6d756bb046fd8aeb3a790bc6baef",
            "7cda80b9b5bb42beb0becc9f82ae133e",
            "1d1c885221054f60b7af0877e8febd9e",
            "7a00d5eaf54f48ad8c2ced776306f75a",
            "ee1b6a068b7e4fda911f47e5026c15a4",
            "a0bde5521dd240dca08a1f153ec88a6c",
            "3bee8532a7044a9882b412cf89df5a5e",
            "d9794dfc40f847c98840fd954c71f440",
            "b9dc78c4370b4c5c9cde53263dfc1496",
            "5316016b5b7445d880f2ecbc5dbf4188",
            "615736c378014b489930f448a88a9e0c",
            "dd3e9b44b01045bbab4c9e0a21b1ef58",
            "c7f116b9c958419f964131d9d46a1077",
            "c33bff8ac027458d975f8d5bbe0364c9",
            "62347c51e84d4705845745fde2a8c60b",
            "390c5f4514c34690ab011ffe89eb25e6",
            "33ee3db3f96f4d0c8d5418945b423853",
            "e11053d7e5a0427bb56324cbfb9c391f",
            "b37a719f27be47d6875989b694d198a2",
            "a0e47ea3e06846b38fd6722732a4aaf0",
            "069e544b7e254657b1affe0e7ca4ec53",
            "6468b1e0254545b891af4aee16b8d800",
            "7b177f0bb5fe4a348ff399f962f16bab",
            "b46e952178334d01b2bad5e9011779f6",
            "0e74837cd564438aa9718b5d867d40dd",
            "19cb02dda8f6433b9f95b29b980821c5",
            "cec4c72c548244eaa26d9efcfcae79a0",
            "43b3fd370fca4d5d801617f360189f2a",
            "36512fbe1e814138a81c07be8e383dcb",
            "1aba894f6c5748b28d4ebe67105eba9c",
            "8ef90cac3f1c42eca461ab173369c604",
            "2f7b26a23dfd42788b5f807929ade5e3",
            "76d0f2db357f40d38970476f09de126b",
            "e61c4706c88d41a997f3e9a84da1875b",
            "41959f668eaa4de6b0804c5bedf286bf",
            "7fc20f876ec746d6b0cf0afd79d53d3a",
            "38b08ec21f474f57940a7ae8be7e704f",
            "82f36c4b0b8042f8bf8cfc5c0d867c92",
            "ee6428debd284e6b859b1abd066b86b9",
            "967899d2dff9406ab7d20d90a321f964",
            "335b66c62a1d48a8b679f63f06e7becf",
            "211c52dcaa84465583006f22ef004c43",
            "758b99d3d37f4625a41aba0fad77d95e",
            "a61a41e447334d05a818f5cee5ea965a",
            "de516437264347489b2f43d8b3461b0a",
            "74f32cf197a64c4081dc4c3a1f69ce17",
            "938bb9fa4d11455791e64da61978e4d1",
            "5bb5643b7c354436b885f7f10fed6ce3",
            "da8b344c21c04fadbe4df0138ffbe841",
            "e55a3392c4054e50857835a01588c9e7",
            "5350a5cdc663450ab3fc3a0062610936",
            "92e554f40009494b8dfabcaeaf285ccf",
            "38cd7872c90b4cb49064b7e6acb8e3cd",
            "3cf6b3398add439fb20080de056d30d2",
            "ccf6a12b669f4fd483162cdfce419051",
            "660ed12fe98c425596f4c21fcdbcf11b",
            "3a7fdff6f0274dbab57e0ec27cd21fc0",
            "67319f85031c479cba6a831584e1033a",
            "ab86b6e600f0448182d40e9ae4bd1959",
            "e7ffe8248c3a4991bc81051a5e2cad9d",
            "f7d56420a61a4d9597ba7c311e48c0f7",
            "a789ec9358244964a79b765e00e6af2a",
            "fcfffe895d1343be908ecfb09d4b827a",
            "5a1a3d7c1878410e80a7d5c447a4e17b",
            "ffb6e9049bd8413da3ad1658c0875b3c",
            "3710adebb39945a38baa871478aac9a1",
            "7624cba8b4cf425681ba55a485e441e0",
            "08c4122f241b459f8a090b34011e70ac",
            "1655f166005c4883b9d739fe7587db6e",
            "7ceca4abb3bc4291943d5ce1bb8118c7",
            "b7c46e6e347241b4bd4f3bbed1c4a2d7",
            "ad7b93b4adb04200acfa7f31cd38d80a",
            "8a236a1def874b15a0b9af13f73a3ff1",
            "e9ef75adffbd4c2a8877a693abb5b764",
            "ea7a36b5f3fb4bb18ec8af5990c2280d",
            "a47944ef9f8247478da61eb76e34ba2c",
            "4f7e41db97614117b5db6441e52fa86f",
            "bfa7f71657a4433396eaf1018d11eff7",
            "eec49f701e6a42be9b635bb8fda3d7e3",
            "5abc8353d5a94c58bf43f2b9fb34313f",
            "b9bac04da3b84cec9ecc685e2693da16",
            "9311a651502a4c08a561b9b38c120d58",
            "ed7e2769b710405c86b99de7d3443156",
            "96e6704c87f64b568fdb8c2a4665ad74",
            "c5ac468752034e41b14ba237988b1393",
            "c7d4c873a9d64c1e91f75c9efecdb750",
            "f46f1368706e4de8882c8794c131f104",
            "305a5b7bce2f41399144a0428cc54d80",
            "d8ef71bf86c44333908b6937fac2888c",
            "09ac404bfd754f248ce5a2f147c736a9",
            "f158db61687f4af59274465248f8e114",
            "37ac2c340c53486aab6119253ceb54f2",
            "ac2822c5dcef4747b7a4ea2716f8818d",
            "74cf21856d944f5b8cd0240aeaf49a22",
            "4d079b323351424f925754c5eafaf2ac",
            "4362219281294239b48eaa1c8041970f",
            "2b3ef5aa3bae4c61b33e1d7888ee6150",
            "6984f8e750c54e98a37786b17341af50",
            "6bd84f8b8e17486d9c9d127133ef051b",
            "f1cdf52756f143cc9a1d4c21a6f18fc4",
            "7c9ecc66e7404ece99e86ce8c97a43f5",
            "413ff24539b14a17bcf9aabd2917ccc9",
            "d554b87e0d474eca971de5c33d5f3faf",
            "21b69f65545e4d67910976f7ff1a4e0e",
            "29fdec53aa4c48968f5c9116fbd5f832",
            "6ded1c207e1c44f3acd1b0bcdd3abdff",
            "d129ba5ae01d44d68c3269422440545f",
            "651539eaeb2f4f7496282aef73f07364",
            "6917331bfbb648119af41729077a89c0",
            "2ce9388c56e04fa581f113c4702ad077",
            "8d913f7f9da747fa970b08b1c7ed9015",
            "32d9065242954d059135cf1bb9c4e29c",
            "63e19eff65f74629a4f14255e37aa0e4",
            "dc31119a106540daaf02664b67b9e54a",
            "1496cbca85294dfc8f216862a56c4040",
            "f449050942ae46058b25066edf94576b",
            "d42971c35fdc4f6d9c052639166a97a2",
            "4c682132cb024f8ea88d2e9f6bb0e7ac",
            "22180f8dde4d4764844ae6175893765d",
            "fe57b466ccc54459b278d25c040be17c",
            "060d67dd014e44568468dd8239ca319f",
            "5154155e38284e809194ec3338103071",
            "a5a7f02c5e944e269c28e3b18d05063c",
            "56f90b34aede44a781799c8b736ded21",
            "38361f21508f40f6a829e7bdf671bde3",
            "24e2bfedb8184301aa0f2887fe3bd54b",
            "419bbba1f1224c5fa72cd07602ac6e02",
            "31607b2431914726b82721c143798110",
            "3d484fbb44464de4a7905415906b7b39",
            "0518cab8c55e4b6d924f7ccf79bd09b6",
            "2a447285cdde41b38d737588b4700738",
            "6f99c9f5ae504cd28e8c6e04a9c5b21b",
            "b6ffaaa7a3a7433fa3218a276152cd41",
            "d5e2660c10fb4287850f019fbdf45474",
            "ab91854e66ea48bbbe7a7bcec9cd1451",
            "7a1bef629a2f4d848b77ad181c95ee8c",
            "1497c45e079f493db60d0a12211a1100",
            "82cbcb4e56e44d5cb43fe955d8395a64"
          ]
        },
        "outputId": "774c537e-18e9-44e9-c962-71310e86415e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2461b42b8de64e1492db4f6f57cbb8b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bee8532a7044a9882b412cf89df5a5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e11053d7e5a0427bb56324cbfb9c391f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36512fbe1e814138a81c07be8e383dcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/556 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967899d2dff9406ab7d20d90a321f964"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5350a5cdc663450ab3fc3a0062610936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/452 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a789ec9358244964a79b765e00e6af2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a236a1def874b15a0b9af13f73a3ff1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96e6704c87f64b568fdb8c2a4665ad74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d079b323351424f925754c5eafaf2ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ded1c207e1c44f3acd1b0bcdd3abdff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d42971c35fdc4f6d9c052639166a97a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31607b2431914726b82721c143798110"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/datas/sample_submission.csv')\n",
        "submit.iloc[:,1:] = pred_emb\n",
        "submit.to_csv(f'/content/drive/MyDrive/DACON/Hansol_QA/results/submits/gguf_test_yanolja_axolotl_v0.2_inst_topk_1_fewshot_submit.csv', index=False)"
      ],
      "metadata": {
        "id": "1Tv0k8yhCARX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "8sDqZnhFu7rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cosine_similarity(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0"
      ],
      "metadata": {
        "id": "Y-w-ZH_6Br-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/results/infer_answers/gguf_test_yanolja_axolotl_v0.2_no_split.csv')\n",
        "res_answer2 = new['answer'].tolist()\n",
        "\n",
        "pred_emb2 = modelEmb.encode(res_answer2)\n",
        "\n",
        "tot = 0\n",
        "\n",
        "for i in range(len(pred_emb)):\n",
        "  tot +=cosine_similarity(pred_emb[i], pred_emb2[i])\n",
        "\n",
        "print(tot/len(pred_emb))"
      ],
      "metadata": {
        "id": "xcoSsaPNMMkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70639013-d274-4cc9-87bd-2b4720ad63dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8551674239910566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU"
      ],
      "metadata": {
        "id": "tHcM1kdCPuYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0\n",
        "\n",
        "def clean_answer(answer):\n",
        "    last_period_index = answer.rfind(\".\")\n",
        "    if last_period_index != -1:\n",
        "        return answer[:last_period_index+1]\n",
        "    else:\n",
        "        return answer"
      ],
      "metadata": {
        "id": "OVphzGWQMMzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq llama-cpp-python\n",
        "!pip install -qq sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIE19T16PpuW",
        "outputId": "5143059c-5a09-4a92-e01c-d9abfe021146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, runtime\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from llama_cpp import Llama\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.auto import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "WUBpXxUCPxGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_start_time = time.time()\n",
        "\n",
        "\n",
        "cfg_batch = 4096\n",
        "cfg_ctx = 512\n",
        "cfg_model = f'ggml-model-q4_1.gguf'\n",
        "model_path = f'/content/drive/MyDrive/DACON/Hansol_QA/model/yanolja_eostoken_target_merged_cp3800/{cfg_model}'"
      ],
      "metadata": {
        "id": "SPc8N4APP25E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "    n_batch=cfg_batch,\n",
        "    model_path=model_path,\n",
        "    n_ctx=cfg_ctx,\n",
        "    n_gpu_layers=-1,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cive8vZlP42s",
        "outputId": "981935a6-fb59-4b16-c84e-428776241526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 435 tensors from /content/drive/MyDrive/DACON/Hansol_QA/model/yanolja_eostoken_target_merged_cp3800/ggml-model-q4_1.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 48\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 3\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,40960]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,40960]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,40960]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   97 tensors\n",
            "llama_model_loader: - type q4_1:  337 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: mismatch in special tokens definition ( 261/40960 vs 260/40960 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 40960\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 48\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 34B\n",
            "llm_load_print_meta: model ftype      = Q4_1\n",
            "llm_load_print_meta: model params     = 10.80 B\n",
            "llm_load_print_meta: model size       = 6.32 GiB (5.03 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 2 '</s>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.17 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6472.77 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    96.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   96.00 MiB, K (f16):   48.00 MiB, V (f16):   48.00 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =    10.01 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    88.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '48', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '3'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_question = []\n",
        "res_answer = []\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"max_tokens\": 100,\n",
        "    \"stop\":[\"<|im_end|>\"],\n",
        "    \"echo\":False,\n",
        "    \"seed\" : 42,\n",
        "    # \"top_k\":1,\n",
        "    # \"top_p\":0.1,\n",
        "    # \"repeat_penalty\" : 1.5,\n",
        "    \"temperature\" : 0.9,\n",
        "}"
      ],
      "metadata": {
        "id": "4mstJBS4P80L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"방청페인트의 종류에 대해 알려줘.\"\n",
        "\n",
        "question1 = f\"### 질문: {q}\\n\\n\"\n",
        "res1 = llm(question1, **generation_kwargs)\n",
        "answer1 = res1[\"choices\"][0][\"text\"].split(\"### 답변: \\n\")[1]\n",
        "answer1 = clean_answer(answer1)\n",
        "print(answer1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3U8FrNmQBTB",
        "outputId": "56569d23-b168-4fc9-d034-16b784a8ada1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    8302.92 ms\n",
            "llama_print_timings:      sample time =      83.42 ms /   100 runs   (    0.83 ms per token,  1198.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =  154313.98 ms /   100 runs   ( 1543.14 ms per token,     0.65 tokens per second)\n",
            "llama_print_timings:       total time =  154999.12 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 방청페인트의 종류로는 광명단페인트, 방청산화철페인트, 알미늄페인트 등이 있습니다. 또한, 페인트에 사용되는 안료에는 다양한 종류가 있으며, 사용 환경과 목적에 따라 적합한 안료를 선택하는 것이 중요합니다. 갱상재료의 특성에 따라 방청페인트는 여러 가지 종류로 분류될 수 있으며, 상황에 맞는 올바른 사용을 위해서는 전문가의 조언을 구하는 것이 좋습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JInN6L0oWK1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV"
      ],
      "metadata": {
        "id": "k24fMV3tWnaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install -qq llama-cpp-python\n",
        "!pip install -qq sentence_transformers"
      ],
      "metadata": {
        "id": "RJb7CT5nWo6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from llama_cpp import Llama\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "_ej7nfC-Wu7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_start_time = time.time()\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/datas/train_processed.csv')\n",
        "df_real_test = pd.read_csv('/content/drive/MyDrive/DACON/Hansol_QA/datas/test_processed.csv')\n",
        "\n",
        "cfg_train_length = len(df_train)//3\n",
        "df_train = df_train.sample(n=cfg_train_length, random_state=4200).reset_index(drop=True)\n",
        "\n",
        "\n",
        "cfg_token = -1\n",
        "cfg_batch = 4096\n",
        "cfg_ctx = 2048\n",
        "cfg_model = f'ggml-model-q8_0.gguf'\n",
        "model_name = f'yanolja-axolotl-random_sampling_data_new_inst'\n",
        "model_path = f'/content/drive/MyDrive/DACON/Hansol_QA/model/{model_name}/{cfg_model}'\n"
      ],
      "metadata": {
        "id": "HNLzwWmbWw4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def cosine_similarity(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    modelEmb = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "\n",
        "    llm = Llama(\n",
        "        n_batch=cfg_batch,\n",
        "        model_path=model_path,\n",
        "        n_ctx=cfg_ctx,\n",
        "        n_gpu_layers=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "    generation_kwargs = {\n",
        "        \"max_tokens\": cfg_token,\n",
        "        \"stop\":[\"<|im_end|>\"],\n",
        "        \"echo\":False,\n",
        "        \"seed\" : 42,\n",
        "        # \"top_k\":1,\n",
        "        # \"top_p\":0.1,\n",
        "        # \"repeat_penalty\" : 1.5,\n",
        "        # \"temperature\" : 0,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYaGAdzGXBXZ",
        "outputId": "16c1ea16-e16a-4d25-92fc-987636b166ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 435 tensors from /content/drive/MyDrive/DACON/Hansol_QA/model/yanolja-axolotl-random_sampling_data_new_inst/ggml-model-q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 48\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,40960]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,40960]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,40960]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   97 tensors\n",
            "llama_model_loader: - type q8_0:  338 tensors\n",
            "llm_load_vocab: mismatch in special tokens definition ( 261/40960 vs 260/40960 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 40960\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 48\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 34B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 10.80 B\n",
            "llm_load_print_meta: model size       = 10.69 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 2 '</s>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.33 MiB\n",
            "llm_load_tensors: offloading 48 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 49/49 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   170.00 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size = 10779.52 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   384.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  384.00 MiB, K (f16):  192.00 MiB, V (f16):  192.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host input buffer size   =    64.04 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   656.01 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    32.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '48', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_time = datetime.datetime.now()\n",
        "current_time = current_time.strftime(\"%D%H%M\").replace('/', '')\n",
        "\n",
        "res_score = []\n",
        "res_q = []\n",
        "res_gt = []\n",
        "res_answer = []\n",
        "\n",
        "for i in tqdm(range(cfg_train_length)):\n",
        "    instruction = \"제시된 각 질문에 대해 상세하고 명확한 설명을 제공하시오.\"\n",
        "\n",
        "    question_with_instruction = f\"{instruction} {df_train['질문_1'][i]}\"\n",
        "\n",
        "    res = llm(question_with_instruction, **generation_kwargs)\n",
        "    a = modelEmb.encode(res[\"choices\"][0][\"text\"])\n",
        "    b1 = modelEmb.encode(df_train['답변_1'][i])\n",
        "    b2 = modelEmb.encode(df_train['답변_2'][i])\n",
        "    b3 = modelEmb.encode(df_train['답변_3'][i])\n",
        "    b4 = modelEmb.encode(df_train['답변_4'][i])\n",
        "    b5 = modelEmb.encode(df_train['답변_5'][i])\n",
        "    cos_sum = cosine_similarity(a, b1) + cosine_similarity(a, b2) + cosine_similarity(a, b3) + cosine_similarity(a, b4) + cosine_similarity(a, b5)\n",
        "    b = (cos_sum)/5\n",
        "\n",
        "    res_q.append(df_train['질문_1'][i])\n",
        "    res_answer.append(res[\"choices\"][0][\"text\"])\n",
        "    res_gt.append(df_train['답변_3'][i])\n",
        "    res_score.append(b)\n",
        "    print(i)\n",
        "\n",
        "res_score_sum = round((sum(res_score))/len(res_score), 6)\n",
        "\n",
        "print(res_score)\n",
        "print(res_score_sum)\n",
        "res_exctime = round(time.time() - cfg_start_time, 2)\n",
        "\n",
        "df_res = pd.DataFrame(res_q)\n",
        "df_res['ans'] = res_answer\n",
        "df_res['gt'] = res_gt\n",
        "df_res['score'] = res_score\n",
        "df_res.to_csv(f'/content/drive/MyDrive/DACON/Hansol_QA/results/CV/{current_time}_{res_score_sum}_{model_name}_{cfg_token}_{cfg_train_length}_{res_exctime}_res_cv.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13598939763a4922b8b6045ebfde5189",
            "eaa7fd44b28a4f148677dc823a137bfb",
            "c4930eef52744441aad91fe5ccd1a201",
            "41fe98cf21d0407d821781e5e8f403ff",
            "ccaf3f8698e34196845868d147c8c803",
            "a2ec0aad06c64c50b1ca752ebc44ef51",
            "d86c9f7ca18e421cbf62254f72408d41",
            "56748c21059a42399226daf5132f166f",
            "e6e7d8c8cced44bba271f400e4df3227",
            "4d52afbd9c594948863c76f5a771bd00",
            "82bbf72cbf2346a39fa4f4c4de5c6af0"
          ]
        },
        "id": "lVozsrOZXNQ7",
        "outputId": "a523bc38-5c50-4fe8-878b-9135eeab8923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/214 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13598939763a4922b8b6045ebfde5189"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      52.39 ms /    64 runs   (    0.82 ms per token,  1221.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     840.07 ms /    28 tokens (   30.00 ms per token,    33.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3311.35 ms /    63 runs   (   52.56 ms per token,    19.03 tokens per second)\n",
            "llama_print_timings:       total time =    4513.06 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     318.56 ms /   419 runs   (    0.76 ms per token,  1315.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     191.74 ms /     7 tokens (   27.39 ms per token,    36.51 tokens per second)\n",
            "llama_print_timings:        eval time =   21891.98 ms /   418 runs   (   52.37 ms per token,    19.09 tokens per second)\n",
            "llama_print_timings:       total time =   24253.65 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      76.84 ms /   102 runs   (    0.75 ms per token,  1327.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     339.15 ms /    14 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
            "llama_print_timings:        eval time =    5352.88 ms /   101 runs   (   53.00 ms per token,    18.87 tokens per second)\n",
            "llama_print_timings:       total time =    6130.90 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     113.39 ms /   139 runs   (    0.82 ms per token,  1225.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     354.20 ms /    14 tokens (   25.30 ms per token,    39.53 tokens per second)\n",
            "llama_print_timings:        eval time =    7383.84 ms /   138 runs   (   53.51 ms per token,    18.69 tokens per second)\n",
            "llama_print_timings:       total time =    8472.97 ms /   152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      62.03 ms /    84 runs   (    0.74 ms per token,  1354.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     456.89 ms /    20 tokens (   22.84 ms per token,    43.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4488.76 ms /    83 runs   (   54.08 ms per token,    18.49 tokens per second)\n",
            "llama_print_timings:       total time =    5307.15 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.02 ms /   111 runs   (    0.87 ms per token,  1156.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.75 ms /    11 tokens (   23.80 ms per token,    42.02 tokens per second)\n",
            "llama_print_timings:        eval time =    5875.15 ms /   110 runs   (   53.41 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =    6760.94 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     204.21 ms /   259 runs   (    0.79 ms per token,  1268.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.13 ms /     9 tokens (   27.46 ms per token,    36.42 tokens per second)\n",
            "llama_print_timings:        eval time =   13597.35 ms /   258 runs   (   52.70 ms per token,    18.97 tokens per second)\n",
            "llama_print_timings:       total time =   15169.61 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      55.81 ms /    76 runs   (    0.73 ms per token,  1361.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.04 ms /     9 tokens (   27.34 ms per token,    36.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3903.99 ms /    75 runs   (   52.05 ms per token,    19.21 tokens per second)\n",
            "llama_print_timings:       total time =    4471.23 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     140.32 ms /   160 runs   (    0.88 ms per token,  1140.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     413.77 ms /    20 tokens (   20.69 ms per token,    48.34 tokens per second)\n",
            "llama_print_timings:        eval time =    8300.26 ms /   159 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    9578.62 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.69 ms /    97 runs   (    0.69 ms per token,  1454.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     506.45 ms /    22 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
            "llama_print_timings:        eval time =    4988.34 ms /    96 runs   (   51.96 ms per token,    19.24 tokens per second)\n",
            "llama_print_timings:       total time =    5902.74 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      56.57 ms /    66 runs   (    0.86 ms per token,  1166.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.69 ms /     9 tokens (   26.30 ms per token,    38.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3399.80 ms /    65 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    4060.84 ms /    74 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     127.67 ms /   154 runs   (    0.83 ms per token,  1206.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     321.55 ms /    15 tokens (   21.44 ms per token,    46.65 tokens per second)\n",
            "llama_print_timings:        eval time =    7975.55 ms /   153 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    9164.67 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     275.88 ms /   344 runs   (    0.80 ms per token,  1246.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.33 ms /    10 tokens (   24.73 ms per token,    40.43 tokens per second)\n",
            "llama_print_timings:        eval time =   18126.90 ms /   343 runs   (   52.85 ms per token,    18.92 tokens per second)\n",
            "llama_print_timings:       total time =   20346.54 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     103.72 ms /   133 runs   (    0.78 ms per token,  1282.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.82 ms /    11 tokens (   22.80 ms per token,    43.86 tokens per second)\n",
            "llama_print_timings:        eval time =    6926.57 ms /   132 runs   (   52.47 ms per token,    19.06 tokens per second)\n",
            "llama_print_timings:       total time =    7794.95 ms /   143 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     345.68 ms /   442 runs   (    0.78 ms per token,  1278.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.44 ms /    10 tokens (   24.64 ms per token,    40.58 tokens per second)\n",
            "llama_print_timings:        eval time =   23262.98 ms /   441 runs   (   52.75 ms per token,    18.96 tokens per second)\n",
            "llama_print_timings:       total time =   25894.55 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     130.97 ms /   174 runs   (    0.75 ms per token,  1328.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     108.22 ms /     8 tokens (   13.53 ms per token,    73.92 tokens per second)\n",
            "llama_print_timings:        eval time =    9035.18 ms /   173 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =   10038.74 ms /   181 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.56 ms /   116 runs   (    0.83 ms per token,  1201.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.61 ms /     9 tokens (   27.51 ms per token,    36.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6015.66 ms /   115 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    6948.46 ms /   124 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     524.63 ms /   658 runs   (    0.80 ms per token,  1254.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.84 ms /    11 tokens (   22.44 ms per token,    44.56 tokens per second)\n",
            "llama_print_timings:        eval time =   34844.77 ms /   657 runs   (   53.04 ms per token,    18.86 tokens per second)\n",
            "llama_print_timings:       total time =   38905.30 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      88.59 ms /   119 runs   (    0.74 ms per token,  1343.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.74 ms /    11 tokens (   22.25 ms per token,    44.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6160.31 ms /   118 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    6942.46 ms /   129 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     106.58 ms /   133 runs   (    0.80 ms per token,  1247.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     334.31 ms /    15 tokens (   22.29 ms per token,    44.87 tokens per second)\n",
            "llama_print_timings:        eval time =    6892.82 ms /   132 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7970.69 ms /   147 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      45.27 ms /    63 runs   (    0.72 ms per token,  1391.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.00 ms /    10 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3241.53 ms /    62 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    3770.01 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      58.00 ms /    78 runs   (    0.74 ms per token,  1344.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     430.00 ms /    18 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4016.51 ms /    77 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    4830.55 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      53.23 ms /    62 runs   (    0.86 ms per token,  1164.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.20 ms /    10 tokens (   24.42 ms per token,    40.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3186.11 ms /    61 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    3817.15 ms /    71 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      68.91 ms /    91 runs   (    0.76 ms per token,  1320.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     422.05 ms /    19 tokens (   22.21 ms per token,    45.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4696.84 ms /    90 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    5533.97 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     112.76 ms /   138 runs   (    0.82 ms per token,  1223.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     508.80 ms /    21 tokens (   24.23 ms per token,    41.27 tokens per second)\n",
            "llama_print_timings:        eval time =    7152.27 ms /   137 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    8455.93 ms /   158 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.83 ms /   102 runs   (    0.74 ms per token,  1345.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.76 ms /    10 tokens (   24.68 ms per token,    40.52 tokens per second)\n",
            "llama_print_timings:        eval time =    5269.86 ms /   101 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5972.20 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      85.17 ms /   107 runs   (    0.80 ms per token,  1256.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.57 ms /    12 tokens (   20.88 ms per token,    47.89 tokens per second)\n",
            "llama_print_timings:        eval time =    5539.17 ms /   106 runs   (   52.26 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    6391.33 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      87.13 ms /   125 runs   (    0.70 ms per token,  1434.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     416.48 ms /    17 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
            "llama_print_timings:        eval time =    6486.84 ms /   124 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    7444.73 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     610.70 ms /   737 runs   (    0.83 ms per token,  1206.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.98 ms /     9 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
            "llama_print_timings:        eval time =   39091.39 ms /   736 runs   (   53.11 ms per token,    18.83 tokens per second)\n",
            "llama_print_timings:       total time =   43741.56 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     135.15 ms /   183 runs   (    0.74 ms per token,  1354.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.28 ms /    10 tokens (   25.23 ms per token,    39.64 tokens per second)\n",
            "llama_print_timings:        eval time =    9481.91 ms /   182 runs   (   52.10 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =   10628.52 ms /   192 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      79.48 ms /   100 runs   (    0.79 ms per token,  1258.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     325.84 ms /    16 tokens (   20.36 ms per token,    49.10 tokens per second)\n",
            "llama_print_timings:        eval time =    5168.37 ms /    99 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    6036.75 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      97.01 ms /   121 runs   (    0.80 ms per token,  1247.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     108.53 ms /     8 tokens (   13.57 ms per token,    73.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6266.32 ms /   120 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7006.12 ms /   128 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      73.92 ms /    95 runs   (    0.78 ms per token,  1285.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.47 ms /    12 tokens (   20.46 ms per token,    48.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4912.14 ms /    94 runs   (   52.26 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    5654.07 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     118.95 ms /   149 runs   (    0.80 ms per token,  1252.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     333.24 ms /    13 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
            "llama_print_timings:        eval time =    7774.73 ms /   148 runs   (   52.53 ms per token,    19.04 tokens per second)\n",
            "llama_print_timings:       total time =    8912.48 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      94.05 ms /   126 runs   (    0.75 ms per token,  1339.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.50 ms /    15 tokens (   22.10 ms per token,    45.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6554.94 ms /   125 runs   (   52.44 ms per token,    19.07 tokens per second)\n",
            "llama_print_timings:       total time =    7447.20 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      74.17 ms /    93 runs   (    0.80 ms per token,  1253.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.47 ms /    12 tokens (   20.87 ms per token,    47.91 tokens per second)\n",
            "llama_print_timings:        eval time =    4821.78 ms /    92 runs   (   52.41 ms per token,    19.08 tokens per second)\n",
            "llama_print_timings:       total time =    5628.84 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      86.44 ms /   118 runs   (    0.73 ms per token,  1365.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.95 ms /    10 tokens (   24.49 ms per token,    40.83 tokens per second)\n",
            "llama_print_timings:        eval time =    6119.58 ms /   117 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    6921.41 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     293.63 ms /   359 runs   (    0.82 ms per token,  1222.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.50 ms /    10 tokens (   24.25 ms per token,    41.24 tokens per second)\n",
            "llama_print_timings:        eval time =   18821.42 ms /   358 runs   (   52.57 ms per token,    19.02 tokens per second)\n",
            "llama_print_timings:       total time =   21112.50 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      85.37 ms /   115 runs   (    0.74 ms per token,  1347.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     327.57 ms /    13 tokens (   25.20 ms per token,    39.69 tokens per second)\n",
            "llama_print_timings:        eval time =    5961.40 ms /   114 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    6815.65 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      63.05 ms /    71 runs   (    0.89 ms per token,  1126.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.97 ms /    10 tokens (   24.60 ms per token,    40.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3664.00 ms /    70 runs   (   52.34 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    4376.96 ms /    80 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      48.76 ms /    64 runs   (    0.76 ms per token,  1312.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =      87.94 ms /     6 tokens (   14.66 ms per token,    68.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3288.01 ms /    63 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    3675.33 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.79 ms /    79 runs   (    0.73 ms per token,  1367.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.90 ms /    10 tokens (   24.79 ms per token,    40.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4061.86 ms /    78 runs   (   52.08 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    4671.74 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      71.46 ms /    84 runs   (    0.85 ms per token,  1175.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.74 ms /    11 tokens (   22.43 ms per token,    44.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4343.28 ms /    83 runs   (   52.33 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    5134.98 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      88.99 ms /   120 runs   (    0.74 ms per token,  1348.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     428.13 ms /    17 tokens (   25.18 ms per token,    39.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6208.94 ms /   119 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    7210.33 ms /   136 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     119.72 ms /   145 runs   (    0.83 ms per token,  1211.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     336.50 ms /    14 tokens (   24.04 ms per token,    41.61 tokens per second)\n",
            "llama_print_timings:        eval time =    7502.17 ms /   144 runs   (   52.10 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    8652.18 ms /   158 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     118.91 ms /   152 runs   (    0.78 ms per token,  1278.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.29 ms /    10 tokens (   24.73 ms per token,    40.44 tokens per second)\n",
            "llama_print_timings:        eval time =    7872.51 ms /   151 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    8903.84 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      85.22 ms /   114 runs   (    0.75 ms per token,  1337.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     411.03 ms /    20 tokens (   20.55 ms per token,    48.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5896.31 ms /   113 runs   (   52.18 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    6851.94 ms /   133 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.15 ms /    95 runs   (    0.79 ms per token,  1264.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     510.26 ms /    21 tokens (   24.30 ms per token,    41.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4915.52 ms /    94 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5933.92 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     114.56 ms /   156 runs   (    0.73 ms per token,  1361.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     325.44 ms /    16 tokens (   20.34 ms per token,    49.16 tokens per second)\n",
            "llama_print_timings:        eval time =    8090.90 ms /   155 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    9189.38 ms /   171 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      86.11 ms /   104 runs   (    0.83 ms per token,  1207.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.32 ms /    12 tokens (   20.69 ms per token,    48.33 tokens per second)\n",
            "llama_print_timings:        eval time =    5365.50 ms /   103 runs   (   52.09 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    6249.73 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      76.31 ms /   105 runs   (    0.73 ms per token,  1375.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.44 ms /     9 tokens (   27.38 ms per token,    36.52 tokens per second)\n",
            "llama_print_timings:        eval time =    5426.41 ms /   104 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    6151.72 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     100.28 ms /   134 runs   (    0.75 ms per token,  1336.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     341.46 ms /    14 tokens (   24.39 ms per token,    41.00 tokens per second)\n",
            "llama_print_timings:        eval time =    6933.81 ms /   133 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    8020.31 ms /   147 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      54.28 ms /    74 runs   (    0.73 ms per token,  1363.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.80 ms /     9 tokens (   26.98 ms per token,    37.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3800.41 ms /    73 runs   (   52.06 ms per token,    19.21 tokens per second)\n",
            "llama_print_timings:       total time =    4381.51 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     103.87 ms /   125 runs   (    0.83 ms per token,  1203.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     340.31 ms /    16 tokens (   21.27 ms per token,    47.02 tokens per second)\n",
            "llama_print_timings:        eval time =    6484.73 ms /   124 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    7539.20 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     194.47 ms /   252 runs   (    0.77 ms per token,  1295.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.43 ms /     9 tokens (   26.83 ms per token,    37.28 tokens per second)\n",
            "llama_print_timings:        eval time =   13120.46 ms /   251 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =   14725.09 ms /   260 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      67.59 ms /    92 runs   (    0.73 ms per token,  1361.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.93 ms /    12 tokens (   20.41 ms per token,    48.99 tokens per second)\n",
            "llama_print_timings:        eval time =    4739.78 ms /    91 runs   (   52.09 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    5415.26 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.22 ms /   102 runs   (    0.79 ms per token,  1271.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.44 ms /    10 tokens (   24.54 ms per token,    40.74 tokens per second)\n",
            "llama_print_timings:        eval time =    5276.76 ms /   101 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    6118.29 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      73.48 ms /    99 runs   (    0.74 ms per token,  1347.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     333.43 ms /    13 tokens (   25.65 ms per token,    38.99 tokens per second)\n",
            "llama_print_timings:        eval time =    5112.60 ms /    98 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5885.72 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      95.17 ms /   117 runs   (    0.81 ms per token,  1229.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     339.44 ms /    15 tokens (   22.63 ms per token,    44.19 tokens per second)\n",
            "llama_print_timings:        eval time =    6066.69 ms /   116 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    7079.03 ms /   131 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      54.06 ms /    73 runs   (    0.74 ms per token,  1350.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     338.68 ms /    13 tokens (   26.05 ms per token,    38.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3756.22 ms /    72 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    4426.98 ms /    85 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.61 ms /   116 runs   (    0.83 ms per token,  1200.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.48 ms /    10 tokens (   24.05 ms per token,    41.58 tokens per second)\n",
            "llama_print_timings:        eval time =    6016.93 ms /   115 runs   (   52.32 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    6930.15 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     105.85 ms /   146 runs   (    0.73 ms per token,  1379.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     106.97 ms /     8 tokens (   13.37 ms per token,    74.79 tokens per second)\n",
            "llama_print_timings:        eval time =    7571.58 ms /   145 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    8384.14 ms /   153 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      90.66 ms /   113 runs   (    0.80 ms per token,  1246.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     334.38 ms /    15 tokens (   22.29 ms per token,    44.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5854.86 ms /   112 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    6859.75 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      60.13 ms /    84 runs   (    0.72 ms per token,  1397.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     338.56 ms /    14 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4327.84 ms /    83 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5046.39 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      63.35 ms /    78 runs   (    0.81 ms per token,  1231.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     411.52 ms /    17 tokens (   24.21 ms per token,    41.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.09 ms /    77 runs   (   52.43 ms per token,    19.07 tokens per second)\n",
            "llama_print_timings:       total time =    4906.74 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      89.03 ms /   121 runs   (    0.74 ms per token,  1359.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.03 ms /    10 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
            "llama_print_timings:        eval time =    6265.09 ms /   120 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7079.25 ms /   130 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      51.47 ms /    67 runs   (    0.77 ms per token,  1301.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.73 ms /     9 tokens (   26.97 ms per token,    37.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3446.73 ms /    66 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    4016.72 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     101.79 ms /   134 runs   (    0.76 ms per token,  1316.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.39 ms /    12 tokens (   20.53 ms per token,    48.70 tokens per second)\n",
            "llama_print_timings:        eval time =    6928.62 ms /   133 runs   (   52.09 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    7891.23 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     138.31 ms /   174 runs   (    0.79 ms per token,  1258.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.46 ms /    12 tokens (   20.12 ms per token,    49.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9057.58 ms /   173 runs   (   52.36 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =   10275.18 ms /   185 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      84.49 ms /   116 runs   (    0.73 ms per token,  1372.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.91 ms /    14 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
            "llama_print_timings:        eval time =    5998.12 ms /   115 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    6858.18 ms /   129 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     111.07 ms /   105 runs   (    1.06 ms per token,   945.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.36 ms /    11 tokens (   22.03 ms per token,    45.39 tokens per second)\n",
            "llama_print_timings:        eval time =    5484.77 ms /   104 runs   (   52.74 ms per token,    18.96 tokens per second)\n",
            "llama_print_timings:       total time =    6484.39 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     101.76 ms /   137 runs   (    0.74 ms per token,  1346.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.16 ms /     9 tokens (   27.46 ms per token,    36.41 tokens per second)\n",
            "llama_print_timings:        eval time =    7094.91 ms /   136 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    7992.60 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      77.92 ms /    97 runs   (    0.80 ms per token,  1244.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     108.13 ms /     8 tokens (   13.52 ms per token,    73.98 tokens per second)\n",
            "llama_print_timings:        eval time =    5015.03 ms /    96 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    5659.92 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      65.67 ms /    89 runs   (    0.74 ms per token,  1355.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     424.94 ms /    18 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4596.07 ms /    88 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5429.37 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      67.98 ms /    89 runs   (    0.76 ms per token,  1309.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     415.08 ms /    18 tokens (   23.06 ms per token,    43.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4603.56 ms /    88 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5582.26 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      61.87 ms /    84 runs   (    0.74 ms per token,  1357.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     328.04 ms /    13 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4344.12 ms /    83 runs   (   52.34 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    5085.40 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.90 ms /   113 runs   (    0.86 ms per token,  1166.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.23 ms /    11 tokens (   22.66 ms per token,    44.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5854.92 ms /   112 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    6785.57 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      94.84 ms /   133 runs   (    0.71 ms per token,  1402.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     111.67 ms /     8 tokens (   13.96 ms per token,    71.64 tokens per second)\n",
            "llama_print_timings:        eval time =    6894.38 ms /   132 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7598.66 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      91.76 ms /   113 runs   (    0.81 ms per token,  1231.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     340.69 ms /    13 tokens (   26.21 ms per token,    38.16 tokens per second)\n",
            "llama_print_timings:        eval time =    5848.34 ms /   112 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    6837.69 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     147.87 ms /   189 runs   (    0.78 ms per token,  1278.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     112.38 ms /     8 tokens (   14.05 ms per token,    71.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9805.34 ms /   188 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =   10907.04 ms /   196 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      65.92 ms /    89 runs   (    0.74 ms per token,  1350.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     326.50 ms /    14 tokens (   23.32 ms per token,    42.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4601.16 ms /    88 runs   (   52.29 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    5349.13 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     127.09 ms /   160 runs   (    0.79 ms per token,  1258.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     102.23 ms /     7 tokens (   14.61 ms per token,    68.47 tokens per second)\n",
            "llama_print_timings:        eval time =    8315.57 ms /   159 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    9347.76 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     170.49 ms /   213 runs   (    0.80 ms per token,  1249.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.45 ms /    10 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
            "llama_print_timings:        eval time =   11071.95 ms /   212 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =   12484.24 ms /   222 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      58.56 ms /    91 runs   (    0.64 ms per token,  1553.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     419.79 ms /    19 tokens (   22.09 ms per token,    45.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4693.74 ms /    90 runs   (   52.15 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5534.20 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.97 ms /    87 runs   (    0.77 ms per token,  1299.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.71 ms /    11 tokens (   22.16 ms per token,    45.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4490.39 ms /    86 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5188.03 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      67.81 ms /    86 runs   (    0.79 ms per token,  1268.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.67 ms /    10 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4426.56 ms /    85 runs   (   52.08 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    5131.46 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      63.26 ms /    90 runs   (    0.70 ms per token,  1422.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.93 ms /    11 tokens (   22.54 ms per token,    44.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4647.51 ms /    89 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5295.92 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      84.92 ms /   123 runs   (    0.69 ms per token,  1448.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.44 ms /     9 tokens (   26.83 ms per token,    37.28 tokens per second)\n",
            "llama_print_timings:        eval time =    6384.16 ms /   122 runs   (   52.33 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    7346.53 ms /   131 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     183.77 ms /   231 runs   (    0.80 ms per token,  1256.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     426.87 ms /    17 tokens (   25.11 ms per token,    39.83 tokens per second)\n",
            "llama_print_timings:        eval time =   12044.34 ms /   230 runs   (   52.37 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =   13727.48 ms /   247 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      50.12 ms /    69 runs   (    0.73 ms per token,  1376.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =      99.80 ms /     7 tokens (   14.26 ms per token,    70.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3559.62 ms /    68 runs   (   52.35 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    3958.56 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     148.63 ms /   194 runs   (    0.77 ms per token,  1305.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     430.08 ms /    18 tokens (   23.89 ms per token,    41.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10115.73 ms /   193 runs   (   52.41 ms per token,    19.08 tokens per second)\n",
            "llama_print_timings:       total time =   11560.25 ms /   211 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      90.31 ms /   112 runs   (    0.81 ms per token,  1240.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.27 ms /    12 tokens (   21.11 ms per token,    47.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5814.82 ms /   111 runs   (   52.39 ms per token,    19.09 tokens per second)\n",
            "llama_print_timings:       total time =    6715.31 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      59.61 ms /    82 runs   (    0.73 ms per token,  1375.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.71 ms /     9 tokens (   27.08 ms per token,    36.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4226.22 ms /    81 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    4861.07 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      86.17 ms /   108 runs   (    0.80 ms per token,  1253.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.67 ms /    12 tokens (   20.72 ms per token,    48.26 tokens per second)\n",
            "llama_print_timings:        eval time =    5615.78 ms /   107 runs   (   52.48 ms per token,    19.05 tokens per second)\n",
            "llama_print_timings:       total time =    6454.91 ms /   119 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.49 ms /    98 runs   (    0.77 ms per token,  1298.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.46 ms /    11 tokens (   22.31 ms per token,    44.81 tokens per second)\n",
            "llama_print_timings:        eval time =    5078.38 ms /    97 runs   (   52.35 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    5835.90 ms /   108 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     155.53 ms /   195 runs   (    0.80 ms per token,  1253.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =      97.75 ms /     7 tokens (   13.96 ms per token,    71.61 tokens per second)\n",
            "llama_print_timings:        eval time =   10149.61 ms /   194 runs   (   52.32 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =   11273.14 ms /   201 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.49 ms /    80 runs   (    0.72 ms per token,  1391.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.90 ms /     9 tokens (   27.21 ms per token,    36.75 tokens per second)\n",
            "llama_print_timings:        eval time =    4126.16 ms /    79 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    4726.16 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     196.59 ms /   256 runs   (    0.77 ms per token,  1302.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     108.38 ms /     8 tokens (   13.55 ms per token,    73.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13337.01 ms /   255 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =   14761.61 ms /   263 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     127.60 ms /   158 runs   (    0.81 ms per token,  1238.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.72 ms /     9 tokens (   27.41 ms per token,    36.48 tokens per second)\n",
            "llama_print_timings:        eval time =    8187.06 ms /   157 runs   (   52.15 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    9330.53 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      61.67 ms /    83 runs   (    0.74 ms per token,  1345.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.25 ms /    10 tokens (   24.62 ms per token,    40.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4262.30 ms /    82 runs   (   51.98 ms per token,    19.24 tokens per second)\n",
            "llama_print_timings:       total time =    4919.12 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      74.22 ms /    93 runs   (    0.80 ms per token,  1253.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     326.91 ms /    15 tokens (   21.79 ms per token,    45.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4797.57 ms /    92 runs   (   52.15 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5655.21 ms /   107 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.49 ms /    93 runs   (    0.81 ms per token,  1232.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     327.93 ms /    15 tokens (   21.86 ms per token,    45.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4794.19 ms /    92 runs   (   52.11 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    5646.29 ms /   107 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      72.46 ms /    91 runs   (    0.80 ms per token,  1255.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.14 ms /    11 tokens (   22.47 ms per token,    44.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4694.44 ms /    90 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5491.67 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     108.69 ms /   149 runs   (    0.73 ms per token,  1370.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     111.74 ms /     8 tokens (   13.97 ms per token,    71.59 tokens per second)\n",
            "llama_print_timings:        eval time =    7703.94 ms /   148 runs   (   52.05 ms per token,    19.21 tokens per second)\n",
            "llama_print_timings:       total time =    8488.61 ms /   156 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     103.80 ms /   134 runs   (    0.77 ms per token,  1290.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     420.08 ms /    18 tokens (   23.34 ms per token,    42.85 tokens per second)\n",
            "llama_print_timings:        eval time =    6943.85 ms /   133 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    8123.35 ms /   151 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      47.12 ms /    65 runs   (    0.72 ms per token,  1379.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.33 ms /    11 tokens (   22.48 ms per token,    44.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3331.68 ms /    64 runs   (   52.06 ms per token,    19.21 tokens per second)\n",
            "llama_print_timings:       total time =    3888.73 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.55 ms /   117 runs   (    0.83 ms per token,  1211.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.50 ms /    11 tokens (   22.05 ms per token,    45.36 tokens per second)\n",
            "llama_print_timings:        eval time =    6050.41 ms /   116 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    6974.03 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     171.49 ms /   222 runs   (    0.77 ms per token,  1294.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.80 ms /     9 tokens (   26.76 ms per token,    37.38 tokens per second)\n",
            "llama_print_timings:        eval time =   11551.70 ms /   221 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =   12963.71 ms /   230 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      56.95 ms /    79 runs   (    0.72 ms per token,  1387.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =      98.19 ms /     7 tokens (   14.03 ms per token,    71.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4065.07 ms /    78 runs   (   52.12 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    4513.43 ms /    85 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     160.05 ms /   206 runs   (    0.78 ms per token,  1287.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.38 ms /     9 tokens (   27.38 ms per token,    36.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10699.30 ms /   205 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =   12018.44 ms /   214 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      78.16 ms /    97 runs   (    0.81 ms per token,  1241.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     510.11 ms /    21 tokens (   24.29 ms per token,    41.17 tokens per second)\n",
            "llama_print_timings:        eval time =    5010.70 ms /    96 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    6097.36 ms /   117 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      44.09 ms /    60 runs   (    0.73 ms per token,  1360.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.34 ms /    13 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3081.33 ms /    59 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    3709.64 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.78 ms /    90 runs   (    0.74 ms per token,  1347.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.13 ms /    10 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4640.25 ms /    89 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5308.71 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     202.08 ms /   268 runs   (    0.75 ms per token,  1326.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     330.98 ms /    16 tokens (   20.69 ms per token,    48.34 tokens per second)\n",
            "llama_print_timings:        eval time =   13980.25 ms /   267 runs   (   52.36 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =   15763.24 ms /   283 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.10 ms /    84 runs   (    0.79 ms per token,  1270.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.84 ms /    12 tokens (   20.40 ms per token,    49.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4331.44 ms /    83 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    5010.26 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      71.84 ms /    98 runs   (    0.73 ms per token,  1364.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     337.14 ms /    16 tokens (   21.07 ms per token,    47.46 tokens per second)\n",
            "llama_print_timings:        eval time =    5064.74 ms /    97 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5842.00 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      81.82 ms /    96 runs   (    0.85 ms per token,  1173.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     428.99 ms /    18 tokens (   23.83 ms per token,    41.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4981.01 ms /    95 runs   (   52.43 ms per token,    19.07 tokens per second)\n",
            "llama_print_timings:       total time =    6008.31 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      83.43 ms /   115 runs   (    0.73 ms per token,  1378.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     342.45 ms /    15 tokens (   22.83 ms per token,    43.80 tokens per second)\n",
            "llama_print_timings:        eval time =    5956.71 ms /   114 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    6851.69 ms /   129 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      85.49 ms /   101 runs   (    0.85 ms per token,  1181.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.75 ms /    16 tokens (   20.80 ms per token,    48.08 tokens per second)\n",
            "llama_print_timings:        eval time =    5255.88 ms /   100 runs   (   52.56 ms per token,    19.03 tokens per second)\n",
            "llama_print_timings:       total time =    6208.55 ms /   116 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      53.09 ms /    75 runs   (    0.71 ms per token,  1412.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.76 ms /    12 tokens (   20.40 ms per token,    49.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3869.16 ms /    74 runs   (   52.29 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    4436.94 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     223.62 ms /   299 runs   (    0.75 ms per token,  1337.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.92 ms /    14 tokens (   23.71 ms per token,    42.18 tokens per second)\n",
            "llama_print_timings:        eval time =   15645.94 ms /   298 runs   (   52.50 ms per token,    19.05 tokens per second)\n",
            "llama_print_timings:       total time =   17547.65 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     109.91 ms /   141 runs   (    0.78 ms per token,  1282.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.17 ms /     9 tokens (   26.91 ms per token,    37.16 tokens per second)\n",
            "llama_print_timings:        eval time =    7306.78 ms /   140 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    8279.17 ms /   149 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     142.46 ms /   199 runs   (    0.72 ms per token,  1396.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     330.42 ms /    13 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
            "llama_print_timings:        eval time =   10352.73 ms /   198 runs   (   52.29 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =   11765.53 ms /   211 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     119.07 ms /   146 runs   (    0.82 ms per token,  1226.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.77 ms /    15 tokens (   22.12 ms per token,    45.21 tokens per second)\n",
            "llama_print_timings:        eval time =    7581.90 ms /   145 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    8748.36 ms /   160 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      98.45 ms /   133 runs   (    0.74 ms per token,  1350.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     419.04 ms /    20 tokens (   20.95 ms per token,    47.73 tokens per second)\n",
            "llama_print_timings:        eval time =    6892.40 ms /   132 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7922.10 ms /   152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      97.26 ms /   119 runs   (    0.82 ms per token,  1223.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     333.38 ms /    16 tokens (   20.84 ms per token,    47.99 tokens per second)\n",
            "llama_print_timings:        eval time =    6169.43 ms /   118 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    7179.63 ms /   134 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      47.14 ms /    63 runs   (    0.75 ms per token,  1336.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.67 ms /    11 tokens (   22.70 ms per token,    44.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3232.91 ms /    62 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    3768.20 ms /    73 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      84.70 ms /   104 runs   (    0.81 ms per token,  1227.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.81 ms /    13 tokens (   25.52 ms per token,    39.18 tokens per second)\n",
            "llama_print_timings:        eval time =    5395.65 ms /   103 runs   (   52.38 ms per token,    19.09 tokens per second)\n",
            "llama_print_timings:       total time =    6363.03 ms /   116 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     114.11 ms /   157 runs   (    0.73 ms per token,  1375.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.50 ms /     9 tokens (   27.17 ms per token,    36.81 tokens per second)\n",
            "llama_print_timings:        eval time =    8132.87 ms /   156 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    9117.76 ms /   165 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      79.77 ms /    96 runs   (    0.83 ms per token,  1203.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     329.05 ms /    14 tokens (   23.50 ms per token,    42.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4961.33 ms /    95 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5868.06 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     175.72 ms /   218 runs   (    0.81 ms per token,  1240.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     110.18 ms /     8 tokens (   13.77 ms per token,    72.61 tokens per second)\n",
            "llama_print_timings:        eval time =   11337.81 ms /   217 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =   12594.37 ms /   225 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.53 ms /    78 runs   (    0.74 ms per token,  1355.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.17 ms /    10 tokens (   24.42 ms per token,    40.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4010.56 ms /    77 runs   (   52.09 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    4611.39 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      71.08 ms /    89 runs   (    0.80 ms per token,  1252.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.28 ms /    10 tokens (   24.43 ms per token,    40.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4601.67 ms /    88 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5334.43 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      88.10 ms /   116 runs   (    0.76 ms per token,  1316.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     324.76 ms /    13 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
            "llama_print_timings:        eval time =    6007.41 ms /   115 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    6927.30 ms /   128 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      76.66 ms /    98 runs   (    0.78 ms per token,  1278.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     334.10 ms /    14 tokens (   23.86 ms per token,    41.90 tokens per second)\n",
            "llama_print_timings:        eval time =    5061.05 ms /    97 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5947.43 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      60.23 ms /    79 runs   (    0.76 ms per token,  1311.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.34 ms /    10 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4064.90 ms /    78 runs   (   52.11 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    4728.51 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      71.04 ms /    96 runs   (    0.74 ms per token,  1351.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     328.04 ms /    13 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4953.38 ms /    95 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5715.95 ms /   108 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      63.47 ms /    77 runs   (    0.82 ms per token,  1213.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.33 ms /    10 tokens (   24.53 ms per token,    40.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3974.14 ms /    76 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    4704.58 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      58.96 ms /    80 runs   (    0.74 ms per token,  1356.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.10 ms /    10 tokens (   24.61 ms per token,    40.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4114.64 ms /    79 runs   (   52.08 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    4715.92 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      61.38 ms /    84 runs   (    0.73 ms per token,  1368.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.01 ms /    12 tokens (   20.50 ms per token,    48.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4337.35 ms /    83 runs   (   52.26 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    4984.08 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     142.09 ms /   176 runs   (    0.81 ms per token,  1238.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =      97.41 ms /     7 tokens (   13.92 ms per token,    71.86 tokens per second)\n",
            "llama_print_timings:        eval time =    9138.14 ms /   175 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =   10160.60 ms /   182 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.16 ms /    91 runs   (    0.83 ms per token,  1210.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.89 ms /     9 tokens (   27.54 ms per token,    36.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4724.53 ms /    90 runs   (   52.49 ms per token,    19.05 tokens per second)\n",
            "llama_print_timings:       total time =    5557.27 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     177.44 ms /   220 runs   (    0.81 ms per token,  1239.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     106.17 ms /     8 tokens (   13.27 ms per token,    75.35 tokens per second)\n",
            "llama_print_timings:        eval time =   11441.02 ms /   219 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =   12766.97 ms /   227 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     245.43 ms /   356 runs   (    0.69 ms per token,  1450.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     325.32 ms /    15 tokens (   21.69 ms per token,    46.11 tokens per second)\n",
            "llama_print_timings:        eval time =   18668.27 ms /   355 runs   (   52.59 ms per token,    19.02 tokens per second)\n",
            "llama_print_timings:       total time =   20787.83 ms /   370 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.09 ms /   100 runs   (    0.80 ms per token,  1248.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =      68.86 ms /     5 tokens (   13.77 ms per token,    72.61 tokens per second)\n",
            "llama_print_timings:        eval time =    5176.85 ms /    99 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5848.05 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     174.08 ms /   231 runs   (    0.75 ms per token,  1326.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.73 ms /    11 tokens (   22.07 ms per token,    45.32 tokens per second)\n",
            "llama_print_timings:        eval time =   12015.31 ms /   230 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =   13527.72 ms /   241 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      39.64 ms /    55 runs   (    0.72 ms per token,  1387.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.92 ms /    15 tokens (   22.13 ms per token,    45.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2840.30 ms /    54 runs   (   52.60 ms per token,    19.01 tokens per second)\n",
            "llama_print_timings:       total time =    3431.56 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      47.58 ms /    68 runs   (    0.70 ms per token,  1429.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     420.94 ms /    17 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3514.86 ms /    67 runs   (   52.46 ms per token,    19.06 tokens per second)\n",
            "llama_print_timings:       total time =    4232.90 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.58 ms /    78 runs   (    0.85 ms per token,  1171.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.38 ms /    10 tokens (   24.64 ms per token,    40.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4022.36 ms /    77 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    4757.74 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.20 ms /    92 runs   (    0.72 ms per token,  1389.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.62 ms /     9 tokens (   27.51 ms per token,    36.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4754.32 ms /    91 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    5414.57 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.36 ms /   103 runs   (    0.78 ms per token,  1281.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     329.19 ms /    14 tokens (   23.51 ms per token,    42.53 tokens per second)\n",
            "llama_print_timings:        eval time =    5340.99 ms /   102 runs   (   52.36 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    6239.30 ms /   116 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      96.37 ms /   137 runs   (    0.70 ms per token,  1421.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.38 ms /     9 tokens (   27.15 ms per token,    36.83 tokens per second)\n",
            "llama_print_timings:        eval time =    7114.67 ms /   136 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    8009.52 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.80 ms /    86 runs   (    0.78 ms per token,  1287.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     514.50 ms /    21 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4451.03 ms /    85 runs   (   52.37 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    5517.04 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.73 ms /    80 runs   (    0.72 ms per token,  1385.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.81 ms /     9 tokens (   27.09 ms per token,    36.91 tokens per second)\n",
            "llama_print_timings:        eval time =    4123.07 ms /    79 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    4756.96 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      87.60 ms /   115 runs   (    0.76 ms per token,  1312.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.02 ms /    12 tokens (   20.42 ms per token,    48.98 tokens per second)\n",
            "llama_print_timings:        eval time =    5963.04 ms /   114 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    6813.19 ms /   126 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      71.61 ms /    95 runs   (    0.75 ms per token,  1326.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     413.40 ms /    18 tokens (   22.97 ms per token,    43.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4917.27 ms /    94 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5814.36 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      54.15 ms /    73 runs   (    0.74 ms per token,  1348.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.50 ms /    10 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3763.76 ms /    72 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    4341.66 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      89.22 ms /   105 runs   (    0.85 ms per token,  1176.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     333.46 ms /    14 tokens (   23.82 ms per token,    41.98 tokens per second)\n",
            "llama_print_timings:        eval time =    5437.10 ms /   104 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    6389.06 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      82.10 ms /   109 runs   (    0.75 ms per token,  1327.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.05 ms /    10 tokens (   24.50 ms per token,    40.81 tokens per second)\n",
            "llama_print_timings:        eval time =    5631.40 ms /   108 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    6378.48 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      95.66 ms /   114 runs   (    0.84 ms per token,  1191.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     326.67 ms /    13 tokens (   25.13 ms per token,    39.80 tokens per second)\n",
            "llama_print_timings:        eval time =    5917.31 ms /   113 runs   (   52.37 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =    6935.46 ms /   126 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     129.42 ms /   174 runs   (    0.74 ms per token,  1344.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.14 ms /    12 tokens (   20.76 ms per token,    48.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9043.40 ms /   173 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =   10245.66 ms /   185 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      58.04 ms /    75 runs   (    0.77 ms per token,  1292.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     108.17 ms /     8 tokens (   13.52 ms per token,    73.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3865.11 ms /    74 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    4341.69 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     145.25 ms /   181 runs   (    0.80 ms per token,  1246.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.63 ms /     9 tokens (   26.63 ms per token,    37.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9387.42 ms /   180 runs   (   52.15 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =   10620.60 ms /   189 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      49.73 ms /    69 runs   (    0.72 ms per token,  1387.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     331.06 ms /    15 tokens (   22.07 ms per token,    45.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3554.01 ms /    68 runs   (   52.26 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    4190.90 ms /    83 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      40.09 ms /    57 runs   (    0.70 ms per token,  1421.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.12 ms /    11 tokens (   22.47 ms per token,    44.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.23 ms /    56 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    3427.92 ms /    67 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      79.34 ms /    96 runs   (    0.83 ms per token,  1210.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.88 ms /     9 tokens (   26.88 ms per token,    37.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4957.99 ms /    95 runs   (   52.19 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    5781.23 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     102.39 ms /   141 runs   (    0.73 ms per token,  1377.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     503.54 ms /    23 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
            "llama_print_timings:        eval time =    7308.15 ms /   140 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    8507.13 ms /   163 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      88.80 ms /   108 runs   (    0.82 ms per token,  1216.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     327.50 ms /    16 tokens (   20.47 ms per token,    48.85 tokens per second)\n",
            "llama_print_timings:        eval time =    5568.22 ms /   107 runs   (   52.04 ms per token,    19.22 tokens per second)\n",
            "llama_print_timings:       total time =    6539.74 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     126.03 ms /   165 runs   (    0.76 ms per token,  1309.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.82 ms /    10 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
            "llama_print_timings:        eval time =    8555.90 ms /   164 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    9720.75 ms /   174 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      56.34 ms /    77 runs   (    0.73 ms per token,  1366.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.17 ms /    11 tokens (   22.74 ms per token,    43.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3965.47 ms /    76 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    4564.56 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      78.51 ms /   102 runs   (    0.77 ms per token,  1299.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.06 ms /     9 tokens (   26.78 ms per token,    37.34 tokens per second)\n",
            "llama_print_timings:        eval time =    5265.40 ms /   101 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    6022.10 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      72.93 ms /    91 runs   (    0.80 ms per token,  1247.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     109.69 ms /     8 tokens (   13.71 ms per token,    72.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4691.78 ms /    90 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5305.09 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     119.93 ms /   146 runs   (    0.82 ms per token,  1217.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.18 ms /    12 tokens (   21.10 ms per token,    47.40 tokens per second)\n",
            "llama_print_timings:        eval time =    7565.87 ms /   145 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    8627.06 ms /   157 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.97 ms /   108 runs   (    0.75 ms per token,  1333.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     325.09 ms /    15 tokens (   21.67 ms per token,    46.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5562.64 ms /   107 runs   (   51.99 ms per token,    19.24 tokens per second)\n",
            "llama_print_timings:       total time =    6445.49 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.89 ms /    95 runs   (    0.80 ms per token,  1251.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.83 ms /    16 tokens (   20.80 ms per token,    48.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4896.45 ms /    94 runs   (   52.09 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =    5746.98 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      55.64 ms /    68 runs   (    0.82 ms per token,  1222.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.88 ms /    10 tokens (   24.59 ms per token,    40.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3493.20 ms /    67 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    4134.40 ms /    77 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      81.90 ms /   110 runs   (    0.74 ms per token,  1343.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     327.49 ms /    15 tokens (   21.83 ms per token,    45.80 tokens per second)\n",
            "llama_print_timings:        eval time =    5683.48 ms /   109 runs   (   52.14 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    6511.57 ms /   124 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      66.41 ms /    72 runs   (    0.92 ms per token,  1084.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =      88.70 ms /     6 tokens (   14.78 ms per token,    67.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3712.76 ms /    71 runs   (   52.29 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    4259.31 ms /    77 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      90.30 ms /   128 runs   (    0.71 ms per token,  1417.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     425.54 ms /    18 tokens (   23.64 ms per token,    42.30 tokens per second)\n",
            "llama_print_timings:        eval time =    6635.39 ms /   127 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    7629.26 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     153.77 ms /   197 runs   (    0.78 ms per token,  1281.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     421.82 ms /    18 tokens (   23.43 ms per token,    42.67 tokens per second)\n",
            "llama_print_timings:        eval time =   10244.61 ms /   196 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =   11696.61 ms /   214 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      89.85 ms /   109 runs   (    0.82 ms per token,  1213.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.47 ms /    10 tokens (   25.15 ms per token,    39.77 tokens per second)\n",
            "llama_print_timings:        eval time =    5659.58 ms /   108 runs   (   52.40 ms per token,    19.08 tokens per second)\n",
            "llama_print_timings:       total time =    6604.63 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     119.02 ms /   161 runs   (    0.74 ms per token,  1352.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.59 ms /     9 tokens (   27.18 ms per token,    36.80 tokens per second)\n",
            "llama_print_timings:        eval time =    8358.37 ms /   160 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    9340.94 ms /   169 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      86.47 ms /   102 runs   (    0.85 ms per token,  1179.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.38 ms /    13 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
            "llama_print_timings:        eval time =    5276.06 ms /   101 runs   (   52.24 ms per token,    19.14 tokens per second)\n",
            "llama_print_timings:       total time =    6219.76 ms /   114 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      95.24 ms /   126 runs   (    0.76 ms per token,  1323.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     347.15 ms /    15 tokens (   23.14 ms per token,    43.21 tokens per second)\n",
            "llama_print_timings:        eval time =    6527.26 ms /   125 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7442.17 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      81.40 ms /    96 runs   (    0.85 ms per token,  1179.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     334.87 ms /    15 tokens (   22.32 ms per token,    44.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4968.36 ms /    95 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    5873.96 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      85.38 ms /   114 runs   (    0.75 ms per token,  1335.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.31 ms /    12 tokens (   20.86 ms per token,    47.94 tokens per second)\n",
            "llama_print_timings:        eval time =    5896.59 ms /   113 runs   (   52.18 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    6684.12 ms /   125 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      62.98 ms /    70 runs   (    0.90 ms per token,  1111.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     330.15 ms /    13 tokens (   25.40 ms per token,    39.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3609.91 ms /    69 runs   (   52.32 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    4435.24 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      61.00 ms /    82 runs   (    0.74 ms per token,  1344.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     342.12 ms /    13 tokens (   26.32 ms per token,    38.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4230.38 ms /    81 runs   (   52.23 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    4977.79 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     141.00 ms /   175 runs   (    0.81 ms per token,  1241.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     330.24 ms /    16 tokens (   20.64 ms per token,    48.45 tokens per second)\n",
            "llama_print_timings:        eval time =    9109.61 ms /   174 runs   (   52.35 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =   10455.53 ms /   190 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.92 ms /   112 runs   (    0.72 ms per token,  1384.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.54 ms /    11 tokens (   22.14 ms per token,    45.17 tokens per second)\n",
            "llama_print_timings:        eval time =    5785.60 ms /   111 runs   (   52.12 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    6566.95 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      82.64 ms /   104 runs   (    0.79 ms per token,  1258.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.66 ms /     9 tokens (   26.74 ms per token,    37.40 tokens per second)\n",
            "llama_print_timings:        eval time =    5378.33 ms /   103 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    6245.56 ms /   112 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      80.12 ms /   107 runs   (    0.75 ms per token,  1335.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     326.39 ms /    14 tokens (   23.31 ms per token,    42.89 tokens per second)\n",
            "llama_print_timings:        eval time =    5531.07 ms /   106 runs   (   52.18 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    6342.11 ms /   120 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      78.40 ms /    96 runs   (    0.82 ms per token,  1224.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.03 ms /    11 tokens (   22.46 ms per token,    44.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4946.57 ms /    95 runs   (   52.07 ms per token,    19.21 tokens per second)\n",
            "llama_print_timings:       total time =    5765.55 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.17 ms /    80 runs   (    0.71 ms per token,  1399.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =      97.14 ms /     7 tokens (   13.88 ms per token,    72.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4108.34 ms /    79 runs   (   52.00 ms per token,    19.23 tokens per second)\n",
            "llama_print_timings:       total time =    4574.62 ms /    86 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      93.78 ms /   110 runs   (    0.85 ms per token,  1172.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     325.58 ms /    13 tokens (   25.04 ms per token,    39.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5699.05 ms /   109 runs   (   52.28 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    6708.55 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      57.18 ms /    79 runs   (    0.72 ms per token,  1381.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.22 ms /    10 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4072.71 ms /    78 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    4681.50 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      68.61 ms /    91 runs   (    0.75 ms per token,  1326.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     332.73 ms /    14 tokens (   23.77 ms per token,    42.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4694.80 ms /    90 runs   (   52.16 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    5464.63 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     101.03 ms /   132 runs   (    0.77 ms per token,  1306.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     499.18 ms /    21 tokens (   23.77 ms per token,    42.07 tokens per second)\n",
            "llama_print_timings:        eval time =    6837.95 ms /   131 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    8015.33 ms /   152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     100.69 ms /   122 runs   (    0.83 ms per token,  1211.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =      91.12 ms /     6 tokens (   15.19 ms per token,    65.85 tokens per second)\n",
            "llama_print_timings:        eval time =    6318.48 ms /   121 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    7091.48 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     105.65 ms /   148 runs   (    0.71 ms per token,  1400.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     328.93 ms /    16 tokens (   20.56 ms per token,    48.64 tokens per second)\n",
            "llama_print_timings:        eval time =    7688.63 ms /   147 runs   (   52.30 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    8689.44 ms /   163 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     122.34 ms /   153 runs   (    0.80 ms per token,  1250.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     333.41 ms /    16 tokens (   20.84 ms per token,    47.99 tokens per second)\n",
            "llama_print_timings:        eval time =    7930.99 ms /   152 runs   (   52.18 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    9147.99 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      75.70 ms /   100 runs   (    0.76 ms per token,  1320.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     339.91 ms /    16 tokens (   21.24 ms per token,    47.07 tokens per second)\n",
            "llama_print_timings:        eval time =    5179.38 ms /    99 runs   (   52.32 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =    6014.12 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      90.09 ms /   113 runs   (    0.80 ms per token,  1254.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.69 ms /    10 tokens (   24.27 ms per token,    41.20 tokens per second)\n",
            "llama_print_timings:        eval time =    5838.98 ms /   112 runs   (   52.13 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    6695.27 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     112.26 ms /   144 runs   (    0.78 ms per token,  1282.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     424.87 ms /    17 tokens (   24.99 ms per token,    40.01 tokens per second)\n",
            "llama_print_timings:        eval time =    7480.85 ms /   143 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
            "llama_print_timings:       total time =    8682.37 ms /   160 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     232.00 ms /   326 runs   (    0.71 ms per token,  1405.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.00 ms /    10 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
            "llama_print_timings:        eval time =   17044.83 ms /   325 runs   (   52.45 ms per token,    19.07 tokens per second)\n",
            "llama_print_timings:       total time =   18974.79 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      83.07 ms /   102 runs   (    0.81 ms per token,  1227.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     424.06 ms /    17 tokens (   24.94 ms per token,    40.09 tokens per second)\n",
            "llama_print_timings:        eval time =    5267.38 ms /   101 runs   (   52.15 ms per token,    19.17 tokens per second)\n",
            "llama_print_timings:       total time =    6289.17 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      92.13 ms /   102 runs   (    0.90 ms per token,  1107.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     411.02 ms /    19 tokens (   21.63 ms per token,    46.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5300.15 ms /   101 runs   (   52.48 ms per token,    19.06 tokens per second)\n",
            "llama_print_timings:       total time =    6378.46 ms /   120 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      72.06 ms /   102 runs   (    0.71 ms per token,  1415.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     422.16 ms /    17 tokens (   24.83 ms per token,    40.27 tokens per second)\n",
            "llama_print_timings:        eval time =    5279.03 ms /   101 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
            "llama_print_timings:       total time =    6143.72 ms /   118 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     119.72 ms /   157 runs   (    0.76 ms per token,  1311.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.91 ms /    12 tokens (   20.41 ms per token,    49.00 tokens per second)\n",
            "llama_print_timings:        eval time =    8144.33 ms /   156 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    9216.35 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      50.60 ms /    75 runs   (    0.67 ms per token,  1482.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.52 ms /    10 tokens (   24.35 ms per token,    41.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3862.74 ms /    74 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
            "llama_print_timings:       total time =    4466.79 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     104.22 ms /   131 runs   (    0.80 ms per token,  1256.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     327.04 ms /    16 tokens (   20.44 ms per token,    48.92 tokens per second)\n",
            "llama_print_timings:        eval time =    6773.51 ms /   130 runs   (   52.10 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    7803.68 ms /   146 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      74.12 ms /    95 runs   (    0.78 ms per token,  1281.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.68 ms /     9 tokens (   27.30 ms per token,    36.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4899.70 ms /    94 runs   (   52.12 ms per token,    19.18 tokens per second)\n",
            "llama_print_timings:       total time =    5664.37 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =      67.00 ms /    85 runs   (    0.79 ms per token,  1268.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     328.96 ms /    15 tokens (   21.93 ms per token,    45.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4385.51 ms /    84 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =    5192.72 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     840.77 ms\n",
            "llama_print_timings:      sample time =     118.31 ms /   154 runs   (    0.77 ms per token,  1301.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     109.18 ms /     8 tokens (   13.65 ms per token,    73.27 tokens per second)\n",
            "llama_print_timings:        eval time =    7974.40 ms /   153 runs   (   52.12 ms per token,    19.19 tokens per second)\n",
            "llama_print_timings:       total time =    8886.56 ms /   161 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213\n",
            "[0.7681029796600342, 0.8954380035400391, 0.7977747917175293, 0.5795556545257569, 0.8273495674133301, 0.7513070106506348, 0.8209623336791992, 0.8299297332763672, 0.9034114837646484, 0.8177706718444824, 0.625499677658081, 0.877796745300293, 0.8191460609436035, 0.9320152282714844, 0.9164140701293946, 0.629492998123169, 0.8352705001831054, 0.6647021293640136, 0.7478991508483886, 0.8706809043884277, 0.7389620780944824, 0.8504174232482911, 0.6694564342498779, 0.796288251876831, 0.7814426898956299, 0.6269454002380371, 0.6292051792144775, 0.8863888740539551, 0.698784065246582, 0.8437670707702637, 0.7068845748901367, 0.8926518440246582, 0.7102718353271484, 0.5563716888427734, 0.7952279567718505, 0.8955549240112305, 0.8537315368652344, 0.8929434776306152, 0.7905792236328125, 0.8169466972351074, 0.486126708984375, 0.9188735961914063, 0.7866578102111816, 0.8280077934265136, 0.8444852828979492, 0.787843656539917, 0.7060833930969238, 0.7956328868865967, 0.8781953811645508, 0.7139519214630127, 0.8409309387207031, 0.8186836242675781, 0.7884212017059327, 0.8332294464111328, 0.8124797821044922, 0.7019547939300537, 0.9413661956787109, 0.8029108047485352, 0.782418966293335, 0.7564682483673095, 0.7738505840301514, 0.9282144546508789, 0.8123991012573242, 0.8217056274414063, 0.7918411254882812, 0.79890456199646, 0.5939143657684326, 0.6478591918945312, 0.5934069633483887, 0.8908087730407714, 0.7204091072082519, 0.7735071659088135, 0.8526572227478028, 0.7818897247314454, 0.8144416809082031, 0.8338780403137207, 0.7845609188079834, 0.8684657096862793, 0.9068706512451172, 0.8255703926086426, 0.6788815021514892, 0.9246108055114746, 0.755124855041504, 0.6516551017761231, 0.7958722591400147, 0.8149935722351074, 0.8119842529296875, 0.7915099620819092, 0.7607645034790039, 0.7906651973724366, 0.7689619064331055, 0.795169448852539, 0.8643626213073731, 0.8315255165100097, 0.7630842208862305, 0.8820345878601075, 0.6705334663391114, 0.9056512832641601, 0.6463348388671875, 0.7917481899261475, 0.7827447891235352, 0.7708882808685302, 0.8968412399291992, 0.7676764965057373, 0.8813406944274902, 0.7961719989776611, 0.7582446098327636, 0.4031365871429443, 0.863010311126709, 0.9244717597961426, 0.8211297035217285, 0.7617392539978027, 0.6280974864959716, 0.9671576499938965, 0.795582389831543, 0.7767291069030762, 0.9659915924072265, 0.700771713256836, 0.7844826221466065, 0.7603096961975098, 0.8295504570007324, 0.6243926048278808, 0.8249515533447266, 0.6787716388702393, 0.7704219818115234, 0.9815427780151367, 0.7626142501831055, 0.879425048828125, 0.6181848526000977, 0.8651458740234375, 0.8105473518371582, 0.8239091873168946, 0.8497264862060547, 0.8676290512084961, 0.4752792835235596, 0.77003173828125, 0.8109601020812989, 0.8715701103210449, 0.8453310012817383, 0.8761420249938965, 0.7210123062133789, 0.7838840484619141, 0.6831979274749755, 0.9451639175415039, 0.597916555404663, 0.7811370849609375, 0.8391271591186523, 0.8212886810302734, 0.8654695510864258, 0.7621605873107911, 0.7745712280273438, 0.8731982231140136, 0.7679512977600098, 0.7785096645355225, 0.7960654258728027, 0.7272325992584229, 0.8741338729858399, 0.7894591808319091, 0.8625556945800781, 0.8189729690551758, 0.8223727226257325, 0.8861309051513672, 0.7833109855651855, 0.8298559188842773, 0.8443157196044921, 0.743614673614502, 0.8737802505493164, 0.8697517395019532, 0.8066110610961914, 0.8698721885681152, 0.8066507339477539, 0.8515974044799804, 0.8226619720458984, 0.8057406425476075, 0.6931515693664551, 0.786774730682373, 0.7501398086547851, 0.6956357955932617, 0.8180256843566894, 0.8127860069274903, 0.6682999610900879, 0.8556892395019531, 0.8157302856445312, 0.9062559127807617, 0.7948631763458252, 0.8293678283691406, 0.5979797840118408, 0.8102456092834472, 0.776186180114746, 0.7872882843017578, 0.4312572479248047, 0.6987018585205078, 0.6663486957550049, 0.8781218528747559, 0.8513647079467773, 0.7639531135559082, 0.7824333667755127, 0.8760545730590821, 0.9368134498596191, 0.7683962821960449, 0.8907995223999023, 0.8333976745605469, 0.7107333183288574, 0.8551780700683593, 0.9578007698059082, 0.738094425201416, 0.87631254196167, 0.8401419639587402, 0.8970804214477539, 0.8049026489257812, 0.6987715721130371, 0.9219130516052246, 0.8044835090637207, 0.8461310386657714]\n",
            "0.792188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9izbXv6ZfWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}